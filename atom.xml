<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhisheng的博客</title>
  
  <subtitle>坑要一个个填，路要一步步走！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.54tianzhisheng.cn/"/>
  <updated>2021-11-11T15:33:45.652Z</updated>
  <id>http://www.54tianzhisheng.cn/</id>
  
  <author>
    <name>zhisheng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>宕机一台机器，结果一百多个 Flink 作业挂了</title>
    <link href="http://www.54tianzhisheng.cn/2021/11/11/flink-akka-framesize/"/>
    <id>http://www.54tianzhisheng.cn/2021/11/11/flink-akka-framesize/</id>
    <published>2021-11-10T16:00:00.000Z</published>
    <updated>2021-11-11T15:33:45.652Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>因宕机了一台物理机器，实时集群不少作业发生 failover，其中大部分作业都能 failover 成功，某个部门的部分作业一直在 failover，始终未成功，到 WebUI 查看作业异常日志如下：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">2021-11-09 16:01:11</span><br><span class="line">java.util.concurrent.CompletionException: java.lang.reflect.UndeclaredThrowableException</span><br><span class="line"> at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)</span><br><span class="line"> at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)</span><br><span class="line"> at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592)</span><br><span class="line"> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line"> at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line"> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)</span><br><span class="line"> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line"> at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: java.lang.reflect.UndeclaredThrowableException</span><br><span class="line"> at com.sun.proxy.$Proxy54.submitTask(Unknown Source)</span><br><span class="line"> at org.apache.flink.runtime.jobmaster.RpcTaskManagerGateway.submitTask(RpcTaskManagerGateway.java:72)</span><br><span class="line"> at org.apache.flink.runtime.executiongraph.Execution.lambda$deploy$10(Execution.java:756)</span><br><span class="line"> at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)</span><br><span class="line"> ... 7 more</span><br><span class="line">Caused by: java.io.IOException: The rpc invocation size 56424326 exceeds the maximum akka framesize.</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.createRpcInvocationMessage(AkkaInvocationHandler.java:276)</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.invokeRpc(AkkaInvocationHandler.java:205)</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.invoke(AkkaInvocationHandler.java:134)</span><br><span class="line"> ... 11 more</span><br></pre></td></tr></table></figure><h3 id="解决异常过程"><a href="#解决异常过程" class="headerlink" title="解决异常过程"></a>解决异常过程</h3><p>从上面的异常日志中我们提取到关键信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.io.IOException: The rpc invocation size 56424326 exceeds the maximum akka framesize.</span><br></pre></td></tr></table></figure><p>看起来是 RPC 的消息大小超过了默认的 akka framesize 的最大值了，所以我们来了解一下这个值的默认值，从 <a href="https://nightlies.apache.org/flink/flink-docs-release-1.12/deployment/config.html#akka-framesize">官网</a> 我们可以看的到该值的默认大小为 “10485760b”，并且该参数的描述为：</p><p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gwbm72hedkj31i806imya.jpg" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Maximum size of messages which are sent between the JobManager and the TaskManagers. If Flink fails because messages exceed this limit, then you should increase it. The message size requires a size-unit specifier.</span><br></pre></td></tr></table></figure><p>翻译过来的意思就是：这个参数是 JobManager 和 TaskManagers 之间通信允许的最大消息大小，如果 Flink 作业因为通信消息大小超过了该值，你可以通过增加该值的大小来解决，该参数需要指定一个单位。</p><h3 id="分析原因"><a href="#分析原因" class="headerlink" title="分析原因"></a>分析原因</h3><p>Flink 使用 Akka 作为组件（JobManager/TaskManager/ResourceManager）之间的 RPC 框架，在 JobManager 和 TaskManagers 之间发送的消息的最大大小默认为 10485760b，如果消息超过这个限制就会失败，报错。这个可以看下抛出异常处的源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">protected RpcInvocation createRpcInvocationMessage(String methodName, Class&lt;?&gt;[] parameterTypes, Object[] args) throws IOException &#123;</span><br><span class="line">    Object rpcInvocation;</span><br><span class="line">    if (this.isLocal) &#123;</span><br><span class="line">        rpcInvocation = new LocalRpcInvocation(methodName, parameterTypes, args);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            RemoteRpcInvocation remoteRpcInvocation = new RemoteRpcInvocation(methodName, parameterTypes, args);</span><br><span class="line">            if (remoteRpcInvocation.getSize() &gt; this.maximumFramesize) &#123;</span><br><span class="line">                // 异常所在位置</span><br><span class="line">                throw new IOException(&quot;The rpc invocation size exceeds the maximum akka framesize.&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            rpcInvocation = remoteRpcInvocation;</span><br><span class="line">        &#125; catch (IOException var6) &#123;</span><br><span class="line">            LOG.warn(&quot;Could not create remote rpc invocation message. Failing rpc invocation because...&quot;, var6);</span><br><span class="line">            throw var6;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return (RpcInvocation)rpcInvocation;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至于为什么 JobManager 和 TaskManager 之间的 RPC 消息大小会如此之大，初步的解释是在 task 出现异常之后，它需要调用 updateTaskExecutionState(TaskExecutionState，taskExecutionState) 这个 RPC 接口去通知 Flink Jobmanager 去改变对应 task 的状态并且重启 task。但是呢，taskExecutionState 这个参数里面有个 error 属性，当我的 task 打出来的错误栈太多的时候，在序列化的之后超过了 rpc 接口要求的最大数据大小（也就是 maximum akka framesize），导致调用 updateTaskExecutionState 这个 rpc 接口失败，Jobmanager 无法获知这个 task 已经处于 fail 的状态，也无法重启，然后就导致了一系列连锁反应。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>任务停止，在 <code>flink-conf.yaml</code> 中加入 <code>akka.framesize</code> 参数，调大该值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">akka.framesize: &quot;62914560b&quot;</span><br></pre></td></tr></table></figure><p>然后将任务重启，可以观察 Jobmanager Configration 看看参数是否生效。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;因宕机了一台物理机器，实时集群不少作业发生 failover，其中大部分作业都能 failover 成功，某个部门的部分作业一直在 failover，始终未成功，到 WebUI 查看作业异常日志如下：&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>实时平台如何管理多个 Flink 版本？—— 为啥会出现多个版本？</title>
    <link href="http://www.54tianzhisheng.cn/2021/09/26/realtime-platform-flink-version/"/>
    <id>http://www.54tianzhisheng.cn/2021/09/26/realtime-platform-flink-version/</id>
    <published>2021-09-25T16:00:00.000Z</published>
    <updated>2021-11-14T03:12:49.099Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为啥会出现多个版本？"><a href="#为啥会出现多个版本？" class="headerlink" title="为啥会出现多个版本？"></a>为啥会出现多个版本？</h3><a id="more"></a><ul><li><p><strong>Flink 社区</strong>本身迭代速度非常快，目前阿里云有一大波的人专职做 Flink 开源，另外还拥有活跃的社区贡献者，所以功能开发较快，bug 修复速度较快，几乎每 4 个月一个大版本，每个大版本之间迭代的功能非常多，代码变动非常大，API 接口变动也大，动不动就干翻自己了。</p></li><li><p>社区迭代快就快呗，为什么<strong>公司</strong>也要要不断跟着社区鼻子走？社区迭代快意味着功能多，修复的 bug 多，相对于早期版本意味着稳定性也高些。除了国内一二线公司有特别多的专职人去负责这块，大多数中小公司最简单最快捷体验到稳定性最高、功能性最多、性能最好的 Flink 版本无非是直接使用最新的 Flink 版本。举个例子：Flink SQL 从最早期（1.9）的功能、性能到目前 1.14，差别真的大很多，优化了特别多的地方，增强了很多功能。原先使用 Flink SQL 完成一个流处理任务非常麻烦，还不如直接写几十行代码来的快，目前我情愿写 SQL 去处理一个流任务。那么自然会跟着升级到新版本。</p></li><li><p><strong>用户 A</strong> 问 Flink SQL 支持单独设置并行度吗？<strong>用户 B</strong> 问实时平台现在支持 Flink 1.13 版本的 Window TVF？这个要 Flink xxx 版本才能支持，要不你升级一下 Flink 版本到 xxx？这样就能支持了，类似的场景还有很多，对于<strong>中小公司的实时平台负责人</strong>来说，这无非最省事；对于<strong>大公司的负责实时开发的人</strong>来说，这无疑是一个噩梦，每次升级新版本都要将在老版本开发的各种功能都想尽办法移植到新版本上来，碰到 API 接口变动大的无非相当于重写了，或者将新版本的某些特别需要的功能通过打 patch 的方式打到老版本里面去。</p></li><li><p>新版本香是真的香，可是为啥有的人不用呢？问题就是，实时作业大多数是长期运行的，如果一个作业没啥错误，在生产运行的好好的，也不出啥故障，稳定性和性能也都能接受（并不是所有作业数据量都很大，会遇到性能问题），那么<strong>用户</strong>为啥要使用新版本？用户才不管你新版本功能多牛逼，性能多屌呢，老子升级还要改依赖版本、改接口代码、测试联调、性能测试（谁知道你说的性能提升是不是吹牛逼的）、稳定性测试（可能上线双跑一段时间验证），这些不需要时间呀，你叫我升级就升级，滚犊子吧，你知道我还有多少业务需求要做吗？</p></li></ul><p>那么就落下这个场地了，又要使用新版本的功能去解决问题，老作业的用户跟他各种扯皮也打动不了他升级作业的版本，那么自然就不断的出现了多个版本了。</p><p>这样，如果不对版本做好规划，那么摊子就逐渐越来越大，越来越难收拾了？</p><p>那么该如何管理公司的 Flink 版本？如果管理和兼容多个 Flink 版本的作业提交？如何兼容 Jar 包和 SQL 作业的提交</p><h3 id="怎么管理多个-Flink-版本的作业提交？"><a href="#怎么管理多个-Flink-版本的作业提交？" class="headerlink" title="怎么管理多个 Flink 版本的作业提交？"></a>怎么管理多个 Flink 版本的作业提交？</h3><p>尽请期待下篇文章</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;为啥会出现多个版本？&quot;&gt;&lt;a href=&quot;#为啥会出现多个版本？&quot; class=&quot;headerlink&quot; title=&quot;为啥会出现多个版本？&quot;&gt;&lt;/a&gt;为啥会出现多个版本？&lt;/h3&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 数据转换必须熟悉的算子（Operator)</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/13/flink-in-action-3.3/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/13/flink-in-action-3.3/</id>
    <published>2021-07-12T16:00:00.000Z</published>
    <updated>2021-11-14T04:33:27.153Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3-3-必须熟悉的数据转换-Operator-算子"><a href="#3-3-必须熟悉的数据转换-Operator-算子" class="headerlink" title="3.3 必须熟悉的数据转换 Operator(算子)"></a>3.3 必须熟悉的数据转换 Operator(算子)</h2><p>在 Flink 应用程序中，无论你的应用程序是批程序，还是流程序，都是上图这种模型，有数据源（source），有数据下游（sink），我们写的应用程序多是对数据源过来的数据做一系列操作，总结如下。</p><a id="more"></a><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-14-141653.png" alt=""></p><p>1、<strong>Source</strong>: 数据源，Flink 在流处理和批处理上的 source 大概有 4 类：基于本地集合的 source、基于文件的 source、基于网络套接字的 source、自定义的 source。自定义的 source 常见的有 Apache kafka、Amazon Kinesis Streams、RabbitMQ、Twitter Streaming API、Apache NiFi 等，当然你也可以定义自己的 source。</p><p>2、<strong>Transformation</strong>: 数据转换的各种操作，有 Map / FlatMap / Filter / KeyBy / Reduce / Fold / Aggregations / Window / WindowAll / Union / Window join / Split / Select / Project 等，操作很多，可以将数据转换计算成你想要的数据。</p><p>3、<strong>Sink</strong>: 接收器，Sink 是指 Flink 将转换计算后的数据发送的地点 ，你可能需要存储下来。Flink 常见的 Sink 大概有如下几类：写入文件、打印出来、写入 Socket 、自定义的 Sink 。自定义的 sink 常见的有 Apache kafka、RabbitMQ、MySQL、ElasticSearch、Apache Cassandra、Hadoop FileSystem 等，同理你也可以定义自己的 Sink。</p><p>那么本文将给大家介绍的就是 Flink 中的批和流程序常用的算子（Operator）。</p><h3 id="3-3-1-DataStream-Operator"><a href="#3-3-1-DataStream-Operator" class="headerlink" title="3.3.1 DataStream Operator"></a>3.3.1 DataStream Operator</h3><p>我们先来看看流程序中常用的算子。</p><h4 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h4><p>Map 算子的输入流是 DataStream，经过 Map 算子后返回的数据格式是 SingleOutputStreamOperator 类型，获取一个元素并生成一个元素，举个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Employee&gt; map = employeeStream.map(<span class="keyword">new</span> MapFunction&lt;Employee, Employee&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Employee <span class="title">map</span><span class="params">(Employee employee)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        employee.salary = employee.salary + <span class="number">5000</span>;</span><br><span class="line">        <span class="keyword">return</span> employee;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">map.print();</span><br></pre></td></tr></table></figure><p>新的一年给每个员工的工资加 5000。</p><h4 id="FlatMap"><a href="#FlatMap" class="headerlink" title="FlatMap"></a>FlatMap</h4><p>FlatMap 算子的输入流是 DataStream，经过 FlatMap 算子后返回的数据格式是 SingleOutputStreamOperator 类型，获取一个元素并生成零个、一个或多个元素，举个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Employee&gt; flatMap = employeeStream.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;Employee, Employee&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(Employee employee, Collector&lt;Employee&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (employee.salary &gt;= <span class="number">40000</span>) &#123;</span><br><span class="line">            out.collect(employee);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">flatMap.print();</span><br></pre></td></tr></table></figure><p>将工资大于 40000 的找出来。</p><h4 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h4><h4 id="KeyBy"><a href="#KeyBy" class="headerlink" title="KeyBy"></a>KeyBy</h4><h4 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h4><h4 id="Aggregations"><a href="#Aggregations" class="headerlink" title="Aggregations"></a>Aggregations</h4><h4 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h4><h4 id="WindowAll"><a href="#WindowAll" class="headerlink" title="WindowAll"></a>WindowAll</h4><h4 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h4><h4 id="Window-Join"><a href="#Window-Join" class="headerlink" title="Window Join"></a>Window Join</h4><h4 id="Split"><a href="#Split" class="headerlink" title="Split"></a>Split</h4><h4 id="Select"><a href="#Select" class="headerlink" title="Select"></a>Select</h4><h3 id="3-3-2-DataSet-Operator"><a href="#3-3-2-DataSet-Operator" class="headerlink" title="3.3.2 DataSet Operator"></a>3.3.2 DataSet Operator</h3><h4 id="First-n"><a href="#First-n" class="headerlink" title="First-n"></a>First-n</h4><h3 id="3-3-3-流计算与批计算统一的思路"><a href="#3-3-3-流计算与批计算统一的思路" class="headerlink" title="3.3.3 流计算与批计算统一的思路"></a>3.3.3 流计算与批计算统一的思路</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/iYFMZFA">https://t.zsxq.com/iYFMZFA</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="3-3-4-小结与反思"><a href="#3-3-4-小结与反思" class="headerlink" title="3.3.4 小结与反思"></a>3.3.4 小结与反思</h3><p>本节介绍了在开发 Flink 作业中数据转换常使用的算子（包含流作业和批作业），DataStream API 和 DataSet API 中部分算子名字是一致的，也有不同的地方，最后讲解了下 Flink 社区后面流批统一的思路。</p><p>你们公司使用 Flink 是流作业居多还是批作业居多？</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;3-3-必须熟悉的数据转换-Operator-算子&quot;&gt;&lt;a href=&quot;#3-3-必须熟悉的数据转换-Operator-算子&quot; class=&quot;headerlink&quot; title=&quot;3.3 必须熟悉的数据转换 Operator(算子)&quot;&gt;&lt;/a&gt;3.3 必须熟悉的数据转换 Operator(算子)&lt;/h2&gt;&lt;p&gt;在 Flink 应用程序中，无论你的应用程序是批程序，还是流程序，都是上图这种模型，有数据源（source），有数据下游（sink），我们写的应用程序多是对数据源过来的数据做一系列操作，总结如下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何使用 Flink Window 及 Window 基本概念与实现原理?</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/12/flink-in-action-3.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/12/flink-in-action-3.2/</id>
    <published>2021-07-11T16:00:00.000Z</published>
    <updated>2021-11-14T04:29:54.825Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3-2-Flink-Window-基础概念与实现原理"><a href="#3-2-Flink-Window-基础概念与实现原理" class="headerlink" title="3.2 Flink Window 基础概念与实现原理"></a>3.2 Flink Window 基础概念与实现原理</h2><p>目前有许多数据分析的场景从批处理到流处理的演变， 虽然可以将批处理作为流处理的特殊情况来处理，但是分析无穷集的流数据通常需要思维方式的转变并且具有其自己的术语，例如，“windowing（窗口化）”、“at-least-once（至少一次）”、“exactly-once（只有一次）” 。</p><a id="more"></a><p>对于刚刚接触流处理的人来说，这种转变和新术语可能会非常混乱。 Apache Flink 是一个为生产环境而生的流处理器，具有易于使用的 API，可以用于定义高级流分析程序。Flink 的 API 在数据流上具有非常灵活的窗口定义，使其在其他开源流处理框架中脱颖而出。</p><p>在本节将讨论用于流处理的窗口的概念，介绍 Flink 的内置窗口，并解释它对自定义窗口语义的支持。</p><h3 id="3-2-1-Window-简介"><a href="#3-2-1-Window-简介" class="headerlink" title="3.2.1 Window 简介"></a>3.2.1 Window 简介</h3><p>下面我们结合一个现实的例子来说明。</p><p>就拿交通传感器的示例：统计经过某红绿灯的汽车数量之和？</p><p>假设在一个红绿灯处，我们每隔 15 秒统计一次通过此红绿灯的汽车数量，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-064257.png" alt=""></p><p>可以把汽车的经过看成一个流，无穷的流，不断有汽车经过此红绿灯，因此无法统计总共的汽车数量。但是，我们可以换一种思路，每隔 15 秒，我们都将与上一次的结果进行 sum 操作（滑动聚合），如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-064320.png" alt=""></p><p>这个结果似乎还是无法回答我们的问题，根本原因在于流是无界的，我们不能限制流，但可以在有一个有界的范围内处理无界的流数据。因此，我们需要换一个问题的提法：每分钟经过某红绿灯的汽车数量之和？</p><p>这个问题，就相当于一个定义了一个 Window（窗口），Window 的界限是 1 分钟，且每分钟内的数据互不干扰，因此也可以称为翻滚（不重合）窗口，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-065851.png" alt=""></p><p>第一分钟的数量为 18，第二分钟是 28，第三分钟是 24……这样，1 个小时内会有 60 个 Window。</p><p>再考虑一种情况，每 30 秒统计一次过去 1 分钟的汽车数量之和，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-071008.png" alt=""></p><p>此时，Window 出现了重合。这样，1 个小时内会有 120 个 Window。</p><h3 id="3-2-2-Window-有什么作用？"><a href="#3-2-2-Window-有什么作用？" class="headerlink" title="3.2.2 Window 有什么作用？"></a>3.2.2 Window 有什么作用？</h3><p>通常来讲，Window 就是用来对一个无限的流设置一个有限的集合，在有界的数据集上进行操作的一种机制。Window 又可以分为基于时间（Time-based）的 Window 以及基于数量（Count-based）的 window。</p><h3 id="3-2-3-Flink-自带的-Window"><a href="#3-2-3-Flink-自带的-Window" class="headerlink" title="3.2.3 Flink 自带的 Window"></a>3.2.3 Flink 自带的 Window</h3><p>Flink 在 KeyedStream（DataStream 的继承类） 中提供了下面几种 Window：</p><ul><li>以时间驱动的 Time Window</li><li>以事件数量驱动的 Count Window</li><li>以会话间隔驱动的 Session Window</li></ul><p>提供上面三种 Window 机制后，由于某些特殊的需要，DataStream API 也提供了定制化的 Window 操作，供用户自定义 Window。</p><p>下面将先围绕上面说的三种 Window 来进行分析并教大家如何使用，然后对其原理分析，最后在解析其源码实现。</p><h3 id="3-2-4-Time-Window-的用法及源码分析"><a href="#3-2-4-Time-Window-的用法及源码分析" class="headerlink" title="3.2.4 Time Window 的用法及源码分析"></a>3.2.4 Time Window 的用法及源码分析</h3><h3 id="3-2-5-Count-Window-的用法及源码分析"><a href="#3-2-5-Count-Window-的用法及源码分析" class="headerlink" title="3.2.5 Count Window 的用法及源码分析"></a>3.2.5 Count Window 的用法及源码分析</h3><h3 id="3-2-6-Session-Window-的用法及源码分析"><a href="#3-2-6-Session-Window-的用法及源码分析" class="headerlink" title="3.2.6 Session Window 的用法及源码分析"></a>3.2.6 Session Window 的用法及源码分析</h3><h3 id="3-2-7-如何自定义-Window？"><a href="#3-2-7-如何自定义-Window？" class="headerlink" title="3.2.7 如何自定义 Window？"></a>3.2.7 如何自定义 Window？</h3><h3 id="3-2-8-Window-源码分析"><a href="#3-2-8-Window-源码分析" class="headerlink" title="3.2.8 Window 源码分析"></a>3.2.8 Window 源码分析</h3><h3 id="3-2-9-Window-组件之-WindowAssigner-的用法及源码分析"><a href="#3-2-9-Window-组件之-WindowAssigner-的用法及源码分析" class="headerlink" title="3.2.9 Window 组件之 WindowAssigner 的用法及源码分析"></a>3.2.9 Window 组件之 WindowAssigner 的用法及源码分析</h3><h3 id="3-2-10-Window-组件之-Trigger-的用法及源码分析"><a href="#3-2-10-Window-组件之-Trigger-的用法及源码分析" class="headerlink" title="3.2.10 Window 组件之 Trigger 的用法及源码分析"></a>3.2.10 Window 组件之 Trigger 的用法及源码分析</h3><h3 id="3-2-11-Window-组件之-Evictor-的用法及源码分析"><a href="#3-2-11-Window-组件之-Evictor-的用法及源码分析" class="headerlink" title="3.2.11 Window 组件之 Evictor 的用法及源码分析"></a>3.2.11 Window 组件之 Evictor 的用法及源码分析</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/qnQRvrf">https://t.zsxq.com/qnQRvrf</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="3-2-12-小结与反思"><a href="#3-2-12-小结与反思" class="headerlink" title="3.2.12 小结与反思"></a>3.2.12 小结与反思</h3><p>本节从生活案例来分享关于 Window 方面的需求，进而开始介绍 Window 相关的知识，并把 Flink 中常使用的三种窗口都一一做了介绍，并告诉大家如何使用，还分析了其实现原理。最后还对 Window 的内部组件做了详细的分析，为自定义 Window 提供了方法。</p><p>不知道你看完本节后对 Window 还有什么疑问吗？你们是根据什么条件来选择使用哪种 Window 的？在使用的过程中有遇到什么问题吗？ </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;3-2-Flink-Window-基础概念与实现原理&quot;&gt;&lt;a href=&quot;#3-2-Flink-Window-基础概念与实现原理&quot; class=&quot;headerlink&quot; title=&quot;3.2 Flink Window 基础概念与实现原理&quot;&gt;&lt;/a&gt;3.2 Flink Window 基础概念与实现原理&lt;/h2&gt;&lt;p&gt;目前有许多数据分析的场景从批处理到流处理的演变， 虽然可以将批处理作为流处理的特殊情况来处理，但是分析无穷集的流数据通常需要思维方式的转变并且具有其自己的术语，例如，“windowing（窗口化）”、“at-least-once（至少一次）”、“exactly-once（只有一次）” 。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 中 Processing Time、Event Time、Ingestion Time 对比及其使用场景分析</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/11/flink-in-action-3.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/11/flink-in-action-3.1/</id>
    <published>2021-07-10T16:00:00.000Z</published>
    <updated>2021-11-14T04:34:33.437Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第三章-——-Flink-中的流计算处理"><a href="#第三章-——-Flink-中的流计算处理" class="headerlink" title="第三章 —— Flink 中的流计算处理"></a>第三章 —— Flink 中的流计算处理</h1><p>通过第二章的入门案例讲解，相信你已经知道了 Flink 程序的开发过程，本章将带你熟悉 Flink 中的各种特性，比如多种时间语义、丰富的窗口机制、流计算中常见的运算操作符、Watermark 机制、丰富的 Connectors（Kafka、ElasticSearch、Redis、HBase 等） 的使用方式。除了介绍这些知识点的原理之外，笔者还将通过案例来教会大家如何去实战使用，最后还会讲解这些原理的源码实现，希望你可以更深刻的理解这些特性。</p><h2 id="3-1-Flink-多种时间语义对比"><a href="#3-1-Flink-多种时间语义对比" class="headerlink" title="3.1 Flink 多种时间语义对比"></a>3.1 Flink 多种时间语义对比</h2><a id="more"></a><p>Flink 在流应用程序中支持不同的 <strong>Time</strong> 概念，就比如有 Processing Time、Event Time 和 Ingestion Time。下面我们一起来看看这三个 Time。</p><h3 id="3-1-1-Processing-Time"><a href="#3-1-1-Processing-Time" class="headerlink" title="3.1.1 Processing Time"></a>3.1.1 Processing Time</h3><p>Processing Time 是指事件被处理时机器的系统时间。</p><p>如果我们 Flink Job 设置的时间策略是 Processing Time 的话，那么后面所有基于时间的操作（如时间窗口）都将会使用当时机器的系统时间。每小时 Processing Time 窗口将包括在系统时钟指示整个小时之间到达特定操作的所有事件。</p><p>例如，如果应用程序在上午 9:15 开始运行，则第一个每小时 Processing Time 窗口将包括在上午 9:15 到上午 10:00 之间处理的事件，下一个窗口将包括在上午 10:00 到 11:00 之间处理的事件。</p><p>Processing Time 是最简单的 “Time” 概念，不需要流和机器之间的协调，它提供了最好的性能和最低的延迟。但是，在分布式和异步的环境下，Processing Time 不能提供确定性，因为它容易受到事件到达系统的速度（例如从消息队列）、事件在系统内操作流动的速度以及中断的影响。</p><h3 id="3-1-2-Event-Time"><a href="#3-1-2-Event-Time" class="headerlink" title="3.1.2 Event Time"></a>3.1.2 Event Time</h3><p>Event Time 是指事件发生的时间，一般就是数据本身携带的时间。这个时间通常是在事件到达 Flink 之前就确定的，并且可以从每个事件中获取到事件时间戳。在 Event Time 中，时间取决于数据，而跟其他没什么关系。Event Time 程序必须指定如何生成 Event Time 水印，这是表示 Event Time 进度的机制。</p><p>完美的说，无论事件什么时候到达或者其怎么排序，最后处理 Event Time 将产生完全一致和确定的结果。但是，除非事件按照已知顺序（事件产生的时间顺序）到达，否则处理 Event Time 时将会因为要等待一些无序事件而产生一些延迟。由于只能等待一段有限的时间，因此就难以保证处理 Event Time 将产生完全一致和确定的结果。</p><p>假设所有数据都已到达，Event Time 操作将按照预期运行，即使在处理无序事件、延迟事件、重新处理历史数据时也会产生正确且一致的结果。 例如，每小时事件时间窗口将包含带有落入该小时的事件时间戳的所有记录，不管它们到达的顺序如何（是否按照事件产生的时间）。</p><h3 id="3-1-3-Ingestion-Time"><a href="#3-1-3-Ingestion-Time" class="headerlink" title="3.1.3 Ingestion Time"></a>3.1.3 Ingestion Time</h3><p>Ingestion Time 是事件进入 Flink 的时间。 在数据源操作处（进入 Flink source 时），每个事件将进入 Flink 时当时的时间作为时间戳，并且基于时间的操作（如时间窗口）会利用这个时间戳。</p><p>Ingestion Time 在概念上位于 Event Time 和 Processing Time 之间。 与 Processing Time 相比，成本可能会高一点，但结果更可预测。因为 Ingestion Time 使用稳定的时间戳（只在进入 Flink 的时候分配一次），所以对事件的不同窗口操作将使用相同的时间戳（第一次分配的时间戳），而在 Processing Time 中，每个窗口操作符可以将事件分配给不同的窗口（基于机器系统时间和到达延迟）。</p><p>与 Event Time 相比，Ingestion Time 程序无法处理任何无序事件或延迟数据，但程序中不必指定如何生成水印。</p><p>在 Flink 中，Ingestion Time 与 Event Time 非常相似，唯一区别就是 Ingestion Time 具有自动分配时间戳和自动生成水印功能。</p><h3 id="3-1-4-三种-Time-的对比结果"><a href="#3-1-4-三种-Time-的对比结果" class="headerlink" title="3.1.4 三种 Time 的对比结果"></a>3.1.4 三种 Time 的对比结果</h3><h3 id="3-1-5-使用场景分析"><a href="#3-1-5-使用场景分析" class="headerlink" title="3.1.5 使用场景分析"></a>3.1.5 使用场景分析</h3><h3 id="3-1-6-Time-策略设置"><a href="#3-1-6-Time-策略设置" class="headerlink" title="3.1.6 Time 策略设置"></a>3.1.6 Time 策略设置</h3><h3 id="3-1-7-小结与反思"><a href="#3-1-7-小结与反思" class="headerlink" title="3.1.7 小结与反思"></a>3.1.7 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/znqnMNB">https://t.zsxq.com/znqnMNB</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第三章-——-Flink-中的流计算处理&quot;&gt;&lt;a href=&quot;#第三章-——-Flink-中的流计算处理&quot; class=&quot;headerlink&quot; title=&quot;第三章 —— Flink 中的流计算处理&quot;&gt;&lt;/a&gt;第三章 —— Flink 中的流计算处理&lt;/h1&gt;&lt;p&gt;通过第二章的入门案例讲解，相信你已经知道了 Flink 程序的开发过程，本章将带你熟悉 Flink 中的各种特性，比如多种时间语义、丰富的窗口机制、流计算中常见的运算操作符、Watermark 机制、丰富的 Connectors（Kafka、ElasticSearch、Redis、HBase 等） 的使用方式。除了介绍这些知识点的原理之外，笔者还将通过案例来教会大家如何去实战使用，最后还会讲解这些原理的源码实现，希望你可以更深刻的理解这些特性。&lt;/p&gt;
&lt;h2 id=&quot;3-1-Flink-多种时间语义对比&quot;&gt;&lt;a href=&quot;#3-1-Flink-多种时间语义对比&quot; class=&quot;headerlink&quot; title=&quot;3.1 Flink 多种时间语义对比&quot;&gt;&lt;/a&gt;3.1 Flink 多种时间语义对比&lt;/h2&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 案例2：实时处理 Socket 数据</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/10/flink-in-action-2.4/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/10/flink-in-action-2.4/</id>
    <published>2021-07-09T16:00:00.000Z</published>
    <updated>2021-11-08T15:29:24.446Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-4-案例2：实时处理-Socket-数据"><a href="#2-4-案例2：实时处理-Socket-数据" class="headerlink" title="2.4 案例2：实时处理 Socket 数据"></a>2.4 案例2：实时处理 Socket 数据</h2><p>在 2.3 节中讲解了 Flink 最简单的 WordCount 程序的创建、运行结果查看和代码分析，本节将继续带大家来看一个入门上手的程序：Flink 处理 Socket 数据。</p><a id="more"></a><h3 id="2-4-1-使用-IDEA-创建项目"><a href="#2-4-1-使用-IDEA-创建项目" class="headerlink" title="2.4.1 使用 IDEA 创建项目"></a>2.4.1 使用 IDEA 创建项目</h3><p>使用 IDEA 创建新的 module，结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">├── pom.xml</span><br><span class="line">└── src</span><br><span class="line">    ├── main</span><br><span class="line">    │   ├── java</span><br><span class="line">    │   │   └── com</span><br><span class="line">    │   │       └── zhisheng</span><br><span class="line">    │   │           └── socket</span><br><span class="line">    │   │               └── Main.java</span><br><span class="line">    │   └── resources</span><br><span class="line">    │       └── log4j.properties</span><br><span class="line">    └── test</span><br><span class="line">        └── java</span><br></pre></td></tr></table></figure><p>项目创建好了后，我们下一步开始编写 Flink Socket Job 的代码。</p><h3 id="2-4-2-实时处理-Socket-数据应用程序代码实现"><a href="#2-4-2-实时处理-Socket-数据应用程序代码实现" class="headerlink" title="2.4.2 实时处理 Socket 数据应用程序代码实现"></a>2.4.2 实时处理 Socket 数据应用程序代码实现</h3><p>程序代码如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//参数检查</span></span><br><span class="line">        <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">"USAGE:\nSocketTextStreamWordCount &lt;hostname&gt; &lt;port&gt;"</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        String hostname = args[<span class="number">0</span>];</span><br><span class="line">        Integer port = Integer.parseInt(args[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">//获取数据</span></span><br><span class="line">        DataStreamSource&lt;String&gt; stream = env.socketTextStream(hostname, port);</span><br><span class="line">        <span class="comment">//计数</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = stream.flatMap(<span class="keyword">new</span> LineSplitter())</span><br><span class="line">                .keyBy(<span class="number">0</span>)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line">        sum.print();</span><br><span class="line">        env.execute(<span class="string">"Java WordCount from SocketText"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">LineSplitter</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; collector)</span> </span>&#123;</span><br><span class="line">            String[] tokens = s.toLowerCase().split(<span class="string">"\\W+"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (String token: tokens) &#123;</span><br><span class="line">                <span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    collector.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(token, <span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>pom.xml</strong> 添加 build：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">source</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">target</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-shade-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>shade<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">artifactSet</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>org.apache.flink:force-shading<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>com.google.code.findbugs:jsr305<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>org.slf4j:*<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>log4j:*<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">artifactSet</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">filters</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">filter</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">artifact</span>&gt;</span>*:*<span class="tag">&lt;/<span class="name">artifact</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.SF<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.DSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.RSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">filters</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">transformers</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">transformer</span> <span class="attr">implementation</span>=<span class="string">"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"</span>&gt;</span></span><br><span class="line">                                <span class="comment">&lt;!--注意：这里一定要换成你自己的 Job main 方法的启动类--&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.zhisheng.socket.Main<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">transformers</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="2-4-3-运行实时处理-Socket-数据应用程序"><a href="#2-4-3-运行实时处理-Socket-数据应用程序" class="headerlink" title="2.4.3 运行实时处理 Socket 数据应用程序"></a>2.4.3 运行实时处理 Socket 数据应用程序</h3><p>下面分别讲解在 IDE 和 Flink UI 上运行作业。</p><h4 id="本地-IDE-运行"><a href="#本地-IDE-运行" class="headerlink" title="本地 IDE 运行"></a>本地 IDE 运行</h4><h4 id="UI-运行-Job"><a href="#UI-运行-Job" class="headerlink" title="UI 运行 Job"></a>UI 运行 Job</h4><h3 id="2-4-4-实时处理-Socket-数据应用程序代码分析"><a href="#2-4-4-实时处理-Socket-数据应用程序代码分析" class="headerlink" title="2.4.4 实时处理 Socket 数据应用程序代码分析"></a>2.4.4 实时处理 Socket 数据应用程序代码分析</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/VBEQv3F">https://t.zsxq.com/VBEQv3F</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="2-4-5-Flink-中使用-Lambda-表达式"><a href="#2-4-5-Flink-中使用-Lambda-表达式" class="headerlink" title="2.4.5 Flink 中使用 Lambda 表达式"></a>2.4.5 Flink 中使用 Lambda 表达式</h3><p>因为 Lambda 表达式看起来简洁，所以有时候也是希望在这些 Flink 作业中也可以使用上它，虽然 Flink 中是支持 Lambda，但是个人感觉不太友好。比如上面的应用程序如果将 LineSplitter 该类之间用 Lambda 表达式完成的话则要像下面这样写：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">stream.flatMap((s, collector) -&gt; &#123;</span><br><span class="line">    <span class="keyword">for</span> (String token : s.toLowerCase().split(<span class="string">"\\W+"</span>)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            collector.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(token, <span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">        .keyBy(<span class="number">0</span>)</span><br><span class="line">        .sum(<span class="number">1</span>)</span><br><span class="line">        .print();</span><br></pre></td></tr></table></figure><p>但是这样写完后，运行作业报错如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; org.apache.flink.api.common.functions.InvalidTypesException: The return type of function &apos;main(LambdaMain.java:34)&apos; could not be determined automatically, due to type erasure. You can give type information hints by using the returns(...) method on the result of the transformation call, or by letting your function implement the &apos;ResultTypeQueryable&apos; interface.</span><br><span class="line">at org.apache.flink.api.dag.Transformation.getOutputType(Transformation.java:417)</span><br><span class="line">at org.apache.flink.streaming.api.datastream.DataStream.getType(DataStream.java:175)</span><br><span class="line">at org.apache.flink.streaming.api.datastream.DataStream.keyBy(DataStream.java:318)</span><br><span class="line">at com.zhisheng.examples.streaming.socket.LambdaMain.main(LambdaMain.java:41)</span><br><span class="line">Caused by: org.apache.flink.api.common.functions.InvalidTypesException: The generic type parameters of &apos;Collector&apos; are missing. In many cases lambda methods don&apos;t provide enough information for automatic type extraction when Java generics are involved. An easy workaround is to use an (anonymous) class instead that implements the &apos;org.apache.flink.api.common.functions.FlatMapFunction&apos; interface. Otherwise the type has to be specified explicitly using type information.</span><br><span class="line">at org.apache.flink.api.java.typeutils.TypeExtractionUtils.validateLambdaType(TypeExtractionUtils.java:350)</span><br><span class="line">at org.apache.flink.api.java.typeutils.TypeExtractionUtils.extractTypeFromLambda(TypeExtractionUtils.java:176)</span><br><span class="line">at org.apache.flink.api.java.typeutils.TypeExtractor.getUnaryOperatorReturnType(TypeExtractor.java:571)</span><br><span class="line">at org.apache.flink.api.java.typeutils.TypeExtractor.getFlatMapReturnTypes(TypeExtractor.java:196)</span><br><span class="line">at org.apache.flink.streaming.api.datastream.DataStream.flatMap(DataStream.java:611)</span><br><span class="line">at com.zhisheng.examples.streaming.socket.LambdaMain.main(LambdaMain.java:34)</span><br></pre></td></tr></table></figure><p>根据上面的报错信息其实可以知道要怎么解决了，该错误是因为 Flink 在用户自定义的函数中会使用泛型来创建 serializer，当使用匿名函数时，类型信息会被保留。但 Lambda 表达式并不是匿名函数，所以 javac 编译的时候并不会把泛型保存到 class 文件里。解决方法：使用 Flink 提供的 returns 方法来指定 flatMap 的返回类型</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//使用 TupleTypeInfo 来指定 Tuple 的参数类型</span></span><br><span class="line">.returns((TypeInformation) TupleTypeInfo.getBasicTupleTypeInfo(String.class, Integer.class))</span><br></pre></td></tr></table></figure><p>在 flatMap 后面加上上面这个 returns 就行了，但是如果算子多了的话，每个都去加一个 returns，其实会很痛苦的，所以通常使用匿名函数或者自定义函数居多。</p><h3 id="2-4-5-小结与反思"><a href="#2-4-5-小结与反思" class="headerlink" title="2.4.5 小结与反思"></a>2.4.5 小结与反思</h3><p>在第一章中介绍了 Flink 的特性，本章主要是让大家能够快速入门，所以在第一节和第二节中分别讲解了 Flink 的环境准备和搭建，在第三节和第四节中通过两个入门的应用程序（WordCount 应用程序和读取 Socket 数据应用程序）让大家可以快速入门 Flink，两个程序都是需要自己动手实操，所以更能加深大家的印象。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2-4-案例2：实时处理-Socket-数据&quot;&gt;&lt;a href=&quot;#2-4-案例2：实时处理-Socket-数据&quot; class=&quot;headerlink&quot; title=&quot;2.4 案例2：实时处理 Socket 数据&quot;&gt;&lt;/a&gt;2.4 案例2：实时处理 Socket 数据&lt;/h2&gt;&lt;p&gt;在 2.3 节中讲解了 Flink 最简单的 WordCount 程序的创建、运行结果查看和代码分析，本节将继续带大家来看一个入门上手的程序：Flink 处理 Socket 数据。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 案例1：WordCount 应用程序</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/09/flink-in-action-2.3/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/09/flink-in-action-2.3/</id>
    <published>2021-07-08T16:00:00.000Z</published>
    <updated>2021-11-08T15:29:24.442Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-3-案例1：WordCount-应用程序"><a href="#2-3-案例1：WordCount-应用程序" class="headerlink" title="2.3 案例1：WordCount 应用程序"></a>2.3 案例1：WordCount 应用程序</h2><p>在 2.2 节中带大家讲解了下 Flink 的环境安装，这篇文章就开始我们的第一个 Flink 案例实战，也方便大家快速开始自己的第一个 Flink 应用。大数据里学习一门技术一般都是从 WordCount 开始入门的，那么笔者还是不打破常规了，所以这篇文章笔者也将带大家通过 WordCount 程序来初步了解 Flink。</p><a id="more"></a><h3 id="2-3-1-使用-Maven-创建项目"><a href="#2-3-1-使用-Maven-创建项目" class="headerlink" title="2.3.1 使用 Maven 创建项目"></a>2.3.1 使用 Maven 创建项目</h3><p>Flink 支持 Maven 直接构建模版项目，你在终端使用该命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mvn archetype:generate                               \</span><br><span class="line">      -DarchetypeGroupId=org.apache.flink              \</span><br><span class="line">      -DarchetypeArtifactId=flink-quickstart-java      \</span><br><span class="line">      -DarchetypeVersion=1.9.0</span><br></pre></td></tr></table></figure><p>在执行的过程中它会提示你输入 groupId、artifactId、和 package 名，你按照要求输入就行，最后就可以成功创建一个项目，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-151203.png" alt=""></p><p>进入到目录你就可以看到已经创建了项目，里面结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> zhisheng@zhisheng  ~/IdeaProjects/github/Flink-WordCount  tree</span><br><span class="line">.</span><br><span class="line">├── pom.xml</span><br><span class="line">└── src</span><br><span class="line">    └── main</span><br><span class="line">        ├── java</span><br><span class="line">        │   └── com</span><br><span class="line">        │       └── zhisheng</span><br><span class="line">        │           ├── BatchJob.java</span><br><span class="line">        │           └── StreamingJob.java</span><br><span class="line">        └── resources</span><br><span class="line">            └── log4j.properties</span><br><span class="line"></span><br><span class="line">6 directories, 4 files</span><br></pre></td></tr></table></figure><p>该项目中包含了两个类 BatchJob 和 StreamingJob，另外还有一个 log4j.properties 配置文件，然后你就可以将该项目导入到 IDEA 了。你可以在该目录下执行 <code>mvn clean package</code> 就可以编译该项目，编译成功后在 target 目录下会生成一个 Job 的 Jar 包，但是这个 Job 还不能执行，因为 StreamingJob 这个类中的 main 方法里面只是简单的创建了 StreamExecutionEnvironment 环境，然后就执行 execute 方法，这在 Flink 中是不算一个可执行的 Job 的，因此如果你提交到 Flink UI 上也是会报错的。</p><p>如下图所示，上传作业程序打包编译的 Jar 包：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-151434.png" alt=""></p><p>运行报错结果如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-152026.png" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Server Response Message:</span><br><span class="line">Internal server error.</span><br></pre></td></tr></table></figure><p>我们查看 Flink JobManager 的日志，可以看见错误信息如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-152954.png" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2019-04-26 17:27:33,706 ERROR org.apache.flink.runtime.webmonitor.handlers.JarRunHandler    - Unhandled exception.</span><br><span class="line">org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: No operators defined in streaming topology. Cannot execute.</span><br></pre></td></tr></table></figure><p>因为 execute 方法之前我们是需要补充我们 Job 的一些算子操作的，所以报错还是很正常的，本节下面将会提供完整代码。</p><h3 id="2-3-2-使用-IDEA-创建项目"><a href="#2-3-2-使用-IDEA-创建项目" class="headerlink" title="2.3.2 使用 IDEA 创建项目"></a>2.3.2 使用 IDEA 创建项目</h3><p>一般我们项目可能是由多个 Job 组成，并且代码也都是在同一个工程下面进行管理，上面那种创建方式适合单个 Job 执行，但如果在公司多人合作的时候还是得在同一个工程下面创建项目，每个 Flink Job 对应着一个 module，该 module 负责独立的业务逻辑，比如笔者在 GitHub 的 <a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a> 项目，它的项目结构如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-163154.png" alt=""></p><p>接下来我们需要在父工程的 pom.xml 中加入如下属性（含编码、Flink 版本、JDK 版本、Scala 版本、Maven 编译版本）：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--Flink 版本--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.9.0<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--JDK 版本--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--Scala 2.11 版本--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scala.binary.version</span>&gt;</span>2.11<span class="tag">&lt;/<span class="name">scala.binary.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br></pre></td></tr></table></figure><p>然后加入依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Apache Flink dependencies --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- These dependencies are provided, because they should not be packaged into the JAR file. --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Add logging framework, to produce console output when running in the IDE. --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- These dependencies are excluded from the application JAR by default. --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.17<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>上面依赖中 flink-java 和 flink-streaming-java 是我们 Flink 必备的核心依赖，为什么设置 scope 为 provided 呢（默认是 compile）？是因为 Flink 其实在自己的安装目录中 lib 文件夹里的 <code>lib/flink-dist_2.11-1.9.0.jar</code> 已经包含了这些必备的 Jar 了，所以我们在给自己的 Flink Job 添加依赖的时候最后打成的 Jar 包可不希望又将这些重复的依赖打进去。有两个好处：</p><ul><li>减小了我们打的 Flink Job Jar 包容量大小</li><li>不会因为打入不同版本的 Flink 核心依赖而导致类加载冲突等问题</li></ul><p>但是问题又来了，我们需要在 IDEA 中调试运行我们的 Job，如果将 scope 设置为 provided 的话，是会报错的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Error: A JNI error has occurred, please check your installation and try again</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/apache/flink/api/common/ExecutionConfig$GlobalJobParameters</span><br><span class="line">at java.lang.Class.getDeclaredMethods0(Native Method)</span><br><span class="line">at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)</span><br><span class="line">at java.lang.Class.privateGetMethodRecursive(Class.java:3048)</span><br><span class="line">at java.lang.Class.getMethod0(Class.java:3018)</span><br><span class="line">at java.lang.Class.getMethod(Class.java:1784)</span><br><span class="line">at sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544)</span><br><span class="line">at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.flink.api.common.ExecutionConfig$GlobalJobParameters</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:381)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</span><br><span class="line">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:357)</span><br><span class="line">... 7 more</span><br></pre></td></tr></table></figure><p>默认 scope 为 compile 的话，本地调试的话就不会出错了。另外测试到底能够减小多少 Jar 包的大小呢？我这里先写了个 Job 测试。当 scope 为 compile 时，编译后的 target 目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">zhisheng@zhisheng  ~/Flink-WordCount/target   master ●✚  ll</span><br><span class="line">total 94384</span><br><span class="line">-rw-r--r--  1 zhisheng  staff    45M  4 26 21:23 Flink-WordCount-1.0-SNAPSHOT.jar</span><br><span class="line">drwxr-xr-x  4 zhisheng  staff   128B  4 26 21:23 classes</span><br><span class="line">drwxr-xr-x  3 zhisheng  staff    96B  4 26 21:23 generated-sources</span><br><span class="line">drwxr-xr-x  3 zhisheng  staff    96B  4 26 21:23 maven-archiver</span><br><span class="line">drwxr-xr-x  3 zhisheng  staff    96B  4 26 21:23 maven-status</span><br><span class="line">-rw-r--r--  1 zhisheng  staff   7.2K  4 26 21:23 original-Flink-WordCount-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><p>当 scope 为 provided 时，编译后的 target 目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">zhisheng@zhisheng ~/Flink-WordCount/target   master ●✚  ll</span><br><span class="line">total 32</span><br><span class="line">-rw-r--r--  1 zhisheng  staff   7.5K  4 26 21:27 Flink-WordCount-1.0-SNAPSHOT.jar</span><br><span class="line">drwxr-xr-x  4 zhisheng  staff   128B  4 26 21:27 classes</span><br><span class="line">drwxr-xr-x  3 zhisheng  staff    96B  4 26 21:27 generated-sources</span><br><span class="line">drwxr-xr-x  3 zhisheng  staff    96B  4 26 21:27 maven-archiver</span><br><span class="line">drwxr-xr-x  3 zhisheng  staff    96B  4 26 21:27 maven-status</span><br><span class="line">-rw-r--r--  1 zhisheng  staff   7.2K  4 26 21:27 original-Flink-WordCount-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><p>。。。</p><h3 id="2-3-3-流计算-WordCount-应用程序代码实现"><a href="#2-3-3-流计算-WordCount-应用程序代码实现" class="headerlink" title="2.3.3 流计算 WordCount 应用程序代码实现"></a>2.3.3 流计算 WordCount 应用程序代码实现</h3><h3 id="2-3-4-运行流计算-WordCount-应用程序"><a href="#2-3-4-运行流计算-WordCount-应用程序" class="headerlink" title="2.3.4 运行流计算 WordCount 应用程序"></a>2.3.4 运行流计算 WordCount 应用程序</h3><h4 id="本地-IDE-运行"><a href="#本地-IDE-运行" class="headerlink" title="本地 IDE 运行"></a>本地 IDE 运行</h4><h4 id="UI-运行-Job"><a href="#UI-运行-Job" class="headerlink" title="UI 运行 Job"></a>UI 运行 Job</h4><h3 id="2-3-5-流计算-WordCount-应用程序代码分析"><a href="#2-3-5-流计算-WordCount-应用程序代码分析" class="headerlink" title="2.3.5 流计算 WordCount 应用程序代码分析"></a>2.3.5 流计算 WordCount 应用程序代码分析</h3><h3 id="2-3-6-小结与反思"><a href="#2-3-6-小结与反思" class="headerlink" title="2.3.6 小结与反思"></a>2.3.6 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/Z7EAmq3">https://t.zsxq.com/Z7EAmq3</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2-3-案例1：WordCount-应用程序&quot;&gt;&lt;a href=&quot;#2-3-案例1：WordCount-应用程序&quot; class=&quot;headerlink&quot; title=&quot;2.3 案例1：WordCount 应用程序&quot;&gt;&lt;/a&gt;2.3 案例1：WordCount 应用程序&lt;/h2&gt;&lt;p&gt;在 2.2 节中带大家讲解了下 Flink 的环境安装，这篇文章就开始我们的第一个 Flink 案例实战，也方便大家快速开始自己的第一个 Flink 应用。大数据里学习一门技术一般都是从 WordCount 开始入门的，那么笔者还是不打破常规了，所以这篇文章笔者也将带大家通过 WordCount 程序来初步了解 Flink。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 环境搭建</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/08/flink-in-action-2.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/08/flink-in-action-2.2/</id>
    <published>2021-07-07T16:00:00.000Z</published>
    <updated>2021-11-08T15:30:28.152Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-2-Flink-环境搭建"><a href="#2-2-Flink-环境搭建" class="headerlink" title="2.2 Flink 环境搭建"></a>2.2 Flink 环境搭建</h2><a id="more"></a><p>在 2.1 节中已经将 Flink 的准备环境已经讲完了，本章节将带大家正式开始接触 Flink，那么我们得先安装一下 Flink。Flink 是可以在多个平台（Windows、Linux、Mac）上安装的。在开始写本书的时候最新版本是 1.8 版本，但是写到一半后更新到 1.9 了（合并了大量 Blink 的新特性），所以笔者又全部更新版本到 1.9，书籍后面也都是基于最新的版本讲解与演示。</p><p>Flink 的官网地址是：<a href="https://flink.apache.org/">https://flink.apache.org/</a></p><h3 id="2-2-1-Flink-下载与安装"><a href="#2-2-1-Flink-下载与安装" class="headerlink" title="2.2.1 Flink 下载与安装"></a>2.2.1 Flink 下载与安装</h3><p>Flink 在 Mac、Linux、Window 平台上的安装方式如下。</p><h4 id="在-Mac-和-Linux-下安装"><a href="#在-Mac-和-Linux-下安装" class="headerlink" title="在 Mac 和 Linux 下安装"></a>在 Mac 和 Linux 下安装</h4><p>你可以通过该地址 <a href="https://flink.apache.org/downloads.html">https://flink.apache.org/downloads.html</a> 下载到最新版本的 Flink。这里我们选择 <code>Apache Flink 1.9.0 for Scala 2.11</code> 版本，点击跳转到了一个镜像下载选择的地址，如下图所示，随便选择哪个就行，只是下载速度不一致而已。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-080110.png" alt=""></p><p>下载完后，你就可以直接解压下载的 Flink 压缩包了。接下来我们可以启动一下 Flink，我们进入到 Flink 的安装目录下执行命令 <code>./bin/start-cluster.sh</code> 即可，产生的日志如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zhisheng@zhisheng /usr/local/flink-1.9.0  ./bin/start-cluster.sh</span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host zhisheng.</span><br><span class="line">Starting taskexecutor daemon on host zhisheng.</span><br></pre></td></tr></table></figure><p>如果你的电脑是 Mac 的话，那么你也可以通过 Homebrew 命令进行安装。先通过命令 <code>brew search flink</code> 查找一下包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> zhisheng@zhisheng  ~  brew search flink</span><br><span class="line">==&gt; Formulae</span><br><span class="line">apache-flink ✔       homebrew/linuxbrew-core/apache-flink</span><br></pre></td></tr></table></figure><p>可以发现找得到 Flink 的安装包，但是这样安装的版本可能不是最新的，如果你要安装的话，则使用命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install apache-flink</span><br></pre></td></tr></table></figure><p>那么它就会开始进行下载并安装好，安装后的目录应该是在 <code>/usr/local/Cellar/apache-flink</code> 下，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-030606.png" alt=""></p><p>你可以通过下面命令检查安装的 Flink 到底是什么版本的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flink --version</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Version: 1.9.0, Commit ID: ff472b4</span><br></pre></td></tr></table></figure><p>这种的话运行是得进入 <code>/usr/local/Cellar/apache-flink/1.9.0/libexec/bin</code> 目录下执行命令 <code>./start-cluster.sh</code> 才可以启动 Flink 的。执行命令后的启动日志如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host zhisheng.</span><br><span class="line">Starting taskexecutor daemon on host zhisheng.</span><br></pre></td></tr></table></figure><h4 id="在-Windows-下安装"><a href="#在-Windows-下安装" class="headerlink" title="在 Windows 下安装"></a>在 Windows 下安装</h4><p>如果你的电脑系统是 Windows 的话，那么你就直接双击 Flink 安装目录下面 bin 文件夹里面的 <code>start-cluster.bat</code> 就行，同样可以将 Flink 起动成功。</p><h3 id="2-2-2-Flink-启动与运行"><a href="#2-2-2-Flink-启动与运行" class="headerlink" title="2.2.2 Flink 启动与运行"></a>2.2.2 Flink 启动与运行</h3><p>启动成功后的话，我们可以通过访问地址<code>http://localhost:8081/</code> 查看 UI 长啥样了，如下图所示：</p><h3 id="2-2-3-Flink-目录配置文件解读"><a href="#2-2-3-Flink-目录配置文件解读" class="headerlink" title="2.2.3 Flink 目录配置文件解读"></a>2.2.3 Flink 目录配置文件解读</h3><h3 id="2-2-4-Flink-源码下载"><a href="#2-2-4-Flink-源码下载" class="headerlink" title="2.2.4 Flink 源码下载"></a>2.2.4 Flink 源码下载</h3><h3 id="2-2-5-Flink-源码编译"><a href="#2-2-5-Flink-源码编译" class="headerlink" title="2.2.5 Flink 源码编译"></a>2.2.5 Flink 源码编译</h3><h3 id="2-2-6-将-Flink-源码导入到-IDE"><a href="#2-2-6-将-Flink-源码导入到-IDE" class="headerlink" title="2.2.6 将 Flink 源码导入到 IDE"></a>2.2.6 将 Flink 源码导入到 IDE</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/JyRzVnU">https://t.zsxq.com/JyRzVnU</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="2-2-7-小结与反思"><a href="#2-2-7-小结与反思" class="headerlink" title="2.2.7 小结与反思"></a>2.2.7 小结与反思</h3><p>本节主要讲了 FLink 在不同系统下的安装和运行方法，然后讲了下怎么去下载源码和将源码导入到 IDE 中。不知道你在将源码导入到 IDE 中是否有遇到什么问题呢？</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2-2-Flink-环境搭建&quot;&gt;&lt;a href=&quot;#2-2-Flink-环境搭建&quot; class=&quot;headerlink&quot; title=&quot;2.2 Flink 环境搭建&quot;&gt;&lt;/a&gt;2.2 Flink 环境搭建&lt;/h2&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 环境准备</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/07/flink-in-action-2.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/07/flink-in-action-2.1/</id>
    <published>2021-07-06T16:00:00.000Z</published>
    <updated>2021-11-08T15:18:42.241Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第二章-——-Flink-入门"><a href="#第二章-——-Flink-入门" class="headerlink" title="第二章 —— Flink 入门"></a>第二章 —— Flink 入门</h1><p>通过第一章对 Flink 的介绍，相信你对 Flink 的概念和特性有了一定的了解，接下来本章将开始正式进入 Flink 的学习之旅，笔者将带你搭建 Flink 的环境和编写两个案例（WordCount 程序、读取 Socket 数据）来入门 Flink。</p><h2 id="2-1-Flink-环境准备"><a href="#2-1-Flink-环境准备" class="headerlink" title="2.1 Flink 环境准备"></a>2.1 Flink 环境准备</h2><a id="more"></a><p>通过前面的章节内容，相信你已经对 Flink 的基础概念等知识已经有一定了解，现在是不是迫切的想把 Flink 给用起来？先别急，我们先把电脑的准备环境给安装好，这样后面才能更愉快地玩耍。</p><p>废话不多说了，直奔主题。因为本书后面章节内容会使用 Kafka、MySQL、ElasticSearch 等组件，并且运行 Flink 程序是需要依赖 Java 的，另外就是我们需要使用 IDE 来开发 Flink 应用程序以及使用 Maven 来管理 Flink 应用程序的依赖，所以本节我们提前安装这个几个组件，搭建好本地的环境，后面如果还要安装其他的组件笔者会在对应的章节中补充，如果你的操作系统已经中已经安装过 JDK、Maven、MySQL、IDEA 等，那么你可以跳过对应的内容，直接看你未安装过的。</p><p>这里笔者再说下自己电脑的系统环境：macOS High Sierra 10.13.5，后面文章的演示环境不作特别说明的话就是都在这个系统环境中。</p><h3 id="2-1-1-JDK-安装与配置"><a href="#2-1-1-JDK-安装与配置" class="headerlink" title="2.1.1 JDK 安装与配置"></a>2.1.1 JDK 安装与配置</h3><p>虽然现在 JDK 已经更新到 12 了，但是为了稳定我们还是安装 JDK 8，如果没有安装过的话，可以去<a href="https://www.oracle.com/technetwork/java/javase/downloads/index.html">官网</a> 的<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">下载页面</a>下载对应自己操作系统的最新 JDK8 就行。</p><p>Mac 系统的是 <code>jdk-8u211-macosx-x64.dmg</code> 格式、Linux 系统的是 <code>jdk-8u211-linux-x64.tar.gz</code> 格式。Mac 系统安装的话直接双击然后一直按照提示就行了，最后 JDK 的安装目录在 <code>/Library/Java/JavaVirtualMachines/</code> ，然后在 <code>/etc/hosts</code> 中配置好环境变量（注意：替换你自己电脑本地的路径）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_152.jdk/Contents/Home</span><br><span class="line">export CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure><p>Linux 系统的话就是在某个目录下直接解压就行了，然后在 <code>/etc/profile</code> 添加一下上面的环境变量（注意：替换你自己电脑的路径）。然后执行 <code>java -version</code> 命令可以查看是否安装成功！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> zhisheng@zhisheng ~  java -version</span><br><span class="line">java version &quot;1.8.0_152&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_152-b16)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.152-b16, mixed mode)</span><br></pre></td></tr></table></figure><h3 id="2-1-2-Maven-安装与配置"><a href="#2-1-2-Maven-安装与配置" class="headerlink" title="2.1.2 Maven 安装与配置"></a>2.1.2 Maven 安装与配置</h3><p>安装好 JDK 后我们就可以安装 Maven 了，我们在<a href="http://maven.apache.org/download.cgi">官网</a>下载二进制包就行，然后在自己本地软件安装目录解压压缩包就行。接下来你需要配置一下环境变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export M2_HOME=/Users/zhisheng/Documents/maven-3.5.2</span><br><span class="line">export PATH=$PATH:$M2_HOME/bin</span><br></pre></td></tr></table></figure><p>然后执行命令 <code>mvn -v</code> 可以验证是否安装成功，结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">zhisheng@zhisheng ~ /Users  mvn -v</span><br><span class="line">Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)</span><br><span class="line">Maven home: /Users/zhisheng/Documents/maven-3.5.2</span><br><span class="line">Java version: 1.8.0_152, vendor: Oracle Corporation</span><br><span class="line">Java home: /Library/Java/JavaVirtualMachines/jdk1.8.0_152.jdk/Contents/Home/jre</span><br><span class="line">Default locale: zh_CN, platform encoding: UTF-8</span><br><span class="line">OS name: &quot;mac os x&quot;, version: &quot;10.13.5&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;</span><br></pre></td></tr></table></figure><h3 id="2-1-3-IDE-安装与配置"><a href="#2-1-3-IDE-安装与配置" class="headerlink" title="2.1.3 IDE 安装与配置"></a>2.1.3 IDE 安装与配置</h3><p>安装完 JDK 和 Maven 后，就可以安装 IDE 了，大家可以选择你熟练的 IDE 就行，笔者后面演示的代码都是在 IDEA 中运行的，如果想为了后面不出其他的问题的话，建议尽量和笔者的环境保持一致。</p><p>IDEA 官网下载地址：<a href="https://www.jetbrains.com/idea/download/#section=mac">下载页面的地址</a>，下载后可以双击后然后按照提示一步步安装，安装完成后需要在 IDEA 中配置 JDK 路径和 Maven 的路径，后面我们开发也都是靠 Maven 来管理项目的依赖。</p><h3 id="2-1-4-MySQL-安装与配置"><a href="#2-1-4-MySQL-安装与配置" class="headerlink" title="2.1.4 MySQL 安装与配置"></a>2.1.4 MySQL 安装与配置</h3><h3 id="2-1-5-Kafka-安装与配置"><a href="#2-1-5-Kafka-安装与配置" class="headerlink" title="2.1.5 Kafka 安装与配置"></a>2.1.5 Kafka 安装与配置</h3><h3 id="2-1-6-ElasticSearch-安装与配置"><a href="#2-1-6-ElasticSearch-安装与配置" class="headerlink" title="2.1.6 ElasticSearch 安装与配置"></a>2.1.6 ElasticSearch 安装与配置</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/JyRzVnU">https://t.zsxq.com/JyRzVnU</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="2-1-7-小结与反思"><a href="#2-1-7-小结与反思" class="headerlink" title="2.1.7 小结与反思"></a>2.1.7 小结与反思</h3><p>本节讲解了下 JDK、Maven、IDE、MySQL、Kafka、ElasticSearch 的安装与配置，因为这些都是后面要用的，所以这里单独抽一篇文章来讲解环境准备的安装步骤，当然这里还并不涉及全，因为后面我们还可能会涉及到 HBase、HDFS 等知识，后面我们用到再看，本书的内容主要讲解 Flink，所以更多的环境准备还是得靠大家自己独立完成。</p><p>这里笔者说下笔者自己一般安装环境的选择：</p><p>xxx</p><p>下面章节我们就正式进入 Flink 专题了！</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第二章-——-Flink-入门&quot;&gt;&lt;a href=&quot;#第二章-——-Flink-入门&quot; class=&quot;headerlink&quot; title=&quot;第二章 —— Flink 入门&quot;&gt;&lt;/a&gt;第二章 —— Flink 入门&lt;/h1&gt;&lt;p&gt;通过第一章对 Flink 的介绍，相信你对 Flink 的概念和特性有了一定的了解，接下来本章将开始正式进入 Flink 的学习之旅，笔者将带你搭建 Flink 的环境和编写两个案例（WordCount 程序、读取 Socket 数据）来入门 Flink。&lt;/p&gt;
&lt;h2 id=&quot;2-1-Flink-环境准备&quot;&gt;&lt;a href=&quot;#2-1-Flink-环境准备&quot; class=&quot;headerlink&quot; title=&quot;2.1 Flink 环境准备&quot;&gt;&lt;/a&gt;2.1 Flink 环境准备&lt;/h2&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 大数据计算框架对比</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/06/flink-in-action-1.3/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/06/flink-in-action-1.3/</id>
    <published>2021-07-05T16:00:00.000Z</published>
    <updated>2021-11-08T15:14:17.415Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-3-大数据计算框架对比"><a href="#1-3-大数据计算框架对比" class="headerlink" title="1.3 大数据计算框架对比"></a>1.3 大数据计算框架对比</h2><p>在 1.2 节中已经跟大家详细介绍了 Flink，那么在本节就主要 Blink、Spark Streaming、Structured Streaming 和 Storm 的区别。</p><a id="more"></a><h3 id="1-3-1-Flink"><a href="#1-3-1-Flink" class="headerlink" title="1.3.1 Flink"></a>1.3.1 Flink</h3><p>Flink 是一个针对流数据和批数据分布式处理的引擎，在某些对实时性要求非常高的场景，基本上都是采用 Flink 来作为计算引擎，它不仅可以处理有界的批数据，还可以处理无界的流数据，在 Flink 的设计愿想就是将批处理当成是流处理的一种特例。</p><p>如下图所示，在 Flink 的母公司 <a href="https://www.eu-startups.com/2019/01/alibaba-takes-over-berlin-based-streaming-analytics-startup-data-artisans/">Data Artisans 被阿里收购</a>之后，阿里也在开始逐步将内部的 Blink 代码开源出来并合并在 Flink 主分支上。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-01-143012.jpg" alt="阿里巴巴收购 Data Artisans"></p><p>而 Blink 一个很强大的特点就是它的 Table API &amp; SQL 很强大，社区也在 Flink 1.9 版本将 Blink 开源版本大部分代码合进了 Flink 主分支。</p><h3 id="1-3-2-Blink"><a href="#1-3-2-Blink" class="headerlink" title="1.3.2 Blink"></a>1.3.2 Blink</h3><p>Blink 是早期阿里在 Flink 的基础上开始修改和完善后在内部创建的分支，然后 Blink 目前在阿里服务于阿里集团内部搜索、推荐、广告、菜鸟物流等大量核心实时业务，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-01-160059.jpg" alt=""></p><p>Blink 在阿里内部错综复杂的业务场景中锻炼成长着，经历了内部这么多用户的反馈（各种性能、资源使用率、易用性等诸多方面的问题），Blink 都做了针对性的改进。在 Flink Forward China 峰会上，阿里巴巴集团副总裁周靖人宣布 Blink 在 2019 年 1 月正式开源，同时阿里也希望 Blink 开源后能进一步加深与 Flink 社区的联动，</p><p>Blink 开源地址：<a href="https://github.com/apache/flink/tree/blink">https://github.com/apache/flink/tree/blink</a></p><p>开源版本 Blink 的主要功能和优化点：</p><p>1、Runtime 层引入 Pluggable Shuffle Architecture，开发者可以根据不同的计算模型或者新硬件的需要实现不同的 shuffle 策略进行适配；为了性能优化，Blink 可以让算子更加灵活的 chain 在一起，避免了不必要的数据传输开销；在 BroadCast Shuffle 模式中，Blink 优化掉了大量的不必要的序列化和反序列化开销；Blink 提供了全新的 JM FailOver 机制，JM 发生错误之后，新的 JM 会重新接管整个 JOB 而不是重启 JOB，从而大大减少了 JM FailOver 对 JOB 的影响；Blink 支持运行在 Kubernetes 上。</p><p>2、SQL/Table API 架构上的重构和性能的优化是 Blink 开源版本的一个重大贡献。</p><p>3、Hive 的兼容性，可以直接用 Flink SQL 去查询 Hive 的数据，Blink 重构了 Flink catalog 的实现，并且增加了两种 catalog，一个是基于内存存储的 FlinkInMemoryCatalog，另外一个是能够桥接 Hive metaStore 的 HiveCatalog。</p><p>4、Zeppelin for Flink</p><p>5、Flink Web，更美观的 UI 界面，查看日志和监控 Job 都变得更加方便</p><p>对于开源那会看到一个对话让笔者感到很震撼：</p><blockquote><p>Blink 开源后，两个开源项目之间的关系会是怎样的？未来 Flink 和 Blink 也会由不同的团队各自维护吗？</p><p>Blink 永远不会成为另外一个项目，如果后续进入 Apache 一定是成为 Flink 的一部分</p></blockquote><p>对话详情如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-01-162836.jpg" alt=""></p><p>在 Blink 开源那会，笔者就将源码自己编译了一份，然后自己在本地一直运行着，感兴趣的可以看看文章 <a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a> ，你会发现 Blink 的 UI 还是比较美观和实用的。</p><p>如果你还对 Blink 有什么疑问，可以看看下面两篇文章：</p><p><a href="https://www.infoq.cn/article/wZ_b7Hw9polQWp3mTwVh">阿里重磅开源 Blink：为什么我们等了这么久？</a></p><p><a href="https://www.infoq.cn/article/ZkOGAl6_vkZDTk8tfbbg">重磅！阿里巴巴 Blink 正式开源，重要优化点解读</a></p><h3 id="1-3-3-Spark"><a href="#1-3-3-Spark" class="headerlink" title="1.3.3 Spark"></a>1.3.3 Spark</h3><p>Apache Spark 是一种包含流处理能力的下一代批处理框架。与 Hadoop 的 MapReduce 引擎基于各种相同原则开发而来的 Spark 主要侧重于通过完善的内存计算和处理优化机制加快批处理工作负载的运行速度。Spark 可作为独立集群部署（需要相应存储层的配合），或可与 Hadoop 集成并取代 MapReduce 引擎。</p><p><a href="https://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a> 是 Spark API 核心的扩展，可实现实时数据的快速扩展，高吞吐量，容错处理。数据可以从很多来源（如 Kafka、Flume、Kinesis 等）中提取，并且可以通过很多函数来处理这些数据，处理完后的数据可以直接存入数据库或者 Dashboard 等，如下两图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-06-154210.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-06-134257.jpg" alt=""></p><p><strong>Spark Streaming 的内部实现原理</strong>是接收实时输入数据流并将数据分成批处理，然后由 Spark 引擎处理以批量生成最终结果流，也就是常说的 micro-batch 模式，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-06-134430.jpg" alt=""></p><p><strong>Spark DStreams</strong></p><p>DStreams 是 Spark Streaming 提供的基本的抽象，它代表一个连续的数据流。它要么是从源中获取的输入流，要么是输入流通过转换算子生成的处理后的数据流。在内部实现上，DStream 由连续的序列化 RDD 来表示，每个 RDD 含有一段时间间隔内的数据，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-06-140956.jpg" alt=""></p><p>任何对 DStreams 的操作都转换成了对 DStreams 隐含的 RDD 的操作。例如 flatMap 操作应用于 lines 这个 DStreams 的每个 RDD，生成 words 这个 DStreams 的 RDD 过程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-06-134718.jpg" alt=""></p><p>通过 Spark 引擎计算这些隐含 RDD 的转换算子。DStreams 操作隐藏了大部分的细节，并且为了更便捷，为开发者提供了更高层的 API。</p><p><strong>Spark 支持的滑动窗口</strong></p><p>它和 Flink 的滑动窗口类似，支持传入两个参数，一个代表窗口长度，一个代表滑动间隔，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-06-134915.jpg" alt=""></p><p><strong>Spark 支持更多的 API</strong></p><p>因为 Spark 是使用 Scala 开发的居多，所以从官方文档就可以看得到对 Scala 的 API 支持的很好，而 Flink 源码实现主要以 Java 为主，因此也对 Java API 更友好，从两者目前支持的 API 友好程度，应该是 Spark 更好，它目前也支持 Python API，但是 Flink 新版本也在不断的支持 Python API。</p><p><strong>Spark 支持更多的 Machine Learning Lib</strong></p><p>你可以很轻松的使用 Spark MLlib 提供的机器学习算法，然后将这些这些机器学习算法模型应用在流数据中，目前 Flink Machine Learning 这块的内容还较少，不过阿里宣称会开源些 Flink Machine Learning 算法，保持和 Spark 目前已有的算法一致，我自己在 GitHub 上看到一个阿里开源的仓库，感兴趣的可以看看 <a href="https://github.com/alibaba/flink-ai-extended">flink-ai-extended</a>。</p><p><strong>Spark Checkpoint</strong></p><p>Spark 和 Flink 一样都支持 Checkpoint，但是 Flink 还支持 Savepoint，你可以在停止 Flink 作业的时候使用 Savepoint 将作业的状态保存下来，当作业重启的时候再从 Savepoint 中将停止作业那个时刻的状态恢复起来，保持作业的状态和之前一致。</p><p><strong>Spark SQL</strong></p><p>Spark 除了 DataFrames 和 Datasets 外，也还有 SQL API，这样你就可以通过 SQL 查询数据，另外 Spark SQL 还可以用于从 Hive 中读取数据。</p><p>从 Spark 官网也可以看到很多比较好的特性，这里就不一一介绍了，如果对 Spark 感兴趣的话也可以去<a href="https://spark.apache.org/docs/latest/index.html">官网</a>了解一下具体的使用方法和实现原理。</p><p><strong>Spark Streaming 优缺点</strong></p><p>1、优点</p><ul><li>Spark Streaming 内部的实现和调度方式高度依赖 Spark 的 DAG 调度器和 RDD，这就决定了 Spark Streaming 的设计初衷必须是粗粒度方式的，也就无法做到真正的实时处理</li><li>Spark Streaming 的粗粒度执行方式使其确保“处理且仅处理一次”的特性，同时也可以更方便地实现容错恢复机制。</li><li>由于 Spark Streaming 的 DStream 本质是 RDD 在流式数据上的抽象，因此基于 RDD 的各种操作也有相应的基于 DStream 的版本，这样就大大降低了用户对于新框架的学习成本，在了解 Spark 的情况下用户将很容易使用 Spark Streaming。</li></ul><p>2、缺点</p><ul><li>Spark Streaming 的粗粒度处理方式也造成了不可避免的数据延迟。在细粒度处理方式下，理想情况下每一条记录都会被实时处理，而在 Spark Streaming 中，数据需要汇总到一定的量后再一次性处理，这就增加了数据处理的延迟，这种延迟是由框架的设计引入的，并不是由网络或其他情况造成的。</li><li>使用的是 Processing Time 而不是 Event Time</li></ul><h3 id="1-3-4-Structured-Streaming"><a href="#1-3-4-Structured-Streaming" class="headerlink" title="1.3.4 Structured Streaming"></a>1.3.4 Structured Streaming</h3><h3 id="1-3-5-Storm"><a href="#1-3-5-Storm" class="headerlink" title="1.3.5 Storm"></a>1.3.5 Storm</h3><h4 id="Storm-核心组件"><a href="#Storm-核心组件" class="headerlink" title="Storm 核心组件"></a>Storm 核心组件</h4><h4 id="Storm-核心概念"><a href="#Storm-核心概念" class="headerlink" title="Storm 核心概念"></a>Storm 核心概念</h4><h4 id="Storm-数据处理流程图"><a href="#Storm-数据处理流程图" class="headerlink" title="Storm 数据处理流程图"></a>Storm 数据处理流程图</h4><h3 id="1-3-6-计算框架对比"><a href="#1-3-6-计算框架对比" class="headerlink" title="1.3.6 计算框架对比"></a>1.3.6 计算框架对比</h3><h4 id="Flink-VS-Spark"><a href="#Flink-VS-Spark" class="headerlink" title="Flink VS Spark"></a>Flink VS Spark</h4><h4 id="Flink-VS-Storm"><a href="#Flink-VS-Storm" class="headerlink" title="Flink VS Storm"></a>Flink VS Storm</h4><h4 id="全部对比结果"><a href="#全部对比结果" class="headerlink" title="全部对比结果"></a>全部对比结果</h4><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/vVjeMBY">https://t.zsxq.com/vVjeMBY</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="1-3-7-小结与反思"><a href="#1-3-7-小结与反思" class="headerlink" title="1.3.7 小结与反思"></a>1.3.7 小结与反思</h3><p>因在 1.2 节中已经对 Flink 的特性做了很详细的讲解，所以本节主要介绍其他几种计算框架（Blink、Spark、Spark Streaming、Structured Streaming、Storm），并对比分析了这几种框架的特点与不同。你对这几种计算框架中的哪个最熟悉呢？了解过它们之间的差异吗？你有压测过它们的处理数据的性能吗？</p><p>本章第一节从公司的日常实时计算需求出发，来分析该如何去实现这种实时需求，接着对比了实时计算与离线计算的区别，从而引出了实时计算的优势，接着就在第二节开始介绍本书的重点 —— 实时计算引擎 Flink，把 Flink 的架构、API、特点、优势等方面都做了讲解，在第三节中对比了市面上现有的计算框架，分别对这些框架做了异同点对比，最后还汇总了它们在各个方面的优势和劣势，以供大家公司内部的技术选型。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-3-大数据计算框架对比&quot;&gt;&lt;a href=&quot;#1-3-大数据计算框架对比&quot; class=&quot;headerlink&quot; title=&quot;1.3 大数据计算框架对比&quot;&gt;&lt;/a&gt;1.3 大数据计算框架对比&lt;/h2&gt;&lt;p&gt;在 1.2 节中已经跟大家详细介绍了 Flink，那么在本节就主要 Blink、Spark Streaming、Structured Streaming 和 Storm 的区别。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 彻底了解大数据实时计算框架 Flink</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/05/flink-in-action-1.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/05/flink-in-action-1.2/</id>
    <published>2021-07-04T16:00:00.000Z</published>
    <updated>2021-10-27T14:02:00.366Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-2-彻底了解大数据实时计算框架-Flink"><a href="#1-2-彻底了解大数据实时计算框架-Flink" class="headerlink" title="1.2 彻底了解大数据实时计算框架 Flink"></a>1.2 彻底了解大数据实时计算框架 Flink</h2><p>在 1.1 节中讲解了日常开发常见的实时需求，然后分析了这些需求的实现方式，接着对比了实时计算和离线计算。随着这些年大数据的飞速发展，也出现了不少计算的框架（Hadoop、Storm、Spark、Flink）。在网上有人将大数据计算引擎的发展分为四个阶段。</p><a id="more"></a><ul><li>第一代：Hadoop 承载的 MapReduce</li><li>第二代：支持 DAG（有向无环图）框架的计算引擎 Tez 和 Oozie，主要还是批处理任务</li><li>第三代：支持 Job 内部的 DAG（有向无环图），以 Spark 为代表</li><li>第四代：大数据统一计算引擎，包括流处理、批处理、AI、Machine Learning、图计算等，以 Flink 为代表</li></ul><p>或许会有人不同意以上的分类，笔者觉得其实这并不重要的，重要的是体会各个框架的差异，以及更适合的场景。并进行理解，没有哪一个框架可以完美的支持所有的场景，也就不可能有任何一个框架能完全取代另一个。</p><p>本文将对 Flink 的整体架构和 Flink 的多种特性做个详细的介绍！在讲 Flink 之前的话，我们先来看看 <strong>数据集类型</strong> 和 <strong>数据运算模型</strong> 的种类。</p><h4 id="数据集类型"><a href="#数据集类型" class="headerlink" title="数据集类型"></a>数据集类型</h4><p>数据集类型有分无穷和有界数据集：</p><ul><li>无穷数据集：无穷的持续集成的数据集合</li><li>有界数据集：有限不会改变的数据集合</li></ul><p>那么那些常见的无穷数据集有哪些呢？</p><ul><li>用户与客户端的实时交互数据</li><li>应用实时产生的日志</li><li>金融市场的实时交易记录</li><li>…</li></ul><h4 id="数据运算模型"><a href="#数据运算模型" class="headerlink" title="数据运算模型"></a>数据运算模型</h4><p>数据运算模型有分流式处理和批处理：</p><ul><li>流式：只要数据一直在产生，计算就持续地进行</li><li>批处理：在预先定义的时间内运行计算，当计算完成时释放计算机资源</li></ul><p>那么我们再来看看 Flink 它是什么呢？</p><h3 id="1-2-1-Flink-简介"><a href="#1-2-1-Flink-简介" class="headerlink" title="1.2.1 Flink 简介"></a>1.2.1 Flink 简介</h3><p>Flink 是一个针对流数据和批数据的分布式处理引擎，代码主要是由 Java 实现，部分代码是 Scala。它可以处理有界的批量数据集、也可以处理无界的实时数据集，总结如下图所示。对 Flink 而言，其所要处理的主要场景就是流数据，批数据只是流数据的一个极限特例而已，所以 Flink 也是一款真正的流批统一的计算引擎。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/pRMhfm.jpg" alt=""></p><p>如下图所示，Flink 提供了 State、Checkpoint、Time、Window 等，它们为 Flink 提供了基石，本篇文章下面会稍作讲解，具体深度分析后面会有专门的文章来讲解。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/vY6T3M.jpg" alt=""></p><h3 id="1-2-2-Flink-整体架构"><a href="#1-2-2-Flink-整体架构" class="headerlink" title="1.2.2 Flink 整体架构"></a>1.2.2 Flink 整体架构</h3><p>Flink 整体架构从下至上分为：</p><ol><li><p>部署：Flink 支持本地运行（IDE 中直接运行程序）、能在独立集群（Standalone 模式）或者在被 YARN、Mesos、K8s 管理的集群上运行，也能部署在云上。</p></li><li><p>运行：Flink 的核心是分布式流式数据引擎，意味着数据以一次一个事件的形式被处理。</p></li><li><p>API：DataStream、DataSet、Table API &amp; SQL。</p></li><li><p>扩展库：Flink 还包括用于 CEP（复杂事件处理）、机器学习、图形处理等场景。</p></li></ol><p>整体架构如下图所示：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/Drsi9h.jpg" alt=""></p><h3 id="1-2-3-Flink-的多种方式部署"><a href="#1-2-3-Flink-的多种方式部署" class="headerlink" title="1.2.3 Flink 的多种方式部署"></a>1.2.3 Flink 的多种方式部署</h3><p>作为一个计算引擎，如果要做的足够完善，除了它自身的各种特点要包含，还得支持各种生态圈，比如部署的情况，Flink 是支持以 Standalone、YARN、Kubernetes、Mesos 等形式部署的，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-034112.png" alt=""></p><p>每种部署方式介绍如下：</p><ul><li><p>Local：直接在 IDE 中运行 Flink Job 时则会在本地启动一个 mini Flink 集群。</p></li><li><p>Standalone：在 Flink 目录下执行 <code>bin/start-cluster.sh</code> 脚本则会启动一个 Standalone 模式的集群。</p></li><li><p>YARN：YARN 是 Hadoop 集群的资源管理系统，它可以在群集上运行各种分布式应用程序，Flink 可与其他应用并行于 YARN 中，Flink on YARN 的架构如下图所示。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-034029.png" alt=""></p><ul><li>Kubernetes：Kubernetes 是 Google 开源的容器集群管理系统，在 Docker 技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性，Flink 也支持部署在 Kubernetes 上，在 <a href="https://github.com/Aleksandr-Filichkin/flink-k8s/blob/master/flow.jpg">GitHub</a> 看到有下面这种运行架构的。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-05-19-071249.jpg" alt=""></p><p>通常上面四种居多，另外还支持 AWS、MapR、Aliyun OSS 等。</p><h3 id="1-2-4-Flink-分布式运行流程"><a href="#1-2-4-Flink-分布式运行流程" class="headerlink" title="1.2.4 Flink 分布式运行流程"></a>1.2.4 Flink 分布式运行流程</h3><p>Flink 作业提交架构流程如下图所示：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/p92UrK.jpg" alt=""></p><p>具体流程介绍如下：</p><ol><li><p>Program Code：我们编写的 Flink 应用程序代码</p></li><li><p>Job Client：Job Client 不是 Flink 程序执行的内部部分，但它是任务执行的起点。 Job Client 负责接受用户的程序代码，然后创建数据流，将数据流提交给 JobManager 以便进一步执行。 执行完成后，Job Client 将结果返回给用户</p></li><li><p>JobManager：主进程（也称为作业管理器）协调和管理程序的执行。 它的主要职责包括安排任务，管理 Checkpoint ，故障恢复等。机器集群中至少要有一个 master，master 负责调度 task，协调 Checkpoints 和容灾，高可用设置的话可以有多个 master，但要保证一个是 leader, 其他是 standby; JobManager 包含 Actor system、Scheduler、Check pointing 三个重要的组件</p></li><li><p>TaskManager：从 JobManager 处接收需要部署的 Task。TaskManager 是在 JVM 中的一个或多个线程中执行任务的工作节点。 任务执行的并行性由每个 TaskManager 上可用的任务槽（Slot 个数）决定。 每个任务代表分配给任务槽的一组资源。 例如，如果 TaskManager 有四个插槽，那么它将为每个插槽分配 25％ 的内存。 可以在任务槽中运行一个或多个线程。 同一插槽中的线程共享相同的 JVM。<br>同一 JVM 中的任务共享 TCP 连接和心跳消息。TaskManager 的一个 Slot 代表一个可用线程，该线程具有固定的内存，注意 Slot 只对内存隔离，没有对 CPU 隔离。默认情况下，Flink 允许子任务共享 Slot，即使它们是不同 task 的 subtask，只要它们来自相同的 job。这种共享可以有更好的资源利用率。</p></li></ol><h3 id="1-2-5-Flink-API"><a href="#1-2-5-Flink-API" class="headerlink" title="1.2.5 Flink API"></a>1.2.5 Flink API</h3><p>Flink 提供了不同的抽象级别的 API 以开发流式或批处理应用，如下图所示。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/ozmU46.jpg" alt=""></p><p>这四种 API 功能分别是：</p><ul><li><p>最底层提供了有状态流。它将通过 Process Function 嵌入到 DataStream API 中。它允许用户可以自由地处理来自一个或多个流数据的事件，并使用一致性、容错的状态。除此之外，用户可以注册事件时间和处理事件回调，从而使程序可以实现复杂的计算。</p></li><li><p>DataStream / DataSet API 是 Flink 提供的核心 API ，DataSet 处理有界的数据集，DataStream 处理有界或者无界的数据流。用户可以通过各种方法（map / flatmap / window / keyby / sum / max / min / avg / join 等）将数据进行转换或者计算。</p></li><li><p>Table API 是以表为中心的声明式 DSL，其中表可能会动态变化（在表达流数据时）。Table API 提供了例如 select、project、join、group-by、aggregate 等操作，使用起来却更加简洁（代码量更少）。<br>你可以在表与 DataStream/DataSet 之间无缝切换，也允许程序将 Table API 与 DataStream 以及 DataSet 混合使用。</p></li><li><p>Flink 提供的最高层级的抽象是 SQL 。这一层抽象在语法与表达能力上与 Table API 类似，但是是以 SQL查询表达式的形式表现程序。SQL 抽象与 Table API 交互密切，同时 SQL 查询可以直接在 Table API 定义的表上执行。</p></li></ul><p>Flink 除了 DataStream 和 DataSet API，它还支持 Table API &amp; SQL，Flink 也将通过 SQL 来构建统一的大数据流批处理引擎，因为在公司中通常会有那种每天定时生成报表的需求（批处理的场景，每晚定时跑一遍昨天的数据生成一个结果报表），但是也是会有流处理的场景（比如采用 Flink 来做实时性要求很高的需求），于是慢慢的整个公司的技术选型就变得越来越多了，这样开发人员也就要面临着学习两套不一样的技术框架，运维人员也需要对两种不一样的框架进行环境搭建和作业部署，平时还要维护作业的稳定性。当我们的系统变得越来越复杂了，作业越来越多了，这对于开发人员和运维来说简直就是噩梦，没准哪天凌晨晚上就被生产环境的告警电话给叫醒。所以 Flink 系统能通过 SQL API 来解决批流统一的痛点，这样不管是开发还是运维，他们只需要关注一个计算框架就行，从而减少企业的用人成本和后期开发运维成本。</p><h3 id="1-2-6-Flink-程序与数据流结构"><a href="#1-2-6-Flink-程序与数据流结构" class="headerlink" title="1.2.6 Flink 程序与数据流结构"></a>1.2.6 Flink 程序与数据流结构</h3><p>一个完整的 Flink 应用程序结构如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-14-141653.png" alt=""></p><p>它们的功能分别是：</p><ul><li>Source：数据输入，Flink 在流处理和批处理上的 source 大概有 4 类：基于本地集合的 source、基于文件的 source、基于网络套接字的 source、自定义的 source。自定义的 source 常见的有 Apache kafka、Amazon Kinesis Streams、RabbitMQ、Twitter Streaming API、Apache NiFi 等，当然你也可以定义自己的 source。</li><li>Transformation：数据转换的各种操作，有 Map / FlatMap / Filter / KeyBy / Reduce / Fold / Aggregations / Window / WindowAll / Union / Window join / Split / Select / Project 等，操作很多，可以将数据转换计算成你想要的数据。</li><li>Sink：数据输出，Flink 将转换计算后的数据发送的地点 ，你可能需要存储下来，Flink 常见的 Sink 大概有如下几类：写入文件、打印出来、写入 socket 、自定义的 sink 。自定义的 sink 常见的有 Apache kafka、RabbitMQ、MySQL、ElasticSearch、Apache Cassandra、Hadoop FileSystem 等，同理你也可以定义自己的 sink。</li></ul><p>代码结构如下图所示：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/u3RagR.jpg" alt=""></p><h3 id="1-2-7-丰富的-Connector"><a href="#1-2-7-丰富的-Connector" class="headerlink" title="1.2.7 丰富的 Connector"></a>1.2.7 丰富的 Connector</h3><p>通过源码可以发现不同版本的 Kafka、不同版本的 ElasticSearch、Cassandra、HBase、Hive、HDFS、RabbitMQ 都是支持的，除了流应用的 Connector 是支持的，另外还支持 SQL，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-10-101956.png" alt=""></p><p>再就是要考虑计算的数据来源和数据最终存储，因为 Flink 在大数据领域的的定位就是实时计算，它不做存储（虽然 Flink 中也有 State 去存储状态数据，这里说的存储类似于 MySQL、ElasticSearch 等存储），所以在计算的时候其实你需要考虑的是数据源来自哪里，计算后的结果又存储到哪里去。庆幸的是 Flink 目前已经支持大部分常用的组件了，比如在 Flink 中已经支持了如下这些 Connector：</p><ul><li>不同版本的 Kafka</li><li>不同版本的 ElasticSearch</li><li>Redis</li><li>MySQL</li><li>Cassandra</li><li>RabbitMQ</li><li>HBase</li><li>HDFS</li><li>…</li></ul><p>这些 Connector 除了支持流作业外，目前还有还有支持 SQL 作业的，除了这些自带的 Connector 外，还可以通过 Flink 提供的接口做自定义 Source 和 Sink（在 3.8 节中）。</p><h3 id="1-2-8-事件时间-amp-处理时间语义"><a href="#1-2-8-事件时间-amp-处理时间语义" class="headerlink" title="1.2.8 事件时间&amp;处理时间语义"></a>1.2.8 事件时间&amp;处理时间语义</h3><p>Flink 支持多种 Time，比如 Event time、Ingestion Time、Processing Time，如下图所示，后面 3.1 节中会很详细的讲解 Flink 中 Time 的概念。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-14-140502.png" alt=""></p><h3 id="1-2-9-灵活的窗口机制"><a href="#1-2-9-灵活的窗口机制" class="headerlink" title="1.2.9 灵活的窗口机制"></a>1.2.9 灵活的窗口机制</h3><p>Flink 支持多种 Window，比如 Time Window、Count Window、Session Window，还支持自定义 Window，如下图所示。后面 3.2 节中会很详细的讲解 Flink 中 Window 的概念。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-034900.png" alt=""></p><h3 id="1-2-10-并行执行任务机制"><a href="#1-2-10-并行执行任务机制" class="headerlink" title="1.2.10 并行执行任务机制"></a>1.2.10 并行执行任务机制</h3><p>Flink 的程序内在是并行和分布式的，数据流可以被分区成 stream partitions，operators 被划分为 operator subtasks; 这些 subtasks 在不同的机器或容器中分不同的线程独立运行；operator subtasks 的数量在具体的 operator 就是并行计算数，程序不同的 operator 阶段可能有不同的并行数；如下图所示，source operator 的并行数为 2，但最后的 sink operator 为 1：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/ggMHCK.jpg" alt=""></p><h3 id="1-2-11-状态存储和容错"><a href="#1-2-11-状态存储和容错" class="headerlink" title="1.2.11 状态存储和容错"></a>1.2.11 状态存储和容错</h3><p>Flink 是一款有状态的流处理框架，它提供了丰富的状态访问接口，按照数据的划分方式，可以分为 Keyed State 和 Operator State，在 Keyed State 中又提供了多种数据结构：</p><ul><li>ValueState</li><li>MapState</li><li>ListState</li><li>ReducingState</li><li>AggregatingState</li></ul><p>另外状态存储也支持多种方式：</p><ul><li>MemoryStateBackend：存储在内存中</li><li>FsStateBackend：存储在文件中</li><li>RocksDBStateBackend：存储在 RocksDB 中</li></ul><p>Flink 中支持使用 Checkpoint 来提高程序的可靠性，开启了 Checkpoint 之后，Flink 会按照一定的时间间隔对程序的运行状态进行备份，当发生故障时，Flink 会将所有任务的状态恢复至最后一次发生 Checkpoint 中的状态，并从那里开始重新开始执行。另外 Flink 还支持根据 Savepoint 从已停止作业的运行状态进行恢复，这种方式需要通过命令进行触发。</p><h3 id="1-2-12-自己的内存管理机制"><a href="#1-2-12-自己的内存管理机制" class="headerlink" title="1.2.12 自己的内存管理机制"></a>1.2.12 自己的内存管理机制</h3><p>Flink 并不是直接把对象存放在堆内存上，而是将对象序列化为固定数量的预先分配的内存段。它采用类似 DBMS 的排序和连接算法，可以直接操作二进制数据，以此将序列化和反序列化开销降到最低。如果需要处理的数据容量超过内存，那么 Flink 的运算符会将部分数据存储到磁盘。Flink 的主动内存管理和操作二进制数据有几个好处：</p><ul><li>保证内存可控，可以防止 OutOfMemoryError</li><li>减少垃圾收集压力</li><li>节省数据的存储空间</li><li>高效的二进制操作</li></ul><p>Flink 是如何分配内存、将对象进行序列化和反序列化以及对二进制数据进行操作的，可以参考文章 <a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 是如何管理好内存的？</a> ，该文中讲解了 Flink 的内存管理机制。</p><h3 id="1-2-13-多种扩展库"><a href="#1-2-13-多种扩展库" class="headerlink" title="1.2.13 多种扩展库"></a>1.2.13 多种扩展库</h3><p>Flink 扩展库中含有机器学习、Gelly 图形处理、CEP 复杂事件处理、State Processing API 等，这些扩展库在一些特殊场景下会比较适用，关于这块内容可以在第六章查看。</p><h3 id="1-2-14-小结与反思"><a href="#1-2-14-小结与反思" class="headerlink" title="1.2.14 小结与反思"></a>1.2.14 小结与反思</h3><p>本节在开始介绍 Flink 之前先讲解了下数据集类型和数据运算模型，接着开始介绍 Flink 的各种特性，对于这些特性，你是否有和其他的计算框架做过对比？</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-2-彻底了解大数据实时计算框架-Flink&quot;&gt;&lt;a href=&quot;#1-2-彻底了解大数据实时计算框架-Flink&quot; class=&quot;headerlink&quot; title=&quot;1.2 彻底了解大数据实时计算框架 Flink&quot;&gt;&lt;/a&gt;1.2 彻底了解大数据实时计算框架 Flink&lt;/h2&gt;&lt;p&gt;在 1.1 节中讲解了日常开发常见的实时需求，然后分析了这些需求的实现方式，接着对比了实时计算和离线计算。随着这些年大数据的飞速发展，也出现了不少计算的框架（Hadoop、Storm、Spark、Flink）。在网上有人将大数据计算引擎的发展分为四个阶段。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》——你的公司是否需要引入实时计算引擎？</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/04/flink-in-action-1.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/04/flink-in-action-1.1/</id>
    <published>2021-07-03T16:00:00.000Z</published>
    <updated>2021-10-27T14:09:11.799Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第一章-——-实时计算引擎"><a href="#第一章-——-实时计算引擎" class="headerlink" title="第一章 —— 实时计算引擎"></a>第一章 —— 实时计算引擎</h1><p>本章会从公司常见的计算需求去分析该如何实现这些需求，接着会对比分析实时计算与离线计算之间的区别，从而帮大家分析公司是否需要引入实时计算引擎。接着将会详细的介绍目前最火的实时计算引擎 Flink 的特性，让大家知道其优点，最后会对比其他的计算框架，比如 Spark、Storm 等，希望可以从对比结果来分析这几种计算框架的各自优势，从而为你做技术选型提供一点帮助。</p><h2 id="1-1-你的公司是否需要引入实时计算引擎"><a href="#1-1-你的公司是否需要引入实时计算引擎" class="headerlink" title="1.1 你的公司是否需要引入实时计算引擎"></a>1.1 你的公司是否需要引入实时计算引擎</h2><a id="more"></a><p>大数据发展至今，数据呈指数倍的增长，对实效性的要求也越来越高，所以你可能接触到的实时计算需求会越来越多。本章节将从实时计算需求开始讲起，然后阐述完成该需求需要做的工作，最后对比实时计算与离线计算。</p><h3 id="1-1-1-实时计算需求"><a href="#1-1-1-实时计算需求" class="headerlink" title="1.1.1 实时计算需求"></a>1.1.1 实时计算需求</h3><p>在公司里面，你可能会收到领导、产品经理或者运营等提出的如下需求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">小田，你看能不能做个监控大屏实时查看促销活动商品总销售额（GMV）？</span><br><span class="line"></span><br><span class="line">小朱，搞促销活动的时候能不能实时统计下网站的 PV/UV 啊？</span><br><span class="line"></span><br><span class="line">小鹏，我们现在搞促销活动能不能实时统计销量 Top5 商品啊？</span><br><span class="line"></span><br><span class="line">小李，怎么回事啊？现在搞促销活动结果服务器宕机了都没告警，能不能加一个？</span><br><span class="line"></span><br><span class="line">小刘，服务器这会好卡，是不是出了什么问题啊，你看能不能做个监控大屏实时查看机器的运行情况？</span><br><span class="line"></span><br><span class="line">小赵，我们线上的应用频繁出现 Error 日志，但是只有靠人肉上机器查看才知道情况，能不能在出现错误的时候及时告警通知？</span><br><span class="line"></span><br><span class="line">小夏，我们 1 元秒杀促销活动中有件商品被某个用户薅了 100 件，怎么都没有风控啊？</span><br><span class="line"></span><br><span class="line">小宋，你看我们搞促销活动能不能根据每个顾客的浏览记录实时推荐不同的商品啊？</span><br><span class="line"></span><br><span class="line">……</span><br></pre></td></tr></table></figure><p>那上面这些需求分别对应着什么业务场景呢？我们来总结下，大概如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-071828.png" alt=""></p><p>初看这些需求，你是不是感觉实现会比较难？那么接下来我们来分析一下该如何实现这些需求？从这些需求来看，最根本的业务都是需要<strong>实时查看数据信息</strong>，那么首先我们得想想如何实时去采集数据，然后将采集到的数据进行实时的计算，最后将计算后的结果下发到第三方。从采集到计算再到下发计算结果的整个过程，必须都得是实时的，这样我们看到的数据才是最接近实时的，这样才能够很完美的完成上面的这些实时计算需求。</p><h3 id="1-1-2-数据实时采集"><a href="#1-1-2-数据实时采集" class="headerlink" title="1.1.2 数据实时采集"></a>1.1.2 数据实时采集</h3><p>就上面这些需求，我们知道了需要实时去采集数据，但是针对这些需求，我们到底需要采集些什么数据呢？如下就是我们需要采集的数据：</p><ul><li>用户搜索信息</li><li>用户浏览商品信息</li><li>用户下单订单信息</li><li>网站的所有浏览记录</li><li>机器 CPU/Mem/IO 信息</li><li>应用日志信息</li></ul><h3 id="1-1-3-数据实时计算"><a href="#1-1-3-数据实时计算" class="headerlink" title="1.1.3 数据实时计算"></a>1.1.3 数据实时计算</h3><p>采集后的数据实时上报后，需要做实时的计算，那我们怎么实现计算呢？</p><ul><li>计算所有商品的总销售额</li><li>统计单个商品的销量，最后求 Top5</li><li>关联用户信息和浏览信息、下单信息</li><li>统计网站所有的请求 IP 并统计每个 IP 的请求数量</li><li>计算一分钟内机器 CPU/Mem/IO 的平均值、75 分位数值</li><li>过滤出 Error 级别的日志信息</li></ul><h3 id="1-1-4-数据实时下发"><a href="#1-1-4-数据实时下发" class="headerlink" title="1.1.4 数据实时下发"></a>1.1.4 数据实时下发</h3><p>实时计算后的数据，需要及时的下发到下游，这里说的下游代表可能是告警方式（邮件、短信、钉钉、微信）、存储（消息队列、DB、文件系统等）。</p><p>（1）告警方式（邮件、短信、钉钉、微信）</p><p>在计算层会将计算结果与阈值进行比较，超过阈值触发告警，让运维提前收到通知，告警消息如下图所示，这样运维可以及时做好应对措施，减少故障的损失大小。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-072406.png" alt=""></p><p>（2）存储（消息队列、DB、文件系统等）</p><p>数据存储后，监控大盘（Dashboard）从存储（ElasticSearch、HBase 等）里面查询对应指标的数据就可以查看实时的监控信息，做到对促销活动的商品销量、销售额，机器 CPU、Mem 等有实时监控，运营、运维、开发、领导都可以实时查看并作出对应的措施。</p><ul><li>让运营知道哪些商品是爆款，哪些店铺成交额最多，如下图所示，哪些商品成交额最高，哪些商品浏览量最多；</li></ul><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/wPVXpl.jpg" alt=""></p><ul><li>让运维可以时刻了解机器的运行状况，如下图所示，出现宕机或者其他不稳定情况可以及时处理；</li></ul><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/fQo3Qh.jpg" alt=""></p><ul><li>让开发知道自己项目运行的情况，从 Error 日志知道出现了哪些 Bug，如下图所示；</li></ul><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/RqkWqu.jpg" alt=""></p><ul><li>让领导知道这次促销赚了多少 money，如下图所示。</li></ul><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/OPZz5t.jpg" alt=""></p><p><strong>从数据采集到数据计算再到数据下发，如下图所示，整个流程在上面的场景对实时性要求还是很高的，任何一个地方出现问题都将影响最后的效果！</strong></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-073733.png" alt=""></p><h3 id="1-1-5-实时计算场景"><a href="#1-1-5-实时计算场景" class="headerlink" title="1.1.5 实时计算场景"></a>1.1.5 实时计算场景</h3><p>前面说了这么多场景，这里我们总结一下实时计算常用的场景有哪些呢？比如：</p><ul><li>交通信号灯数据</li><li>道路上车流量统计（拥堵状况）</li><li>公安视频监控</li><li>服务器运行状态监控</li><li>金融证券公司实时跟踪股市波动，计算风险价值</li><li>数据实时 ETL</li><li>银行或者支付公司涉及金融盗窃的预警</li></ul><p>……</p><p>另外自己还做过调研，实时计算框架的使用场景有如下这些：</p><ul><li>业务数据处理，聚合业务数据，统计之类</li><li>流量日志</li><li>ETL</li><li>安防这块，公安视频结构化数据，用 Flink 做图片搜索</li><li>风控，主要处理结构化数据</li><li>业务告警</li><li>动态数据监控</li></ul><p>总结一下大概有下面这四类，如下图所示：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/zL93nD.jpg" alt=""></p><p>这四类分别是：</p><ul><li><strong>实时数据存储</strong>：实时数据存储的时候做一些微聚合、过滤某些字段、数据脱敏，组建数据仓库，实时 ETL。</li><li><strong>实时数据分析</strong>：实时数据接入机器学习框架（TensorFlow）或者一些算法进行数据建模、分析，然后动态的给出商品推荐、广告推荐</li><li><strong>实时监控告警</strong>：金融相关涉及交易、实时风控、车流量预警、服务器监控告警、应用日志告警</li><li><strong>实时数据报表</strong>：活动营销时销售额/销售量大屏，TopN 商品</li></ul><p>说到实时计算，这里不得不讲一下它与传统的离线计算之间的区别！</p><h3 id="1-1-6-离线计算-vs-实时计算"><a href="#1-1-6-离线计算-vs-实时计算" class="headerlink" title="1.1.6 离线计算 vs 实时计算"></a>1.1.6 离线计算 vs 实时计算</h3><p>再讲离线计算和实时计算这两个区别之前，我们先来看看流处理和批处理。</p><h4 id="流处理与批处理"><a href="#流处理与批处理" class="headerlink" title="流处理与批处理"></a>流处理与批处理</h4><p>流处理是一种重要的大数据处理手段，其主要特点是其处理的数据是源源不断且实时到来的。批处理历史比较悠久，而且使用的场景比较多，其主要操作的是大容量的静态数据集，并在计算过程完成后返回结果。它们之间的区别如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-074541.png" alt=""></p><p>看完流处理与批处理这两者的区别之后，我们来抽象一下前面内容的场景需求计算流程（<strong>实时计算</strong>）如下图所示：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/SrubtS.jpg" alt=""></p><p>实时计算需要不断的从 MQ 中读取采集的数据，然后处理计算后往 DB 里存储，在计算这层你无法感知到会有多少数据量过来、要做一些简单的操作（过滤、聚合等）、及时将数据下发。然而传统的<strong>离线计算</strong>却如下图所示：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/eseUjV.jpg" alt=""></p><p>在计算这层，它从 DB（不限 MySQL，还有其他的存储介质）里面读取数据，该数据一般就是固定的（前一天、前一星期、前一个月），然后再做一些复杂的计算或者统计分析，最后生成可供直观查看的报表（dashboard）。</p><h4 id="离线计算的特点"><a href="#离线计算的特点" class="headerlink" title="离线计算的特点"></a>离线计算的特点</h4><p>离线计算一般有下面这些特点：</p><ul><li>数据量大且时间周期长（一天、一星期、一个月、半年、一年）</li><li>在大量数据上进行复杂的批量计算操作</li><li>数据在计算之前已经固定，不再会发生变化</li><li>能够方便的查询批量计算的结果</li></ul><h4 id="实时计算的特点"><a href="#实时计算的特点" class="headerlink" title="实时计算的特点"></a>实时计算的特点</h4><p>在大数据中与离线计算对应的则是实时计算，那么实时计算有什么特点呢？由于应用场景的各不相同，所以这两种计算引擎接收数据的方式也不太一样：离线计算的数据是固定的（不再会发生变化），通常离线计算的任务都是定时的，如：每天晚上 0 点的时候定时计算前一天的数据，生成报表；然而实时计算的数据源却是流式的。</p><p>这里我不得不讲讲什么是流式数据呢？我的理解是比如你在淘宝上下单了某个商品或者点击浏览了某件商品，你就会发现你的页面立马就会给你推荐这种商品的广告和类似商品的店铺，这种就是属于实时数据处理然后作出相关推荐，这类数据需要不断的从你在网页上的点击动作中获取数据，之后进行实时分析然后给出推荐。</p><h4 id="流式数据的特点"><a href="#流式数据的特点" class="headerlink" title="流式数据的特点"></a>流式数据的特点</h4><p>流式数据一般有下面这些特点：</p><ul><li>数据实时到达</li><li>数据到达次序独立，不受应用系统所控制</li><li>数据规模大且无法预知容量</li><li>原始数据一经处理，除非特意保存，否则不能被再次取出处理，或者再次提取数据代价昂贵</li></ul><p>通过上面的内容可以总结实时计算与离线计算的对比如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-075309.png" alt=""></p><h4 id="实时计算的优势"><a href="#实时计算的优势" class="headerlink" title="实时计算的优势"></a>实时计算的优势</h4><p><strong>实时计算一时爽，一直实时计算一直爽</strong>，对于持续生成最新数据的场景，采用流数据处理是非常有利的。例如，再监控服务器的一些运行指标的时候，能根据采集上来的实时数据进行判断，当超出一定阈值的时候发出警报，进行提醒作用。再如通过处理流数据生成简单的报告，如五分钟的窗口聚合数据平均值。复杂的事情还有在流数据中进行数据多维度关联、聚合、筛选，从而找到复杂事件中的根因。更为复杂的是做一些复杂的数据分析操作，如应用机器学习算法，然后根据算法处理后的数据结果提取出有效的信息，作出、给出不一样的推荐内容，让不同的人可以看见不同的网页（千人千面）。</p><h3 id="1-1-7-实时计算面临的挑战"><a href="#1-1-7-实时计算面临的挑战" class="headerlink" title="1.1.7 实时计算面临的挑战"></a>1.1.7 实时计算面临的挑战</h3><p>虽然实时计算有这么多好处，但是要使用实时计算也会面临很多挑战，比如下面这些：</p><ul><li>数据处理唯一性（如何保证数据只处理一次？至少一次？最多一次？）</li><li>数据处理的及时性（采集的实时数据量太大的话可能会导致短时间内处理不过来，如何保证数据能够及时的处理，不出现数据堆积？）</li><li>数据处理层和存储层的可扩展性（如何根据采集的实时数据量的大小提供动态扩缩容？）</li><li>数据处理层和存储层的容错性（如何保证数据处理层和存储层高可用，出现故障时数据处理层和存储层服务依旧可用？）</li></ul><p>因为各种需求，也就造就了现在不断出现实时计算框架，在 1.2 节中将重磅介绍如今最火的实时计算框架 —— Flink，在 1.3 节中会对比介绍 Spark Streaming、Structured Streaming 和 Storm 之间的区别。</p><h3 id="1-1-8-小结与反思"><a href="#1-1-8-小结与反思" class="headerlink" title="1.1.8 小结与反思"></a>1.1.8 小结与反思</h3><p>本节从实时计算的需求作为切入点，然后分析该如何去完成这种实时计算的需求，从而得知整个过程包括数据采集、数据计算、数据存储等，接着总结了实时计算场景的类型。最后开始介绍离线计算与实时计算的区别，并提出了实时计算可能带来的挑战。你们公司有文中所讲的类似需求吗？你是怎么解决的呢？</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第一章-——-实时计算引擎&quot;&gt;&lt;a href=&quot;#第一章-——-实时计算引擎&quot; class=&quot;headerlink&quot; title=&quot;第一章 —— 实时计算引擎&quot;&gt;&lt;/a&gt;第一章 —— 实时计算引擎&lt;/h1&gt;&lt;p&gt;本章会从公司常见的计算需求去分析该如何实现这些需求，接着会对比分析实时计算与离线计算之间的区别，从而帮大家分析公司是否需要引入实时计算引擎。接着将会详细的介绍目前最火的实时计算引擎 Flink 的特性，让大家知道其优点，最后会对比其他的计算框架，比如 Spark、Storm 等，希望可以从对比结果来分析这几种计算框架的各自优势，从而为你做技术选型提供一点帮助。&lt;/p&gt;
&lt;h2 id=&quot;1-1-你的公司是否需要引入实时计算引擎&quot;&gt;&lt;a href=&quot;#1-1-你的公司是否需要引入实时计算引擎&quot; class=&quot;headerlink&quot; title=&quot;1.1 你的公司是否需要引入实时计算引擎&quot;&gt;&lt;/a&gt;1.1 你的公司是否需要引入实时计算引擎&lt;/h2&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Flink 的动态欺诈检测系统(下)</title>
    <link href="http://www.54tianzhisheng.cn/2021/07/03/Flink-Fraud-Detection-engine-3/"/>
    <id>http://www.54tianzhisheng.cn/2021/07/03/Flink-Fraud-Detection-engine-3/</id>
    <published>2021-07-02T16:00:00.000Z</published>
    <updated>2021-07-03T12:24:34.986Z</updated>
    
    <content type="html"><![CDATA[<p>如何实现呢？</p><a id="more"></a><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>在本系列的前两篇文章中，我们描述了如何基于动态更新配置（欺诈检测规则）来实现灵活的数据流分区，以及如何利用 Flink 的 Broadcast 机制在运行时在相关算子之间分配处理配置。</p><p>直接跟上我们上次讨论端到端解决方案的地方，在本篇文章中，我们将描述如何使用 Flink 的 “瑞士军刀” —— Process Function 来创建一个量身定制的实现，以满足你的流业务逻辑需求。我们的讨论将在欺诈检测引擎的背景下继续进行，我们还将演示如何在 DataStream API 提供的窗口不能满足你的要求的情况下，通过自定义窗口来实现你自己的需求。特别的是，我们将研究在设计需要对单个事件进行低延迟响应的解决方案时可以做出权衡。</p><p>本文将描述一些可以独立应用的高级概念，建议你先阅读本系列第一篇和第二篇文章，并阅读其代码实现，以便更容易理解本文。</p><h3 id="ProcessFunction-当作-Window"><a href="#ProcessFunction-当作-Window" class="headerlink" title="ProcessFunction 当作 Window"></a>ProcessFunction 当作 Window</h3><h4 id="低延迟"><a href="#低延迟" class="headerlink" title="低延迟"></a>低延迟</h4><p>首先来看下我们将要支持的欺诈检测规则类型：</p><blockquote><p>“每当同一付款人在 24 小时内支付给同一受益人的款项总额超过 20 万美元时，就会触发警报。”</p></blockquote><p>换句话说，假设现在有一个按照付款人和受益人组成 key 分区的交易数据流，对于每条到来的交易数据流，我们都会统计两个特定参与者之间前 24 小时到现在的付款总额是否超过预定义的阈值。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/time-windows.png" alt=""></p><p>欺诈检测系统的常见关键要求之一是响应时间短。欺诈行为越早被检测到，阻止就会越及时，带来的负面影响就会越小。这一要求在金融领域尤为突出，因为用于评估欺诈检测系统的任何时间都是用户需要等待响应所花费的时间。处理的迅速性通常成为各种支付系统之间的竞争优势，产生告警的时间限制可能低至 300-500 毫秒。这是从欺诈检测系统接收到金融交易事件的那一刻起，直到下游系统发出告警为止的所有延迟时间限制。</p><p>你可能知道，Flink 已经提供了强大的 Window API，这些 API 可以适用于广泛的场景。但是你查看 Flink 所有支持的窗口类型，你会发现没有一个能完全符合我们这个场景的要求 —— 低延迟的计算每条交易数据。Flink 自带的窗口没有可以表达 “从当前事件返回 x 分钟/小时/天” 的语义。在 Window API 中，事件会落到由窗口分配器定义的窗口中，但是他们本身不能单独控制 Window 的创建和计算。如上所述，我们的欺诈检测引擎的目标是在收到新事件后立即对之前的相关数据进行计算。在这种场景下，利用 Flink 自带的 Window API 不清楚是否可行。Window API 提供了一些用于自定义的 Trigger、Evictor 和 Window Assigner，或许它们可能会帮助到我们获得所需的结果。但是，通常情况下很难做到这一点，此外，这种方法不提供对广播状态的访问，这是然后广播状态是实现业务规则动态配置所必须的。</p><p>1) 除了会话窗口，它们仅限于基于会话间隙的分配</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/evaluation-delays.png" alt=""></p><p>我们以使用 Flink 的 Window API 中的滑动窗口为例。使用滑动步长为 S 的滑动窗口转化为等于 S/2 的评估延迟的预期值。这意味着你需要定义 600～1000 毫秒的滑动窗口来满足 300～500 毫秒延迟的低延迟要求。Flink 要为每个滑动窗口存储单独的窗口状态，这会导致作业状态非常大，在任何中等高负载的情况下，这种方案都不可行。为了满足需求，我们需要创建自定的低延迟窗口实现，幸运的是，Flink 为我们提供了这样做所需的所有工具，ProcessFunction 是 Flink API 中一个低级但功能强大的类。它有一个简单的约定：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SomeProcessFunction</span> <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>&lt;<span class="title">KeyType</span>, <span class="title">InputType</span>, <span class="title">OutputType</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(InputType event, Context ctx, Collector&lt;OutputType&gt; out)</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">long</span> timestamp, OnTimerContext ctx, Collector&lt;OutputType&gt; out)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>processElement()：接收输入数据，你可以通过调用 out.collect() 为下一个算子生成一个或者多个输出事件来对每个输入作出反应，你可以将数据传递到侧输出或完全忽略特定的输入数据</li><li>onTimer()：当之前注册的定时器触发时，Flink 会调用 onTimer()，支持事件时间和处理时间定时器</li><li>open()：相当于一个构造函数，它在 TaskManager 的 JVM 内部调用，用于初始化，例如注册 Flink 管理内存，可以在该方法初始化那些没有序列化的字段或者无法从 JobManager JVM 中传递过来的字段。</li></ul><p>最重要的是，ProcessFunction 还可以访问由 Flink 处理的容错状态。这种组合，再加上 Flink 的消息处理能力和低延迟的保证，使得构建具有几乎任意复杂业务逻辑的弹性事件驱动应用程序成为可能。这包括创建和处理带有状态的自定义窗口。</p><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p><strong>状态的清除</strong></p><p>为了能够处理时间窗口，我们需要在程序内部跟踪属于该窗口的数据。为了确保这些数据是容错的，并且能够在分布式系统中发生故障的情况下恢复，我们应该将其存储在 Flink 管理的状态中。随着时间的推移，我们不需要保留所有以前的交易数据。根据欺诈检测样例规则，所有早于 24 小时的交易数据都变得无关紧要。我们正在查看一个不断移动的数据窗口，其中过期的数据需要不断移出范围（换句话说，从状态中清除）。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/window-clean-up.png" alt=""></p><p>我们将使用 MapState 来存储窗口的各个事件。为了有效清理超出范围的事件，我们将使用事件时间戳作为 MapState 的 key。</p><p>在一般情况下，我们必须考虑这样一个事实，即可能存在具有完全相同时间戳的不同事件，因此我们将存储集合而不是每个键（时间戳）的单条数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MapState&lt;Long, Set&lt;Transaction&gt;&gt; windowState;</span><br></pre></td></tr></table></figure><p>注意⚠️：</p><p>当在 KeyedProcessFunction 中使用任何 Flink 管理的状态时，state.value() 调用返回的数据会自动由当前处理的事件的 key 确定范围 - 参见下图。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/keyed-state-scoping.png" alt=""></p><p>如果使用 MapState，则适用相同的原则，不同之处在于返回的是 Map 而不是 MyObject。如果你被迫执行类似 <code>mapState.value().get(inputEvent.getKey())</code> 之类的操作，你可能应该使用 ValueState 而不是 MapState。因为我们想为每个事件 key 存储多个值，所以在我们的例子中，MapState 是正确的选择。</p><p>如本系列的第一篇博客所述，我们将根据主动欺诈检测规则中指定的 key 分配数据。多个不同的规则可以基于相同的分组 key。这意味着我们的警报功能可能会接收由相同 key（例如 {payerId=25;beneficiaryId=12}）限定的交易，但注定要根据不同的规则进行计算，这意味着时间窗口的长度可能不同。这就提出了一个问题，即我们如何才能最好地在 KeyedProcessFunction 中存储容错窗口状态。一种方法是为每个规则创建和管理单独的 MapState。然而，这种方法会很浪费——我们会单独保存重叠时间窗口的状态，因此不必要地存储重复的数据。更好的方法是始终存储刚好足够的数据，以便能够估计由相同 key 限定的所有当前活动规则。为了实现这一点，每当添加新规则时，我们将确定其时间窗口是否具有最大跨度，并将其存储在特殊保留的 WIDEST_RULE_KEY 下的广播状态。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processBroadcastElement</span><span class="params">(Rule rule, Context ctx, Collector&lt;Alert&gt; out)</span></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  updateWidestWindowRule(rule, broadcastState);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateWidestWindowRule</span><span class="params">(Rule rule, BroadcastState&lt;Integer, Rule&gt; broadcastState)</span></span>&#123;</span><br><span class="line">  Rule widestWindowRule = broadcastState.get(WIDEST_RULE_KEY);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (widestWindowRule == <span class="keyword">null</span>) &#123;</span><br><span class="line">    broadcastState.put(WIDEST_RULE_KEY, rule);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (widestWindowRule.getWindowMillis() &lt; rule.getWindowMillis()) &#123;</span><br><span class="line">    broadcastState.put(WIDEST_RULE_KEY, rule);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在让我们更详细地看一下主要方法 processElement() 的实现。</p><p>在上一篇博文中，我们描述了 DynamicKeyFunction 如何允许我们根据规则定义中的 groupingKeyNames 参数执行动态数据分区。随后的描述主要围绕 DynamicAlertFunction，它利用了剩余的规则设置。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/sample-rule-definition.png" alt=""></p><p>如博文系列的前几部分所述，我们的警报处理函数接收 <code>Keyed&lt;Transaction, String, Integer&gt;</code> 类型的事件，其中 Transaction 是主要的“包装”事件，String 是 key<br>（payer #x - beneficiary #y)，Integer 是导致调度此事件的规则的 ID。此规则之前存储在广播状态中，必须通过 ID 从该状态中检索。下面是实现代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicAlertFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">KeyedBroadcastProcessFunction</span>&lt;</span></span><br><span class="line"><span class="class">        <span class="title">String</span>, <span class="title">Keyed</span>&lt;<span class="title">Transaction</span>, <span class="title">String</span>, <span class="title">Integer</span>&gt;, <span class="title">Rule</span>, <span class="title">Alert</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">transient</span> MapState&lt;Long, Set&lt;Transaction&gt;&gt; windowState;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      Keyed&lt;Transaction, String, Integer&gt; value, ReadOnlyContext ctx, Collector&lt;Alert&gt; out)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add Transaction to state</span></span><br><span class="line">    <span class="keyword">long</span> currentEventTime = value.getWrapped().getEventTime();                            <span class="comment">// &lt;--- (1)</span></span><br><span class="line">    addToStateValuesSet(windowState, currentEventTime, value.getWrapped());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Calculate the aggregate value</span></span><br><span class="line">    Rule rule = ctx.getBroadcastState(Descriptors.rulesDescriptor).get(value.getId());    <span class="comment">// &lt;--- (2)</span></span><br><span class="line">    Long windowStartTimestampForEvent = rule.getWindowStartTimestampFor(currentEventTime);<span class="comment">// &lt;--- (3)</span></span><br><span class="line"></span><br><span class="line">    SimpleAccumulator&lt;BigDecimal&gt; aggregator = RuleHelper.getAggregator(rule);            <span class="comment">// &lt;--- (4)</span></span><br><span class="line">    <span class="keyword">for</span> (Long stateEventTime : windowState.keys()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (isStateValueInWindow(stateEventTime, windowStartForEvent, currentEventTime)) &#123;</span><br><span class="line">        aggregateValuesInState(stateEventTime, aggregator, rule);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Evaluate the rule and trigger an alert if violated</span></span><br><span class="line">    BigDecimal aggregateResult = aggregator.getLocalValue();                              <span class="comment">// &lt;--- (5)</span></span><br><span class="line">    <span class="keyword">boolean</span> isRuleViolated = rule.apply(aggregateResult);</span><br><span class="line">    <span class="keyword">if</span> (isRuleViolated) &#123;</span><br><span class="line">      <span class="keyword">long</span> decisionTime = System.currentTimeMillis();</span><br><span class="line">      out.collect(<span class="keyword">new</span> Alert&lt;&gt;(rule.getRuleId(),</span><br><span class="line">                              rule,</span><br><span class="line">                              value.getKey(),</span><br><span class="line">                              decisionTime,</span><br><span class="line">                              value.getWrapped(),</span><br><span class="line">                              aggregateResult));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Register timers to ensure state cleanup</span></span><br><span class="line">    <span class="keyword">long</span> cleanupTime = (currentEventTime / <span class="number">1000</span>) * <span class="number">1000</span>;                                  <span class="comment">// &lt;--- (6)</span></span><br><span class="line">    ctx.timerService().registerEventTimeTimer(cleanupTime);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>以下是步骤的详细信息：</p><p>1）我们首先将每个新事件添加到我们的窗口状态：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> &lt;K, V&gt; <span class="function">Set&lt;V&gt; <span class="title">addToStateValuesSet</span><span class="params">(MapState&lt;K, Set&lt;V&gt;&gt; mapState, K key, V value)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Set&lt;V&gt; valuesSet = mapState.get(key);</span><br><span class="line">    <span class="keyword">if</span> (valuesSet != <span class="keyword">null</span>) &#123;</span><br><span class="line">      valuesSet.add(value);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      valuesSet = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">      valuesSet.add(value);</span><br><span class="line">    &#125;</span><br><span class="line">    mapState.put(key, valuesSet);</span><br><span class="line">    <span class="keyword">return</span> valuesSet;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2）接下来，我们检索先前广播的规则，需要根据该规则计算传入的交易数据。</p><p>3) getWindowStartTimestampFor 确定，给定规则中定义的窗口跨度和当前事件时间戳，然后计算窗口应该跨度多久。</p><p>4) 通过迭代所有窗口状态并应用聚合函数来计算聚合值。它可以是平均值、最大值、最小值，或者如本文开头的示例规则中的总和。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isStateValueInWindow</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Long stateEventTime, Long windowStartForEvent, <span class="keyword">long</span> currentEventTime)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> stateEventTime &gt;= windowStartForEvent &amp;&amp; stateEventTime &lt;= currentEventTime;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">aggregateValuesInState</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Long stateEventTime, SimpleAccumulator&lt;BigDecimal&gt; aggregator, Rule rule)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  Set&lt;Transaction&gt; inWindow = windowState.get(stateEventTime);</span><br><span class="line">  <span class="keyword">for</span> (Transaction event : inWindow) &#123;</span><br><span class="line">    BigDecimal aggregatedValue =</span><br><span class="line">        FieldsExtractor.getBigDecimalByName(rule.getAggregateFieldName(), event);</span><br><span class="line">    aggregator.add(aggregatedValue);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5) 有了聚合值，我们可以将其与规则定义中指定的阈值进行比较，并在必要时发出警报。</p><p>6) 最后，我们使用 <code>ctx.timerService().registerEventTimeTimer()</code> 注册一个清理计时器。当它要移出范围时，此计时器将负责删除当前数据。</p><p>7) onTimer 方法会触发窗口状态的清理。</p><p>如前所述，我们总是在状态中保留尽可能多的事件，以计算具有最宽窗口跨度的活动规则。这意味着在清理过程中，我们只需要删除这个最宽窗口范围之外的状态。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/widest-window.png" alt=""></p><p>这是清理程序的实现方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timestamp, <span class="keyword">final</span> OnTimerContext ctx, <span class="keyword">final</span> Collector&lt;Alert&gt; out)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">  Rule widestWindowRule = ctx.getBroadcastState(Descriptors.rulesDescriptor).get(WIDEST_RULE_KEY);</span><br><span class="line"></span><br><span class="line">  Optional&lt;Long&gt; cleanupEventTimeWindow =</span><br><span class="line">      Optional.ofNullable(widestWindowRule).map(Rule::getWindowMillis);</span><br><span class="line">  Optional&lt;Long&gt; cleanupEventTimeThreshold =</span><br><span class="line">      cleanupEventTimeWindow.map(window -&gt; timestamp - window);</span><br><span class="line">  <span class="comment">// Remove events that are older than (timestamp - widestWindowSpan)ms</span></span><br><span class="line">  cleanupEventTimeThreshold.ifPresent(<span class="keyword">this</span>::evictOutOfScopeElementsFromWindow);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">evictOutOfScopeElementsFromWindow</span><span class="params">(Long threshold)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    Iterator&lt;Long&gt; keys = windowState.keys().iterator();</span><br><span class="line">    <span class="keyword">while</span> (keys.hasNext()) &#123;</span><br><span class="line">      Long stateEventTime = keys.next();</span><br><span class="line">      <span class="keyword">if</span> (stateEventTime &lt; threshold) &#123;</span><br><span class="line">        keys.remove();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(ex);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上是实现细节的描述。我们的方法会在新交易数据到达时立即触发对时间窗口的计算。因此，它满足了我们的主要要求——发出警报的低延迟。完整的实现请看 github 上的项目代码 <a href="https://github.com/afedulov/fraud-detection-demo">https://github.com/afedulov/fraud-detection-demo</a>。</p><h3 id="完善和优化"><a href="#完善和优化" class="headerlink" title="完善和优化"></a>完善和优化</h3><p>上面描述的方法的优缺点是什么？</p><p><strong>优点</strong>：</p><ul><li>低延迟能力</li><li>具有潜在用例特定优化的定制解决方案</li><li>高效的状态重用（具有相同 key 的规则共享状态）</li></ul><p><strong>缺点</strong>：</p><ul><li>无法利用现有 Window API 中潜在的未来优化</li><li>无延迟事件处理，可在 Window API 中开箱即用</li><li>二次计算复杂度和潜在的大状态</li></ul><p>现在让我们看看后两个缺点，看看我们是否可以解决它们。</p><h4 id="延迟数据"><a href="#延迟数据" class="headerlink" title="延迟数据"></a>延迟数据</h4><p>处理延迟数据之前先提出了一个问题 - 在延迟数据到达的情况下重新评估窗口是否仍然有意义？ 如果需要这样做，你需要增加最宽的窗口大小，用来允许容忍最大的数据延迟。这样将避免因延迟数据问题导致触发了不完整的时间窗口数据。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/late-events.png" alt=""></p><p>然而，可以说，对于强调低延迟处理的场景，这种延迟触发将毫无意义。在这种情况下，我们可以跟踪到目前为止我们观察到的最新时间戳，对于不会单调增加此值的事件，只需将它们添加到状态并跳过聚合计算和警报触发逻辑。</p><h4 id="冗余重复计算和状态大小"><a href="#冗余重复计算和状态大小" class="headerlink" title="冗余重复计算和状态大小"></a>冗余重复计算和状态大小</h4><p>在我们描述的实现中，我们保存每条数据处于状态中并在每个新数据来时遍历它们并一次又一次地计算聚合。这在重复计算上浪费计算资源方面显然不是最佳的。</p><p>保存每个交易数据处于状态的主要原因是什么？存储事件的粒度直接对应于时间窗口计算的精度。因为我们是存储每条明细交易数据，所以一旦它们离开精确的 2592000000 毫秒时间窗口（以毫秒为单位的 30 天），我们就可以精确地移除它们。在这一点上，值得提出一个问题——在估计这么长的时间窗口时，我们真的需要这个毫秒级的精度，还是在特殊情况下可以接受潜在的误报？如果你的用例的答案是不需要这样的精度，那么你可以基于分桶和预聚合实施额外的优化。这种优化的思想可以分解如下：</p><ul><li><p>不是存储每条明细交易数据，而是创建一个父类，该类可以包含单条数据的字段或是根据聚合函数计算处理一批数据后的聚合值。</p></li><li><p>不要使用以毫秒为单位的时间戳作为 MapState key，而是将它们四舍五入到你愿意接受的粒度级别（例如，一分钟），将数据分桶。</p></li><li><p>每当计算窗口时，将新的交易数据存储到聚合桶中，而不是为每个数据存储单独的数据点。</p></li></ul><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/pre-aggregation.png" alt=""></p><h4 id="状态数据和序列化器"><a href="#状态数据和序列化器" class="headerlink" title="状态数据和序列化器"></a>状态数据和序列化器</h4><p>为了进一步优化实现，我们可以问自己的另一个问题是获得具有完全相同时间戳的不同事件的可能性有多大。在所描述的实现中，我们展示了通过在 <code>MapState&lt;Long, Set&lt;Transaction&gt;&gt;</code> 中存储每个时间戳的数据集来解决这个问题的一种方法。但是，这种选择对性能的影响可能比预期的要大。原因是 Flink 当前不提供原生 Set 序列化器，而是强制使用效率较低的 Kryo 序列化器（FLINK-16729）。一个有意义的替代策略是假设在正常情况下，没有两个有差异的事件可以具有完全相同的时间戳，并将窗口状态转换为 <code>MapState&lt;Long, Transaction&gt;</code> 类型。你可以使用辅助输出来收集和监控与你的假设相矛盾的任何意外事件。性能优化期间，我通常建议你禁用 Kryo，并通过确保使用更高效的序列化程序来验证你的应用程序可以进一步优化的位置。</p><p>你可以通过设置断点并验证返回的 TypeInformation 的类型来快速确定你的类将使用哪个序列化程序。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/type-pojo.png" alt=""></p><p>PojoTypeInfo 表示将使用高效的 Flink POJO 序列化器。</p><p><img src="https://flink.apache.org/img/blog/patterns-blog-3/type-kryo.png" alt=""></p><p>GenericTypeInfo 表示使用了 Kryo 序列化程序。</p><p>交易数据修剪：我们可以将单个事件数据减少到仅要用到的字段，而不是存储完整的事件数据，减少数据序列化与反序列化对机器施加额外的压力。这可能需要根据活动规则的配置将单个事件提取需要对字段出来，并将这些字段存储到通用 Map<String, Object> 数据结构中。</p><p>虽然这种调整可能会对大对象产生显著的改进，但它不应该是你的首选。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文总结了我们在第一部分中开始的欺诈检测引擎的实现描述。在这篇博文中，我们演示了如何利用 ProcessFunction 来“模拟”具有复杂自定义逻辑的窗口。我们已经讨论了这种方法的优缺点，并详细说明了如何应用自定义场景特定的优化 - 这是 Window API 无法直接实现的。</p><p>这篇博文的目的是说明 Apache Flink API 的强大功能和灵活性。它的核心是 Flink 的支柱，作为开发人员，它为你节省了大量的工作，并通过提供以下内容很好地推广到广泛的用例：</p><ul><li><p>分布式集群中的高效数据交换</p></li><li><p>通过数据分区的水平可扩展性</p></li><li><p>具有快速本地访问的容错状态</p></li><li><p>方便处理状态数据，就像使用局部变量一样简单</p></li><li><p>多线程、并行执行引擎。 ProcessFunction 代码在单线程中运行，无需同步。 Flink 处理所有并行执行方面并正确访问共享状态，而你作为开发人员不必考虑（并发很难）。</p></li></ul><p>所有这些方面都使得使用 Flink 构建应用程序成为可能，这些应用程序远远超出了普通的流 ETL 用例，并且可以实现任意复杂的分布式事件驱动应用程序。使用 Flink，你可以重新思考处理广泛用例的方法，这些用例通常依赖于使用无状态并行执行节点并将状态容错问题“推”到数据库，这种方法通常注定会遇到可扩展性问题面对不断增长的数据量。</p><blockquote><p>本篇文章属于翻译文章，作者：zhisheng</p><p>原文地址：<a href="http://www.54tianzhisheng.cn/2021/07/03/Flink-Fraud-Detection-engine-3/">http://www.54tianzhisheng.cn/2021/07/03/Flink-Fraud-Detection-engine-3/</a></p><p>英文作者：alex_fedulov</p><p>英文原文地址：<a href="https://flink.apache.org/news/2020/07/30/demo-fraud-detection-3.html">https://flink.apache.org/news/2020/07/30/demo-fraud-detection-3.html</a></p></blockquote><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何实现呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Flink 的动态欺诈检测系统(中)</title>
    <link href="http://www.54tianzhisheng.cn/2021/01/23/Flink-Fraud-Detection-engine-2/"/>
    <id>http://www.54tianzhisheng.cn/2021/01/23/Flink-Fraud-Detection-engine-2/</id>
    <published>2021-01-22T16:00:00.000Z</published>
    <updated>2021-01-23T15:53:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>如何实现呢？</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在上一篇博客中，我们对欺诈检测引擎的目标和所需要的功能进行了描述，我们还描述了如何基于可修改的规则而不是使用硬编码的 KeysExtractor 实现 Flink 应用程序的数据自定义分区。</p><p>我们在上篇博客中特意省略了有关如何初始化应用的规则以及如何在作业运行时更新的细节，在本文我们将详细的介绍这些细节，你将学习如何将上篇博客中描述的数据分区防御与动态配置结合使用，当这两种模式结合使用的时候，可以省去重新编译代码和重新部署 Flink 作业的需要，从而可以应对多种业务场景逻辑修改的情况。</p><h3 id="广播规则"><a href="#广播规则" class="headerlink" title="广播规则"></a>广播规则</h3><p>首先让我们看看预定义的数据处理代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Alert&gt; alerts =</span><br><span class="line">    transactions</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicKeyFunction())</span><br><span class="line">        .keyBy((keyed) -&gt; keyed.getKey());</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicAlertFunction())</span><br></pre></td></tr></table></figure><p>DynamicKeyFunction 函数提供动态数据分区，同时 DynamicAlertFunction 函数负责执行处理数据的主要逻辑并根据已定义的规则发动告警消息。</p><p>在上篇文中中简化了用例，并假定已预先初始化了所应用的规则集数据，并可以通过 DynamicKeyFunction 的 <code>List&lt;Rules&gt;</code> 访问这些规则：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicKeyFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessFunction</span>&lt;<span class="title">Transaction</span>, <span class="title">Keyed</span>&lt;<span class="title">Transaction</span>, <span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Simplified */</span></span><br><span class="line">  List&lt;Rule&gt; rules = <span class="comment">/* Rules that are initialized somehow.*/</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显然，在初始化阶段，可以直接在 Flink Job 的代码内部添加规则到此列表（创建<code>List</code>对象；使用它的<code>add</code>方法）。这样做的主要缺点是，每次修改规则后都需要重新编译作业。在真实的欺诈检测系统中，规则会经常更改，因此从业务和运营需求的角度来看，使此方法不可接受，需要一种不同的方法。</p><p>接下来，让我们看一下在上一篇文章中介绍的示例规则定义：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-134902.jpg" alt=""></p><p>上一篇文章介绍了使用 <code>DynamicKeyFunction</code>提取数据含 <code>groupingKeyNames</code> 里面字段组成数据分组 key 的方法。此规则第二部分中的参数由 <code>DynamicAlertFunction</code> 使用：它们定义了所执行操作的实际逻辑及其参数（例如告警触发限制）。这意味着相同的规则必须同时存在于<code>DynamicKeyFunction</code>和<code>DynamicAlertFunction</code>。</p><p>下图展示了我们正在构建的系统的最终工作图：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-135336.jpg" alt=""></p><p>上图的主要模块是：</p><ul><li><strong>Transaction Source</strong>：Flink 作业的 Source 端，它会并行的消费 Kafka 中的金融交易流数据</li><li>**Dynamic Key Function：动态的提取数据分区的 key。随后的<code>keyBy</code>函数会将动态的 key 值进行 hash，并在后续运算符的所有并行实例之间相应地对数据进行分区。</li><li><strong>Dynamic Alert Function</strong>：累积窗口中的数据，并基于该窗口创建告警。</li></ul><h3 id="Apache-Flink-内部的数据交换"><a href="#Apache-Flink-内部的数据交换" class="headerlink" title="Apache Flink 内部的数据交换"></a>Apache Flink 内部的数据交换</h3><p>上面的作业图还展示了运算符之间的各种数据交换模式，为了了解广播模式是如何工作的，我们先来看一下 Apache Flink 在分布式运行时存在哪些消息传播方法：</p><ul><li><p><strong>FORWARD</strong>：上图中 Transaction Source 后的 FORWARD 意味着每个 Transaction Source 的并行度实例消费到的数据都将精确的传输到后面的 DynamicKeyFunction 运算符的每个实例。它还表示两个连接的运算符处于相同的并行度，这种模式如下图所示：</p><p>  <img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-143026.jpg" alt=""></p><ul><li><p><strong>HASH</strong>：DynamicKeyFunction 和 DynamicAlertFunction 之间的 HASH 意味着每条消息都会计算一个哈希值，并且消息会在下一个运算符的所有可用并行度之间均匀分配，这种连接一般是通过 keyBy 算子。</p><p>  <img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-143447.jpg" alt=""></p></li></ul></li><li><p><strong>REBALANCE</strong>：这种情况下一般是手动的调用 rebalance() 函数或者并行度发生改变导致的，这样会导致数据以循环的方式重新分区，有助于某些情况喜爱的数据倾斜。</p><p>  <img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-144041.jpg" alt=""></p><ul><li><p><strong>BROADCAST</strong>：在本文图二中的欺诈检测作业图中包含了一个 Rules Source，它会从 Kafka 中消费规则数据，然后通过 <strong>BROADCAST </strong>的通道将规则数据发动到处理实时数据流的算子中去。与在运算符之间传输数据的其他方法（例如 forward、hash、rebalence，这三种仅会将数据发到下游运算符的某个并行度中去）不同，broadcast 可以使得每条消息都会在下游所有的并行度中处理。broadcast 适用于需要影响所有消息处理的任务，而不管消息的 key 或者 Source 的分区是多少。</p><p>  <img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-23-145129.jpg" alt=""></p></li></ul></li></ul><h3 id="广播状态"><a href="#广播状态" class="headerlink" title="广播状态"></a>广播状态</h3><p>为了使用规则数据流，我们需要将其连接到主数据流：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Streams setup</span></span><br><span class="line">DataStream&lt;Transaction&gt; transactions = [...]</span><br><span class="line">DataStream&lt;Rule&gt; rulesUpdateStream = [...]</span><br><span class="line"></span><br><span class="line">BroadcastStream&lt;Rule&gt; rulesStream = rulesUpdateStream.broadcast(RULES_STATE_DESCRIPTOR);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Processing pipeline setup</span></span><br><span class="line"> DataStream&lt;Alert&gt; alerts =</span><br><span class="line">     transactions</span><br><span class="line">         .connect(rulesStream)</span><br><span class="line">         .process(<span class="keyword">new</span> DynamicKeyFunction())</span><br><span class="line">         .keyBy((keyed) -&gt; keyed.getKey())</span><br><span class="line">         .connect(rulesStream)</span><br><span class="line">         .process(<span class="keyword">new</span> DynamicAlertFunction())</span><br></pre></td></tr></table></figure><p>如您所见，可以通过调用<code>broadcast</code>方法并指定状态描述符，从任何常规流中创建广播流。在处理主数据流的事件时需要存储和查找广播的数据，因此，Flink 始终根据此状态描述符自动创建相应的<em>广播状态</em>。这与你在使用其他的状态类型不一样，那些是需要在 open 方法里面对其进行初始化。另请注意，广播状态始终是 KV 格式（<code>MapState</code>）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> MapStateDescriptor&lt;Integer, Rule&gt; RULES_STATE_DESCRIPTOR =</span><br><span class="line">        <span class="keyword">new</span> MapStateDescriptor&lt;&gt;(<span class="string">"rules"</span>, Integer.class, Rule.class);</span><br></pre></td></tr></table></figure><p>连接<code>rulesStream</code>后会导致 ProcessFunction 的内部发生某些变化。上一篇文章以稍微简化的方式介绍了<code>ProcessFunction</code>。但是 <code>DynamicKeyFunction</code>实际上是一个<code>BroadcastProcessFunction</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BroadcastProcessFunction</span>&lt;<span class="title">IN1</span>, <span class="title">IN2</span>, <span class="title">OUT</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(IN1 value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        ReadOnlyContext ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">processBroadcastElement</span><span class="params">(IN2 value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                 Context ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                 Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不同的是，添加<code>processBroadcastElement</code> 了方法，该方法是用于处理到达的广播规则流。以下新版本的<code>DynamicKeyFunction</code> 函数允许在 processElement 方法里面中动态的修改数据分发的 key 列表：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicKeyFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">BroadcastProcessFunction</span>&lt;<span class="title">Transaction</span>, <span class="title">Rule</span>, <span class="title">Keyed</span>&lt;<span class="title">Transaction</span>, <span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processBroadcastElement</span><span class="params">(Rule rule,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Context ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Collector&lt;Keyed&lt;Transaction, String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">    BroadcastState&lt;Integer, Rule&gt; broadcastState = ctx.getBroadcastState(RULES_STATE_DESCRIPTOR);</span><br><span class="line">    broadcastState.put(rule.getRuleId(), rule);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(Transaction event,</span></span></span><br><span class="line"><span class="function"><span class="params">                           ReadOnlyContext ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Collector&lt;Keyed&lt;Transaction, String, Integer&gt;&gt; out)</span></span>&#123;</span><br><span class="line">    ReadOnlyBroadcastState&lt;Integer, Rule&gt; rulesState =</span><br><span class="line">                                  ctx.getBroadcastState(RULES_STATE_DESCRIPTOR);</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Integer, Rule&gt; entry : rulesState.immutableEntries()) &#123;</span><br><span class="line">        <span class="keyword">final</span> Rule rule = entry.getValue();</span><br><span class="line">        out.collect(</span><br><span class="line">          <span class="keyword">new</span> Keyed&lt;&gt;(</span><br><span class="line">            event, KeysExtractor.getKey(rule.getGroupingKeyNames(), event), rule.getRuleId()));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的代码中，<code>processElement()</code>接收金融交易数据，并在 <code>processBroadcastElement()</code> 接收规则更新数据。创建新规则时，将如上面广播流的那张图所示进行分配，并会保存在所有使用 <code>processBroadcastState</code> 运算符的并行实例中。我们使用规则的 ID 作为存储和引用单个规则的 key。我们遍历动态更新的广播状态中的数据，而不是遍历硬编码的 <code>List&lt;Rules&gt;</code> 。</p><p>在将规则存储在广播 MapState 中时，DynamicAlertFunction 遵循相同的逻辑。如第 1 部分中所述，通过processElement 方法输入的每条消息均应按照一个特定规则进行处理，并通过 DynamicKeyFunction 对其进行“预标记”并带有相应的ID。我们需要做的就是使用提供的 ID 从 BroadcastState 中检索相应规则，并根据该规则所需的逻辑对其进行处理。在此阶段，我们还将消息添加到内部函数状态，以便在所需的数据时间窗口上执行计算。我们将在下一篇文章中考虑如何实现这一点。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在本文，我们继续研究了使用 Apache Flink 构建的欺诈检测系统的用例。我们研究了在并行运算符实例之间分配数据的不同方式，最重要的是广播状态。我们演示了如何通过广播状态提供的功能来组合和增强动态分区。在运行时发送动态更新的功能是 Apache Flink 的强大功能，适用于多种其他使用场景，例如控制状态（清除/插入/修复），运行 A / B 实验或执行 ML 模型系数的更新。</p><blockquote><p>本篇文章属于翻译文章，作者：zhisheng</p><p>原文地址：<a href="http://www.54tianzhisheng.cn/2021/01/23/Flink-Fraud-Detection-engine-2/">http://www.54tianzhisheng.cn/2021/01/23/Flink-Fraud-Detection-engine-2/</a></p><p>英文作者：<a href="https://twitter.com/alex_fedulov">alex_fedulov</a> </p><p>英文原文地址：<a href="https://flink.apache.org/news/2020/03/24/demo-fraud-detection-2.html">https://flink.apache.org/news/2020/03/24/demo-fraud-detection-2.html</a></p></blockquote><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何实现呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Flink 的动态欺诈检测系统(上)</title>
    <link href="http://www.54tianzhisheng.cn/2021/01/22/Flink-Fraud-Detection-engine/"/>
    <id>http://www.54tianzhisheng.cn/2021/01/22/Flink-Fraud-Detection-engine/</id>
    <published>2021-01-21T16:00:00.000Z</published>
    <updated>2021-01-22T01:36:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>如何实现呢？</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在本系列博客中，你将学习到三种构建 Flink 应用程序的强大案例：</p><ul><li>动态更新应用程序的逻辑</li><li>动态的数据分区（shuffle），在作业运行时进行控制</li><li>基于自定义窗口逻辑的低延迟告警（不使用 Window API）</li></ul><p>这几个案例扩展了使用静态定义的数据流可以实现的功能，并提供了满足复杂业务需求的基础。</p><p><strong>动态更新应用程序的逻辑</strong> 允许作业在运行时进行更改，不需要将作业停止后修改代码再发布。</p><p><strong>动态的数据分区</strong> 为运行中的 Flink 作业作业提供了动态地将数据分组（group by）的功能。对于想要构建一个可以动态配置应用逻辑的 Flink 程序，类似功能很常见。</p><p><strong>自定义窗口管理</strong> 演示了如何在原生的 Window API 不能完全满足你的需求下，去通过最底层的 Process Function API 来完成你的需求。你将学会如何自定义 Window 逻辑来实现低延迟告警以及如何利用定时器（Timer）来限制状态的无限增长。</p><p>这几个案例都是建立在 Flink 核心功能的基础上，但是通过官方文档你可能无法立即明白，因为如果没有具体的用例，解释和呈现它们背后的原理其实并不是那么简单。这就是为什么我们将通过一些实际的案例来展示，本案例为 Apache Flink 的一个真实使用场景 —— 欺诈检测引擎。我希望你能从本系列文章中收获到这些强大的功能和方法，然后能应用在你们实际的应用场景中去。</p><p>在该系列的第一篇博客中，我们将先来看看这个应用程序的架构、组件和交互。然后我们将深入研究第一个案例的的实现细节 —— <strong>动态数据分区</strong>。</p><p>你将能够在本地运行完整的欺诈检测演示应用程序，并且可以通过 Github 仓库查看其完整实现代码。</p><h3 id="欺诈检测系统演示"><a href="#欺诈检测系统演示" class="headerlink" title="欺诈检测系统演示"></a>欺诈检测系统演示</h3><p>本次掩饰的欺诈检测引擎的代码是开源的，可以在线获取，要是想在本地运行它，请按照 <a href="">https://github.com/afedulov/fraud-detection-demo</a> 中的 README 描述的步骤自行进行操作。</p><p>你将看到该案例的代码和组件都很全，仅需要通过 docker 和 docker-compose 构建源码。仓库里面包含了下面组件：</p><ul><li>含有 Zookeeper 的 Apache Kafka</li><li>Apache Flink（应用程序）</li><li>欺诈检测引擎的 Web 应用</li></ul><p>欺诈检测引擎的目标是消费金融交易的实时数据流，然后根据一组检测规则对其进行评估。这些规则会经常更改和调整，在实际的生产系统中，重要的是要能在作业运行的时候去添加和删除规则，而不会因停止和重新启动作业从而造成高昂的代价。</p><p>当你在本地运行成功后，你在浏览器中输入 URL 可以看到如下效果：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-21-150159.jpg" alt="欺诈检测引擎演示UI"></p><p>点击 “Start” 按钮后，你可以在左侧看到系统中流动的金融交易大盘，你可以通过顶部的滑块去控制每秒生成的数据，中间部分用于管理 Flink 用于计算的规则，你可以在这里创建新规则以及发出控制命令，例如清除 Flink 的状态。</p><p>现成的演示带有一组预定义的示例规则，你可以点击 Start 按钮，一段时间之后，将观察到 UI 右侧部分中显示的告警，这些告警消息是 Flink 根据预定义的规则评估生成的交易流的结果。</p><p>我们的样本欺诈检测系统包含三个主要的组件：</p><ul><li>前端（React）</li><li>后端（SpringBoot）</li><li>欺诈检测 Flink 应用程序</li></ul><p>三者之间的组成关系如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-21-151639.jpg" alt=""></p><p>后端将 REST API 暴露给前端，用于创建/删除规则以及发出用于管理演示执行的控制命令，然后，它会将这些前端操作行为数据发送到 Kafka Topic <code>Control</code> 中。后端还包含了一个交易数据生成器组件，该组件用来模拟交易数据的，然后会将这些交易数据发送到 Kafka Topic <code>Transactions</code> 中，这些数据最后都会被 Flink 应用程序去消费，Flink 程序经过规则计算这些交易数据后生成的告警数据会发送到 Kafka Topic <code>Alerts</code> 中，并通过 Web Sockets  将数据传到前端 UI。</p><p>现在你已经熟悉了该欺诈检测引擎的总体结构和布局了，接下来我们详细介绍这个系统里面包含的内容。</p><h3 id="数据动态分区"><a href="#数据动态分区" class="headerlink" title="数据动态分区"></a>数据动态分区</h3><p>如果过去你曾经使用过 Flink DataStream API，那么你肯定很熟悉 keyBy 方法。对数据流中的所有数据按键进行 shuffle，这样具有相同 key 的元素就会被分配到相同的分区。</p><p>一般在程序中，数据分区的 keyBy 字段是固定的，由数据内的某些静态字段确定，例如，当构建一个简单的基于窗口的交易流聚合时，我们可能总是按照交易账户 ID 进行分组。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Transaction&gt; input = <span class="comment">// [...]</span></span><br><span class="line">DataStream&lt;...&gt; windowed = input</span><br><span class="line">  .keyBy(Transaction::getAccountId)</span><br><span class="line">  .window(<span class="comment">/*window specification*/</span>);</span><br></pre></td></tr></table></figure><p>这种方法是在广泛的用例中实现水平可伸缩性的主要模块，但是在应用程序试图在运行时提供业务逻辑灵活性的情况下，这还是不够的。为了理解为什么会发生这种情况，让我们首先以功能需求的形式为欺诈检测系统阐明一个现实的样本规则定义：</p><blockquote><p>在<strong>一个星期</strong> 之内，当 用户 <strong>A</strong> <strong>累计</strong> 向 <strong>B</strong> 用户支付的金额超过 <strong>1000000 美元</strong>，则触发一条告警</p></blockquote><p>PS：A 和 B 用字段描述的话分别是 付款人（payer）和受益人（beneficiary）</p><p>在上面的规则中，我们可以发现许多参数，我们希望能够在新提交的规则中指定这些参数，甚至可能在运行时进行动态的修改或调整：</p><ul><li>聚合的字段（付款金额）</li><li>分组字段（付款人和受益人）</li><li>聚合函数（求和）</li><li>窗口大小（1 星期）</li><li>阈值（1000000）</li><li>计算符号（大于）</li></ul><p>因此，我们将使用以下简单的 JSON 格式来定义上述参数：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"ruleId"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"ruleState"</span>: <span class="string">"ACTIVE"</span>,</span><br><span class="line">  <span class="attr">"groupingKeyNames"</span>: [<span class="string">"payerId"</span>, <span class="string">"beneficiaryId"</span>],</span><br><span class="line">  <span class="attr">"aggregateFieldName"</span>: <span class="string">"paymentAmount"</span>,</span><br><span class="line">  <span class="attr">"aggregatorFunctionType"</span>: <span class="string">"SUM"</span>,</span><br><span class="line">  <span class="attr">"limitOperatorType"</span>: <span class="string">"GREATER"</span>,</span><br><span class="line">  <span class="attr">"limit"</span>: <span class="number">1000000</span>,</span><br><span class="line">  <span class="attr">"windowMinutes"</span>: <span class="number">10080</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这一点上，重要的是了解 groupingKeyNames 决定了数据的实际物理分区，所有指定参数（payerId + beneficiaryId）相同的交易数据都会汇总到同一个物理计算 operator 里面去。很明显，如果要实现这样的功能，在 Flink 里面是使用 keyBy 函数来完成。</p><p>Flink 官方文档中 keyBy() 函数的大多数示例都是使用硬编码的 <code>KeySelector</code>，它提取特定数据的字段。但是，为了支持所需的灵活性，我们必须根据规则中的规范以更加动态的方式提取它们，为此，我们将不得不使用一个额外的运算符，该运算符会将每条数据分配到正确的聚合实例中。</p><p>总体而言，我们的主要处理流程如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Alert&gt; alerts =</span><br><span class="line">    transactions</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicKeyFunction())</span><br><span class="line">        .keyBy(<span class="comment">/* some key selector */</span>);</span><br><span class="line">        .process(<span class="comment">/* actual calculations and alerting */</span>)</span><br></pre></td></tr></table></figure><p>先前我们已经建立了每个规则定义一个<strong><code>groupingKeyNames</code></strong>参数，该参数指定将哪些字段组合用于传入事件的分组。每个规则可以使用这些字段的任意组合。同时，每个传入事件都可能需要根据多个规则进行评估。这意味着事件可能需要同时出现在计算 operator 的多个并行实例中，这些实例对应于不同的规则，因此需要进行分叉。确保此类事件的调度能达到 <code>DynamicKeyFunction()</code> 的目的。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-22-004512.jpg" alt=""></p><p><code>DynamicKeyFunction</code>迭代一组已定义的规则，并通过 <code>keyBy()</code>函数提取所有数据所需的分组 key ：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicKeyFunction</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">ProcessFunction</span>&lt;<span class="title">Transaction</span>, <span class="title">Keyed</span>&lt;<span class="title">Transaction</span>, <span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">   ...</span><br><span class="line">  <span class="comment">/* Simplified */</span></span><br><span class="line">  List&lt;Rule&gt; rules = <span class="comment">/* Rules that are initialized somehow.</span></span><br><span class="line"><span class="comment">                        Details will be discussed in a future blog post. */</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      Transaction event,</span></span></span><br><span class="line"><span class="function"><span class="params">      Context ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">      Collector&lt;Keyed&lt;Transaction, String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (Rule rule :rules) &#123;</span><br><span class="line">       out.collect(</span><br><span class="line">           <span class="keyword">new</span> Keyed&lt;&gt;(</span><br><span class="line">               event,</span><br><span class="line">               KeysExtractor.getKey(rule.getGroupingKeyNames(), event),</span><br><span class="line">               rule.getRuleId()));</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>KeysExtractor.getKey()</code>使用反射从数据中提取<code>groupingKeyNames</code>里面所有所需字段的值，并将它们拼接为字符串，例如<code>&quot;{payerId=25;beneficiaryId=12}&quot;</code>。Flink 将计算该字符串的哈希值，并将此特定组合的数据处理分配给集群中的特定服务器。这样就会跟踪<em>付款人25</em>和<em>受益人12</em>之间的所有交易，并在所需的时间范围内评估定义的规则。</p><p>注意，<code>Keyed</code>引入了具有以下签名的包装器类作为输出类型<code>DynamicKeyFunction</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Keyed</span>&lt;<span class="title">IN</span>, <span class="title">KEY</span>, <span class="title">ID</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> IN wrapped;</span><br><span class="line">  <span class="keyword">private</span> KEY key;</span><br><span class="line">  <span class="keyword">private</span> ID id;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">  <span class="function"><span class="keyword">public</span> KEY <span class="title">getKey</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> key;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此 POJO 的字段携带了以下信息：<code>wrapped</code>是原始数据，<code>key</code>是使用 <code>KeysExtractor</code>提取出来的结果，<code>id</code>是导致事件的调度规则的 ID（根据规则特定的分组逻辑）。</p><p>这种类型的事件将作为<code>keyBy()</code>函数的输入，并允许使用简单的 lambda 表达式作为<a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/api_concepts.html#define-keys-using-key-selector-functions"><code>KeySelector</code></a>实现动态数据 shuffle 的最后一步。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Alert&gt; alerts =</span><br><span class="line">    transactions</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicKeyFunction())</span><br><span class="line">        .keyBy((keyed) -&gt; keyed.getKey());</span><br><span class="line">        .process(<span class="keyword">new</span> DynamicAlertFunction())</span><br></pre></td></tr></table></figure><p>通过应用，<code>DynamicKeyFunction</code>我们隐式复制了事件，以便在 Flink 集群中并行的执行每个规则评估。通过这样做，我们获得了一个重要的功能——规则处理的水平可伸缩性。通过向集群添加更多服务器，即增加并行度，我们的系统将能够处理更多规则。实现此功能的代价是数据重复，这可能会成为一个问题，具体取决于一组特定的参数，例如传入数据速率，可用网络带宽，事件有效负载大小等。在实际情况下，可以进行其他优化应用，例如组合计算具有相同groupingKeyNames 的规则，或使用过滤层，将事件中不需要处理特定规则的所有字段删除。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在此博客文章中，我们通过查看示例用例（欺诈检测引擎）讨论了如何对 Flink 应用程序进行动态，运行时更改。我们已经描述了总体项目结构及其组件之间的交互，并提供了使用 docker 进行构建和运行演示欺诈检测应用程序。然后，我们展示了将 <strong>数据动态分区</strong> ，这是第一个实现灵活的动态配置的代码案例。</p><p>为了专注于描述本案例的核心机制，我们将 DSL 和基本规则引擎的复杂性降至最低。在未来，不难想象会添加一些扩展，例如允许使用更复杂的规则定义，包括某些事件的过滤，逻辑规则链接以及其他更高级的功能。</p><p>在本系列的第二篇博客中，我们将描述规则如何进入正在运行的欺诈检测引擎。此外，我们将详细介绍引擎的主要处理功能 <em>DynamicAlertFunction()</em> 的实现细节。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2021-01-22-011700.jpg" alt=""></p><p>在下一篇文章中，我们会教大家如何利用 Apache Flink 的广播流在我们的欺诈检测系统中动态的处理规则。</p><blockquote><p>本篇文章属于翻译文章，作者：zhisheng</p><p>原文地址：<a href="http://www.54tianzhisheng.cn/2021/01/22/Flink-Fraud-Detection-engine/">http://www.54tianzhisheng.cn/2021/01/22/Flink-Fraud-Detection-engine/</a></p><p>英文作者：<a href="https://twitter.com/alex_fedulov">alex_fedulov</a> </p><p>英文原文地址：<a href="https://flink.apache.org/news/2020/01/15/demo-fraud-detection.html">https://flink.apache.org/news/2020/01/15/demo-fraud-detection.html</a></p></blockquote><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何实现呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink Forward Asia 2020 全部 PPT 开放下载</title>
    <link href="http://www.54tianzhisheng.cn/2020/12/21/flink-forward-Asia-2020/"/>
    <id>http://www.54tianzhisheng.cn/2020/12/21/flink-forward-Asia-2020/</id>
    <published>2020-12-20T16:00:00.000Z</published>
    <updated>2020-12-21T15:12:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink Forward Asia 2020 在北京召开的，有主会场和几个分会场（企业实践、Apache Flink 核心技术、开源大数据生态、实时数仓、人工智能），内容涉及很多，可以查看下面图片介绍。</p><a id="more"></a><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142353.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142431.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142511.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142538.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142616.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-12-21-142643.png" alt=""></p><h3 id="如何获取上面这些-PPT？"><a href="#如何获取上面这些-PPT？" class="headerlink" title="如何获取上面这些 PPT？"></a>如何获取上面这些 PPT？</h3><p>上面的这些 PPT 本人已经整理好了，你可以扫描下面二维码，关注微信公众号：zhisheng，然后在里面回复关键字: <strong>ffa2020</strong> 即可获取已放出的 PPT。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-28-144329.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink Forward Asia 2020 在北京召开的，有主会场和几个分会场（企业实践、Apache Flink 核心技术、开源大数据生态、实时数仓、人工智能），内容涉及很多，可以查看下面图片介绍。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.12 Release 文档解读</title>
    <link href="http://www.54tianzhisheng.cn/2020/12/06/Flink-1.12/"/>
    <id>http://www.54tianzhisheng.cn/2020/12/06/Flink-1.12/</id>
    <published>2020-12-05T16:00:00.000Z</published>
    <updated>2020-12-06T13:47:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.12 快要发布了，这里提前解读一下 Release 文档</p><a id="more"></a><p>本文的 Release 文档描述了在 Flink 1.11 和 Flink 1.12 之间更改的重要方面，例如配置，行为或依赖项。 如果您打算将 Flink 版本升级到 1.12，请仔细阅读这些说明。</p><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><p><strong>移除掉 ExecutionConfig 中过期的方法</strong></p><p>移除掉了 <code>ExecutionConfig#isLatencyTrackingEnabled</code> 方法, 你可以使用 <code>ExecutionConfig#getLatencyTrackingInterval</code> 方法代替.</p><p>移除掉了 <code>ExecutionConfig#enable/disableSysoutLogging</code>、<code>ExecutionConfig#set/isFailTaskOnCheckpointError</code> 过期的方法。</p><p>移除掉了 <code>-q</code> CLI 参数。</p><p><strong>移除掉过期的 <code>RuntimeContext#getAllAccumulators</code> 方法</strong></p><p>过期的 <code>RuntimeContext#getAllAccumulators</code> 方法被移除掉了，请使用 <code>RuntimeContext#getAccumulator</code> 方法作为代替。</p><p><strong>由于数据丢失的风险把 <code>CheckpointConfig#setPreferCheckpointForRecovery</code> 方法标为过期</strong></p><p><code>CheckpointConfig#setPreferCheckpointForRecovery</code> 方法标记为过期了, 因为作业在进行恢复时，如果使用较旧的 Checkpoint 状态而不使用新的 Save point 状态数据，可能会导致数据丢失。</p><p><strong>FLIP-134: DataStream API 的批处理执行</strong></p><ul><li>允许在 <code>KeyedStream.intervalJoin()</code> 的配置时间属性，在 Flink 1.12 之前 <code>KeyedStream.intervalJoin()</code> 算子的时间属性依赖于全局设置的时间属性。在 Flink 1.12 中我们可以在 IntervalJoin 方法后加上 <code>inProcessingTime()</code> 或 <code>inEventTime()</code> ，这样 Join 就不再依赖于全局的时间属性。</li></ul><ul><li><p>在 Flink 1.12 中将 DataStream API 的 <code>timeWindow()</code> 方法标记为过期，请使用 <code>window(WindowAssigner)</code>、<code>TumblingEventTimeWindows</code>、 <code>SlidingEventTimeWindows</code>、<code>TumblingProcessingTimeWindows</code> 或者 <code>SlidingProcessingTimeWindows</code>。</p></li><li><p>将 <code>StreamExecutionEnvironment.setStreamTimeCharacteristic()</code> 和 <code>TimeCharacteristic</code> 方法标记为过期。在 Flink 1.12 中，默认的时间属性改变成 EventTime 了，于是你不再需要该方法去开启 EventTime 了。在 EventTime 时间属性下，你使用 processing-time 的 windows 和 timers 也都依旧会生效。如果你想禁用水印，请使用 <code>ExecutionConfig.setAutoWatermarkInterval(long)</code> 方法。如果你想使用 <code>IngestionTime</code>，请手动设置适当的 WatermarkStrategy。如果你使用的是基于时间属性更改行为的通用 ‘time window’ 算子(eg: <code>KeyedStream.timeWindow()</code>)，请使用等效操作明确的指定处理时间和事件时间。</p></li><li><p>允许在 CEP PatternStream 上显式配置时间属性在 Flink 1.12 之前，CEP 算子里面的时间依赖于全局配置的时间属性，在 1.12 之后可以在 PatternStream 上使用 <code>inProcessingTime()</code> 或 <code>inEventTime()</code> 方法。</p></li></ul><p><strong>API 清理</strong></p><ul><li><p>移除了 UdfAnalyzer 配置，移除了 <code>ExecutionConfig#get/setCodeAnalysisMode</code> 方法和 <code>SkipCodeAnalysis</code> 类。</p></li><li><p>移除了过期的 <code>DataStream#split</code> 方法，该方法从很早的版本中已经标记成为过期的了，你可以使用 Side Output 来代替。</p></li><li><p>移除了过期的 <code>DataStream#fold()</code> 方法和其相关的类，你可以使用更加高性能的 <code>DataStream#reduce</code>。</p></li></ul><p><strong>扩展 CompositeTypeSerializerSnapshot 以允许复合序列化器根据外部配置迁移</strong></p><p>不再推荐使用 CompositeTypeSerializerSnapshot 中的 <code>isOuterSnapshotCompatible(TypeSerializer)</code> 方法，推荐使用 <code>OuterSchemaCompatibility#resolveOuterSchemaCompatibility(TypeSerializer)</code> 方法。</p><p><strong>将 Scala 版本升级到 2.1.1</strong></p><p>Flink 现在依赖 Scala 2.1.1，意味着不再支持 Scala 版本小于 2.11.11。</p><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><p><strong>对 aggregate 函数的 SQL DDL 使用新类型推断</strong></p><p>aggregate 函数的 <code>CREATE FUNCTION</code> DDL 现在使用新类型推断，可能有必要将现有实现更新为新的反射类型提取逻辑，将 <code>StreamTableEnvironment.registerFunction</code> 标为过期。</p><p><strong>更新解析器模块 FLIP-107</strong></p><p>现在 <code>METADATA</code> 属于保留关键字，记得使用反引号转义。</p><p><strong>将内部 aggregate 函数更新为新类型</strong></p><p>使用 COLLECT 函数的 SQL 查询可能需要更新为新类型的系统。</p><h2 id="Connectors-和-Formats"><a href="#Connectors-和-Formats" class="headerlink" title="Connectors 和 Formats"></a>Connectors 和 Formats</h2><p><strong>移除 Kafka 0.10.x 和 0.11.x Connector</strong></p><p>在 Flink 1.12 中，移除掉了 Kafka 0.10.x 和 0.11.x Connector，请使用统一的 Kafka Connector（适用于 0.10.2.x 版本之后的任何 Kafka 集群），你可以参考 Kafka Connector 页面的文档升级到新的 Flink Kafka Connector 版本。</p><p><strong>CSV 序列化 Schema 包含行分隔符</strong></p><p><code>csv.line-delimiter</code> 配置已经从 CSV 格式中移除了，因为行分隔符应该由 Connector 定义而不是由 format 定义。如果用户在以前的 Flink 版本中一直使用了该配置，则升级到 Flink 1.12 时，应该删除该配置。</p><p><strong>升级 Kafka Schema Registry Client 到 5.5.0 版本</strong></p><p><code>flink-avro-confluent-schema-registry</code> 模块不再在 fat-jar 中提供，你需要显式的在你自己的作业中添加该依赖，SQL-Client 用户可以使用<code>flink-sql-avro-confluent-schema-registry</code> fat jar。</p><p><strong>将 Avro 版本从 1.8.2 升级到 1.10.0 版本</strong></p><p><code>flink-avro</code> 模块中的 Avro 版本升级到了 1.10，如果出于某种原因要使用较旧的版本，请在项目中明确降级 Avro 版本。</p><p><strong>注意</strong>：我们观察到，与 1.8.2 相比，Avro 1.10 版本的性能有所下降，如果你担心性能，并且可以使用较旧版本的 Avro，那么请降级 Avro 版本。</p><p><strong>为 SQL Client 打包 <code>flink-avro</code> 模块时会创建一个 uber jar</strong></p><p>SQL Client jar 会被重命名为 <code>flink-sql-avro-1.12.jar</code>，以前是 <code>flink-avro-1.12-sql-jar.jar</code>，而且不再需要手动添加 Avro 依赖。</p><h2 id="Deployment（部署）"><a href="#Deployment（部署）" class="headerlink" title="Deployment（部署）"></a>Deployment（部署）</h2><p><strong>默认 Log4j 配置了日志大小超过 100MB 滚动</strong></p><p>默认的 log4j 配置现在做了变更：除了在 Flink 启动时现有的日志文件滚动外，它们在达到 100MB 大小时也会滚动。Flink 总共保留 10 个日志文件，从而有效地将日志目录的总大小限制为 1GB（每个 Flink 服务记录到该目录）。</p><p><strong>默认在 Flink Docker 镜像中使用 jemalloc</strong></p><p>在 Flink 的 Docker 镜像中，jemalloc 被用作默认的内存分配器，以减少内存碎片问题。用户可以通过将 <code>disable-jemalloc</code> 标志传递给 <code>docker-entrypoint.sh</code> 脚本来回滚使用 glibc。有关更多详细信息，请参阅 Docker 文档上的 Flink。</p><p><strong>升级 Mesos 版本到 1.7</strong></p><p>将 Mesos 依赖版本从 1.0.1 版本升级到 1.7.0 版本。</p><p><strong>如果 Flink 进程在超时后仍未停止，则发送 SIGKILL</strong></p><p>在 Flink 1.12 中，如果 SIGTERM 无法成功关闭 Flink 进程，我们更改了独立脚本的行为以发出 SIGKILL。</p><p><strong>介绍非阻塞作业提交</strong></p><p>提交工作的语义略有变化，提交调用几乎立即返回，并且作业处于新的 INITIALIZING 状态，当作业处于该状态时，对作业做 Savepoint 或者检索作业详情信息等操作将不可用。</p><p>一旦创建了该作业的 JobManager，该作业就处于 CREATED 状态，并且所有的调用均可用。</p><h2 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h2><p><strong>FLIP-141: Intra-Slot Managed Memory 共享</strong></p><p><code>python.fn-execution.buffer.memory.size</code> 和 <code>python.fn-execution.framework.memory.size</code> 的配置已删除，因此不再生效。除此之外，<code>python.fn-execution.memory.managed</code> 默认的值更改为 <code>true</code>， 因此默认情况下 Python workers 将使用托管内存。</p><p><strong>FLIP-119 Pipelined Region Scheduling</strong></p><p>从 Flink 1.12 开始，将以 pipelined region 为单位进行调度。pipelined region 是一组流水线连接的任务。这意味着，对于包含多个 region 的流作业，在开始部署任务之前，它不再等待所有任务获取 slot。取而代之的是，一旦任何 region 获得了足够的任务 slot 就可以部署它。对于批处理作业，将不会为任务分配 slot，也不会单独部署任务。取而代之的是，一旦某个 region 获得了足够的 slot，则该任务将与所有其他任务一起部署在同一区域中。</p><p>可以使用 <code>jobmanager.scheduler.scheduling-strategy：legacy</code> 启用旧的调度程序。</p><p><strong>RocksDB optimizeForPointLookup 导致丢失时间窗口</strong></p><p>默认情况下，我们会将 RocksDB 的 ReadOptions 的 setTotalOrderSeek 设置为true，以防止用户忘记使用 optimizeForPointLookup。 同时，我们支持通过RocksDBOptionsFactory 自定义 ReadOptions。如果观察到任何性能下降，请将 setTotalOrderSeek 设置为 false（根据我们的测试，这是不可能的）。</p><p><strong>自定义 OptionsFactory 设置似乎对 RocksDB 没有影响</strong></p><p>过期的 OptionsFactory 和 ConfigurableOptionsFactory 类已移除，请改用 RocksDBOptionsFactory 和 ConfigurableRocksDBOptionsFactory。 如果有任何扩展 DefaultConfigurableOptionsFactory 的类，也请重新编译你的应用程序代码。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.12 快要发布了，这里提前解读一下 Release 文档&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>强烈推荐三本 Spark 新书籍</title>
    <link href="http://www.54tianzhisheng.cn/2020/10/18/Spark-book/"/>
    <id>http://www.54tianzhisheng.cn/2020/10/18/Spark-book/</id>
    <published>2020-10-17T16:00:00.000Z</published>
    <updated>2020-10-18T10:49:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>挺好的三本书</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>看到标题大家可能会想，zhisheng 之前不是一直写 Flink 相关的文章吗？咋开始推荐 Spark 书籍了，这里解释一下，因为本人前段时间接手了公司 Spark 引擎，所以偶尔也会抽空学习一下 Spark，这不看到几本不错的 Spark 书籍，于是想在这里与大家分享一下。</p><h3 id="《Stream-Processing-with-Apache-Spark》"><a href="#《Stream-Processing-with-Apache-Spark》" class="headerlink" title="《Stream Processing with Apache Spark》"></a>《Stream Processing with Apache Spark》</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-101423.png" alt=""></p><p>这本书出版时间是 2019 年 6 月，算是与 《Stream Processing with Apache Flink》是姊妹篇，主要是讲 Spark 的流处理，比如 Structured Streaming 和 Spark Streaming，对 Spark 流处理感兴趣的不可错过该书，虽然现在 Flink 是流处理的 No1，但是并不影响对比着学习他们之间的技术。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-100905.png" alt="流处理章节目录"></p><h3 id="《Learning-Spark-2nd-Edition》"><a href="#《Learning-Spark-2nd-Edition》" class="headerlink" title="《Learning Spark, 2nd Edition》"></a>《Learning Spark, 2nd Edition》</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-101504.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-101551.png" alt=""></p><p>这本书出版时间是 2020 年 7 月，全书我觉得对于整个 Spark 的体系讲的还是很全的，从概念的介绍，到 API / SQL 的使用，再到如何优化 Spark 作业，接着讲解了 Structured Streaming，然后还讲解了通过 Spark 构建数据湖，并且该章节中还对目前很热门的三大数据湖框架 Apache Hudi / Apache Iceberg / Delta Lake 进行了介绍。接着讲解了 Spark 在机器学习相关场景的水碱和应用，最后介绍了 Spark 3.0 的新特性，也是目前唯一不多介绍 Spark 3.0 版本的书籍之一。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-102258.png" alt="本书的目录"></p><h3 id="《Spark-in-Action-2nd-Edition》"><a href="#《Spark-in-Action-2nd-Edition》" class="headerlink" title="《Spark in Action, 2nd Edition》"></a>《Spark in Action, 2nd Edition》</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-102357.png" alt=""></p><p>本书出版时间是 2020 年 5 月，出版社是 Manning，不同于上面两本书是出版于 O’Reilly。本书内容跟其标题其实还是比较相符的，主讲实战，目录如下。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-103030.png" alt=""></p><p>扫描下面二维码，回复 Spark 可获取本文提及到的三本书</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-18-103615.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;挺好的三本书&lt;/p&gt;
    
    </summary>
    
    
      <category term="Spark" scheme="http://www.54tianzhisheng.cn/tags/Spark/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>用了 Flink History Server，妈妈再也不用担心我的作业半夜挂了</title>
    <link href="http://www.54tianzhisheng.cn/2020/10/13/flink-history-server/"/>
    <id>http://www.54tianzhisheng.cn/2020/10/13/flink-history-server/</id>
    <published>2020-10-12T16:00:00.000Z</published>
    <updated>2020-10-15T00:34:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>保存作业停止之前的信息</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Flink On YARN 默认作业挂了之后打开的话，是一个如下这样的页面：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-151818.jpg" alt="作业失败后"></p><p>对于这种我们页面我们只能查看 JobManager 的日志，不再可以查看作业挂掉之前的运行的 Web UI，很难清楚知道作业在挂的那一刻到底发生了啥？如果我们还没有 Metrics 监控的话，那么完全就只能通过日志去分析和定位问题了，所以如果能还原之前的 Web UI，我们可以通过 UI 发现和定位一些问题。</p><h3 id="History-Server-介绍"><a href="#History-Server-介绍" class="headerlink" title="History Server 介绍"></a>History Server 介绍</h3><p>那么这里就需要利用 Flink 中的 History Server 来解决这个问题。那么 History Server 是什么呢？</p><p>它可以用来在相应的 Flink 集群关闭后查询已完成作业的统计信息。例如有个批处理作业是凌晨才运行的，并且我们都知道只有当作业处于运行中的状态，才能够查看到相关的日志信息和统计信息。所以如果作业由于异常退出或者处理结果有问题，我们又无法及时查看（凌晨运行的）作业的相关日志信息。那么 History Server 就显得十分重要了，因为通过 History Server 我们才能查询这些已完成作业的统计信息，无论是正常退出还是异常退出。</p><p>此外，它对外提供了 REST API，它接受 HTTP 请求并使用 JSON 数据进行响应。Flink 任务停止后，JobManager 会将已经完成任务的统计信息进行存档，History Server 进程则在任务停止后可以对任务统计信息进行查询。比如：最后一次的 Checkpoint、任务运行时的相关配置。</p><p>那么如何开启这个呢？你需要在 flink-conf.yml 中配置如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>==============================================================================</span><br><span class="line"><span class="meta">#</span> HistoryServer</span><br><span class="line"><span class="meta">#</span>==============================================================================</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> The HistoryServer is started and stopped via bin/historyserver.sh (start|stop)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Directory to upload completed jobs to. Add this directory to the list of</span><br><span class="line"><span class="meta">#</span> monitored directories of the HistoryServer as well (see below). </span><br><span class="line"><span class="meta">#</span> flink job 运行完成后的日志存放目录</span><br><span class="line">jobmanager.archive.fs.dir: hdfs:///flink/history-log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> The address under which the web-based HistoryServer listens.</span><br><span class="line"><span class="meta">#</span> flink history进程所在的主机</span><br><span class="line"><span class="meta">#</span>historyserver.web.address: 0.0.0.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> The port under which the web-based HistoryServer listens.</span><br><span class="line"><span class="meta">#</span> flink history进程的占用端口</span><br><span class="line"><span class="meta">#</span>historyserver.web.port: 8082</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Comma separated list of directories to monitor for completed jobs.</span><br><span class="line"><span class="meta">#</span> flink history进程的hdfs监控目录</span><br><span class="line">historyserver.archive.fs.dir: hdfs:///flink/history-log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Interval in milliseconds for refreshing the monitored directories.</span><br><span class="line"><span class="meta">#</span> 刷新受监视目录的时间间隔（以毫秒为单位）</span><br><span class="line"><span class="meta">#</span>historyserver.archive.fs.refresh-interval: 10000</span><br></pre></td></tr></table></figure><p>注意： <strong>jobmanager.archive.fs.dir 要和 historyserver.archive.fs.dir 配置的路径要一样</strong> </p><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/historyserver.sh start</span><br></pre></td></tr></table></figure><p>发现报错如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">2020-10-13 21:21:01,310 main INFO  org.apache.flink.core.fs.FileSystem                           - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.</span><br><span class="line">2020-10-13 21:21:01,336 main INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory  - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.</span><br><span class="line">2020-10-13 21:21:01,352 main INFO  org.apache.flink.runtime.security.modules.JaasModule          - Jaas file will be created as /tmp/jaas-354359771751866787.conf.</span><br><span class="line">2020-10-13 21:21:01,355 main INFO  org.apache.flink.runtime.security.SecurityUtils               - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.</span><br><span class="line">2020-10-13 21:21:01,363 main WARN  org.apache.flink.runtime.webmonitor.history.HistoryServer     - Failed to create Path or FileSystem for directory 'hdfs:///flink/history-log'. Directory will not be monitored.</span><br><span class="line">org.apache.flink.core.fs.UnsupportedFileSystemSchemeException: Could not find a file system implementation for scheme 'hdfs'. The scheme is not directly supported by Flink and no Hadoop file system to support this scheme could be loaded.</span><br><span class="line">        at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:450)</span><br><span class="line">        at org.apache.flink.core.fs.FileSystem.get(FileSystem.java:362)</span><br><span class="line">        at org.apache.flink.core.fs.Path.getFileSystem(Path.java:298)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.&lt;init&gt;(HistoryServer.java:187)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.&lt;init&gt;(HistoryServer.java:137)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer$1.call(HistoryServer.java:122)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer$1.call(HistoryServer.java:119)</span><br><span class="line">        at org.apache.flink.runtime.security.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:30)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.main(HistoryServer.java:119)</span><br><span class="line">Caused by: org.apache.flink.core.fs.UnsupportedFileSystemSchemeException: Hadoop is not in the classpath/dependencies.</span><br><span class="line">        at org.apache.flink.core.fs.UnsupportedSchemeFactory.create(UnsupportedSchemeFactory.java:58)</span><br><span class="line">        at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:446)</span><br><span class="line">        ... 8 more</span><br><span class="line">2020-10-13 21:21:01,367 main ERROR org.apache.flink.runtime.webmonitor.history.HistoryServer     - Failed to run HistoryServer.</span><br><span class="line">org.apache.flink.util.FlinkException: Failed to validate any of the configured directories to monitor.</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.&lt;init&gt;(HistoryServer.java:196)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.&lt;init&gt;(HistoryServer.java:137)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer$1.call(HistoryServer.java:122)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer$1.call(HistoryServer.java:119)</span><br><span class="line">        at org.apache.flink.runtime.security.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:30)</span><br><span class="line">        at org.apache.flink.runtime.webmonitor.history.HistoryServer.main(HistoryServer.java:119)</span><br></pre></td></tr></table></figure><p>这个异常的原因是因为 Flink 集群的 CLASS_PATH 下缺少了 HDFS 相关的 jar，我们可以引入 HDFS 的依赖放到 lib 目录下面或者添加 Hadoop 的环境变量。</p><p>这里我们在 historyserver.sh 脚本中增加下面脚本，目的就是添加 Hadoop 的环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> export hadoop classpath</span><br><span class="line">if [ `command -v hadoop` ];then</span><br><span class="line">  export HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line">else</span><br><span class="line">  echo "hadoop command not found in path!"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p>添加后再启动脚本则可以运行成功了，打开页面 <code>机器IP:8082</code> 则可以看到历史所有运行完成或者失败的作业列表信息。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-141733.png" alt="作业列表信息"></p><p>点进单个作业可以看到作业挂之前的所有信息，便于我们去查看挂之前作业的运行情况（Exception 信息/Checkpoint 信息/算子的流入和流出数据量信息等）</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-142108.png" alt="作业挂之前的运行情况"></p><h3 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h3><p>再来看看配置的 <code>/flink/history-log/</code> 目录有什么东西呢？执行下面命令可以查看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls /flink/history-log/</span><br></pre></td></tr></table></figure><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-152148.jpg" alt="hdfs 文件目录"></p><p>其实 history server 会在本地存储已结束 Job 信息，你可以配置 <code>historyserver.web.tmpdir</code> 来决定存储在哪，默认的拼接规则为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.getProperty(<span class="string">"java.io.tmpdir"</span>) + File.separator + <span class="string">"flink-web-history-"</span> + UUID.randomUUID()</span><br></pre></td></tr></table></figure><p>Linux 系统临时目录为 /tmp，你可以看到源码中 HistoryServerOptions 该类中的可选参数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* The local directory used by the HistoryServer web-frontend.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;String&gt; HISTORY_SERVER_WEB_DIR =</span><br><span class="line">    key(<span class="string">"historyserver.web.tmpdir"</span>)</span><br><span class="line">        .noDefaultValue()</span><br><span class="line">        .withDescription(<span class="string">"This configuration parameter allows defining the Flink web directory to be used by the"</span> +</span><br><span class="line">            <span class="string">" history server web interface. The web interface will copy its static files into the directory."</span>);</span><br></pre></td></tr></table></figure><p>那么我们找到本地该临时目录，可以观察到里面保存着很多 JS 文件，其实就是我们刚才看到的页面</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-152227.jpg" alt="本地临时目录"></p><p>历史服务存储文件中，存储了用于页面展示的模板配置。历史任务信息存储在 Jobs 路径下，其中包含了已经完成的 Job，每次启动都会从 historyserver.archive.fs.dir 拉取所有的任务元数据信息。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-152249.jpg" alt="Jobs 目录"></p><p>每个任务文件夹中包含我们需要获取的一些信息，通过 REST API 获取时指标时，就是返回这些内容（Checkpoint/Exception 信息等）。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-13-152331.jpg" alt="具体 Job"></p><h3 id="REST-API"><a href="#REST-API" class="headerlink" title="REST API"></a>REST API</h3><p>以下是可用且带有示例 JSON 响应的请求列表。所有请求格式样例均为 <code>http://hostname:8082/jobs</code>，下面我们仅列出了 URLs 的 <em>path</em> 部分。 尖括号中的值为变量，例如作业 <code>7684be6004e4e955c2a558a9bc463f65</code> 的 <code>http://hostname:port/jobs/&lt;jobid&gt;/exceptions</code> 请求须写为 <code>http://hostname:port/jobs/7684be6004e4e955c2a558a9bc463f65/exceptions</code>。</p><ul><li><code>/config</code></li><li><code>/jobs/overview</code></li><li><code>/jobs/&lt;jobid&gt;</code></li><li><code>/jobs/&lt;jobid&gt;/vertices</code></li><li><code>/jobs/&lt;jobid&gt;/config</code></li><li><code>/jobs/&lt;jobid&gt;/exceptions</code></li><li><code>/jobs/&lt;jobid&gt;/accumulators</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasktimes</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/taskmanagers</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/accumulators</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasks/accumulators</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasks/&lt;subtasknum&gt;</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasks/&lt;subtasknum&gt;/attempts/&lt;attempt&gt;</code></li><li><code>/jobs/&lt;jobid&gt;/vertices/&lt;vertexid&gt;/subtasks/&lt;subtasknum&gt;/attempts/&lt;attempt&gt;/accumulators</code></li><li><code>/jobs/&lt;jobid&gt;/plan</code></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这样我们就可以开心的去查看作业挂之前的 Web UI 信息了，妈妈在也不用担心我的作业挂了！😁</p><h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><ul><li><a href="https://ci.apache.org/projects/flink/flink-docs-master/zh/monitoring/historyserver.html">History Server</a> </li><li><a href="https://www.jianshu.com/p/48aaad9cfc7d">flink历史服务</a> </li></ul><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;保存作业停止之前的信息&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>如何生成 Flink 作业的交互式火焰图？</title>
    <link href="http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/"/>
    <id>http://www.54tianzhisheng.cn/2020/10/05/flink-jvm-profiler/</id>
    <published>2020-10-04T16:00:00.000Z</published>
    <updated>2020-10-11T14:09:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 作业生成火焰图</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Flink 是目前最流行的大数据及流式计算框架之一，用户可以使用 Java/Scala/Python  的DataStream 接口或者标准 SQL 语言来快速实现一个分布式高可用的流式应用，通过内部的 Java JIT、off-heap 内存管理等技术优化性能，并且有完整的 Source、Sink、WebUI、Metrics 等功能集成，让 Flink 几乎成为了流式计算的事实标准。</p><p>但是当处理海量数据的时候，很容易出现各种异常和性能瓶颈，这时我们需要优化系统性能时，常常需要分析程序运行行为和性能瓶颈。Profiling 技术是一种在应用运行时收集程序相关信息的动态分析手段，常用的 JVM Profiler 可以从多个方面对程序进行动态分析，如 CPU、Memory、Thread、Classes、GC 等，其中 CPU Profiling 的应用最为广泛。CPU Profiling 经常被用于分析代码的执行热点，如“哪个方法占用 CPU 的执行时间最长”、“每个方法占用 CPU 的比例是多少”等等，通过 CPU Profiling 得到上述相关信息后，研发人员就可以轻松针对热点瓶颈进行分析和性能优化，进而突破性能瓶颈，大幅提升系统的吞吐量。</p><p>本文介绍我们在做性能优化常用的火焰图以及为如何集成火焰图到通用的 Flink 作业中。</p><h3 id="火焰图介绍"><a href="#火焰图介绍" class="headerlink" title="火焰图介绍"></a>火焰图介绍</h3><p>火焰图是《性能之巅》作者以及 DTrace 等一系列 Linux 系统优化工具作者 Brendan Gregg 大神的作品之一，可以非常清晰地展示应用程序的函数调用栈以及函数调用时间占比，基本原理是通过各种 agent 在程序运行时采样并输出日志，使用 FlameGraph 工具把日志提取出来输出可在浏览器交互式查看的 SVG图片。</p><p>Uber 开源了 jvm-profiler 项目，介绍如何为 Spark 应用和 Java 应用添加火焰图支持，但是目前 Flink 社区和  jvm-profiler 官网都还没有相关的使用教程。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-06-3411601968266_.pic_hd.jpg" alt=""></p><p>实际上基于 JVM 的程序都可以使用这个工具，本文将基于 jvm-profiler 来介绍如何生成 Flink 作业的火焰图。</p><h3 id="下载和编译-jvm-profiler"><a href="#下载和编译-jvm-profiler" class="headerlink" title="下载和编译 jvm-profiler"></a>下载和编译 jvm-profiler</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone git clone https://github.com/uber-common/jvm-profiler.git</span><br><span class="line"></span><br><span class="line">mvn clean install -DskipTests=true -Dcheckstyle.skip -Dfast -T 8C</span><br></pre></td></tr></table></figure><p>编译好了之后，将项目 target 目录下的 jvm-profiler-1.0.0.jar 复制一份到 flink 的 lib 目录下面</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp target/jvm-profiler-1.0.0.jar /usr/local/flink-1.11.1/lib</span><br></pre></td></tr></table></figure><h3 id="下载-FlameGraph"><a href="#下载-FlameGraph" class="headerlink" title="下载 FlameGraph"></a>下载 FlameGraph</h3><p>由于 jvm-profiler 支持生成火焰图需要的日志文件，将日志转化成交互式 SVG 图片还是使用 Brendan Gregg 的FlameGraph 工具。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/brendangregg/FlameGraph.git</span><br></pre></td></tr></table></figure><p>下载项目源码即可，后面会使用 flamegraph.pl 工具来生成图片文件。</p><h3 id="配置-Flink"><a href="#配置-Flink" class="headerlink" title="配置 Flink"></a>配置 Flink</h3><p>对于 Flink 应用，我们只需要在 TaskManager 中注入打点的 Java agent 即可，这里测试，我就使用本地 standalone 模式，修改 Flink conf 目录下的 flink-conf.yaml 文件，添加一下如下配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.java.opts.taskmanager: "-javaagent:/usr/local/flink-1.11.1/lib/jvm-profiler-1.0.0.jar=sampleInterval=50"</span><br></pre></td></tr></table></figure><p>目前最小的采样间隔就是 50 毫秒，然后启动集群和运行一个 Flink 作业：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./bin/start-cluster.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//运行一个作业</span><br><span class="line">./bin/flink run ./examples/streaming/StateMachineExample.jar</span><br></pre></td></tr></table></figure><p>运行之后可以看到 TaskManager 的 stdout 里面打印如下：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-06-3421601969081_.pic_hd.jpg" alt=""></p><p>因为已经注入 Java agent，因此在标准输出中会定期添加火焰图所需要的打点数据，然后使用下面的命令提取相关日志，并且使用 jvm-profiler 和 FlameGraph 提供的工具来生成 SVG 图片文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//1、提取 stdout 文件中的相关日志</span><br><span class="line"></span><br><span class="line">cat log/flink-zhisheng-taskexecutor-0-zhisheng.out | grep "ConsoleOutputReporter - Stacktrace:" | awk '&#123;print substr($0,37)&#125;' &gt; stacktrace.json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//2、在 jvm-profiler 目录下执行下面命令</span><br><span class="line"></span><br><span class="line">python ./stackcollapse.py -i /usr/local/flink-1.11.1/stacktrace.json &gt; stacktrace.folded</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//3、在 FlameGraph 目录下执行下面命令生成 SVG 图片</span><br><span class="line"></span><br><span class="line">./flamegraph.pl /Users/zhisheng/Documents/github/jvm-profiler/stacktrace.folded &gt; stacktrace.svg</span><br></pre></td></tr></table></figure><p>然后用浏览器打开刚才生成的 SVG 图片就可以看到火焰图信息。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-10-06-073728.png" alt=""></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文主要目的在于教大家如何利用 jvm-profiler 去生成 Flink 作业的运行火焰图，这样可以在遇到性能瓶颈问题的时候会很方便大家去定位问题，关于如何去读懂生成的火焰图，后面可以再分享系列文章。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://tech.meituan.com/2019/10/10/jvm-cpu-profiler.html">JVM CPU Profiler技术原理及源码深度解析</a> </li><li><a href="https://github.com/uber-common/jvm-profiler">jvm-profile</a> </li></ul><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 作业生成火焰图&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
</feed>
