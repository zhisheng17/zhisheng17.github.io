<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhisheng的博客</title>
  
  <subtitle>坑要一个个填，路要一步步走！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.54tianzhisheng.cn/"/>
  <updated>2021-11-11T15:33:45.652Z</updated>
  <id>http://www.54tianzhisheng.cn/</id>
  
  <author>
    <name>zhisheng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>宕机一台机器，结果一百多个 Flink 作业挂了</title>
    <link href="http://www.54tianzhisheng.cn/2021/11/11/flink-akka-framesize/"/>
    <id>http://www.54tianzhisheng.cn/2021/11/11/flink-akka-framesize/</id>
    <published>2021-11-10T16:00:00.000Z</published>
    <updated>2021-11-11T15:33:45.652Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>因宕机了一台物理机器，实时集群不少作业发生 failover，其中大部分作业都能 failover 成功，某个部门的部分作业一直在 failover，始终未成功，到 WebUI 查看作业异常日志如下：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">2021-11-09 16:01:11</span><br><span class="line">java.util.concurrent.CompletionException: java.lang.reflect.UndeclaredThrowableException</span><br><span class="line"> at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)</span><br><span class="line"> at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)</span><br><span class="line"> at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592)</span><br><span class="line"> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line"> at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line"> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)</span><br><span class="line"> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line"> at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: java.lang.reflect.UndeclaredThrowableException</span><br><span class="line"> at com.sun.proxy.$Proxy54.submitTask(Unknown Source)</span><br><span class="line"> at org.apache.flink.runtime.jobmaster.RpcTaskManagerGateway.submitTask(RpcTaskManagerGateway.java:72)</span><br><span class="line"> at org.apache.flink.runtime.executiongraph.Execution.lambda$deploy$10(Execution.java:756)</span><br><span class="line"> at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)</span><br><span class="line"> ... 7 more</span><br><span class="line">Caused by: java.io.IOException: The rpc invocation size 56424326 exceeds the maximum akka framesize.</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.createRpcInvocationMessage(AkkaInvocationHandler.java:276)</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.invokeRpc(AkkaInvocationHandler.java:205)</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.invoke(AkkaInvocationHandler.java:134)</span><br><span class="line"> ... 11 more</span><br></pre></td></tr></table></figure><h3 id="解决异常过程"><a href="#解决异常过程" class="headerlink" title="解决异常过程"></a>解决异常过程</h3><p>从上面的异常日志中我们提取到关键信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.io.IOException: The rpc invocation size 56424326 exceeds the maximum akka framesize.</span><br></pre></td></tr></table></figure><p>看起来是 RPC 的消息大小超过了默认的 akka framesize 的最大值了，所以我们来了解一下这个值的默认值，从 <a href="https://nightlies.apache.org/flink/flink-docs-release-1.12/deployment/config.html#akka-framesize">官网</a> 我们可以看的到该值的默认大小为 “10485760b”，并且该参数的描述为：</p><p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gwbm72hedkj31i806imya.jpg" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Maximum size of messages which are sent between the JobManager and the TaskManagers. If Flink fails because messages exceed this limit, then you should increase it. The message size requires a size-unit specifier.</span><br></pre></td></tr></table></figure><p>翻译过来的意思就是：这个参数是 JobManager 和 TaskManagers 之间通信允许的最大消息大小，如果 Flink 作业因为通信消息大小超过了该值，你可以通过增加该值的大小来解决，该参数需要指定一个单位。</p><h3 id="分析原因"><a href="#分析原因" class="headerlink" title="分析原因"></a>分析原因</h3><p>Flink 使用 Akka 作为组件（JobManager/TaskManager/ResourceManager）之间的 RPC 框架，在 JobManager 和 TaskManagers 之间发送的消息的最大大小默认为 10485760b，如果消息超过这个限制就会失败，报错。这个可以看下抛出异常处的源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">protected RpcInvocation createRpcInvocationMessage(String methodName, Class&lt;?&gt;[] parameterTypes, Object[] args) throws IOException &#123;</span><br><span class="line">    Object rpcInvocation;</span><br><span class="line">    if (this.isLocal) &#123;</span><br><span class="line">        rpcInvocation = new LocalRpcInvocation(methodName, parameterTypes, args);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            RemoteRpcInvocation remoteRpcInvocation = new RemoteRpcInvocation(methodName, parameterTypes, args);</span><br><span class="line">            if (remoteRpcInvocation.getSize() &gt; this.maximumFramesize) &#123;</span><br><span class="line">                // 异常所在位置</span><br><span class="line">                throw new IOException(&quot;The rpc invocation size exceeds the maximum akka framesize.&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            rpcInvocation = remoteRpcInvocation;</span><br><span class="line">        &#125; catch (IOException var6) &#123;</span><br><span class="line">            LOG.warn(&quot;Could not create remote rpc invocation message. Failing rpc invocation because...&quot;, var6);</span><br><span class="line">            throw var6;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return (RpcInvocation)rpcInvocation;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至于为什么 JobManager 和 TaskManager 之间的 RPC 消息大小会如此之大，初步的解释是在 task 出现异常之后，它需要调用 updateTaskExecutionState(TaskExecutionState，taskExecutionState) 这个 RPC 接口去通知 Flink Jobmanager 去改变对应 task 的状态并且重启 task。但是呢，taskExecutionState 这个参数里面有个 error 属性，当我的 task 打出来的错误栈太多的时候，在序列化的之后超过了 rpc 接口要求的最大数据大小（也就是 maximum akka framesize），导致调用 updateTaskExecutionState 这个 rpc 接口失败，Jobmanager 无法获知这个 task 已经处于 fail 的状态，也无法重启，然后就导致了一系列连锁反应。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>任务停止，在 <code>flink-conf.yaml</code> 中加入 <code>akka.framesize</code> 参数，调大该值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">akka.framesize: &quot;62914560b&quot;</span><br></pre></td></tr></table></figure><p>然后将任务重启，可以观察 Jobmanager Configration 看看参数是否生效。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;因宕机了一台物理机器，实时集群不少作业发生 failover，其中大部分作业都能 failover 成功，某个部门的部分作业一直在 failover，始终未成功，到 WebUI 查看作业异常日志如下：&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>实时平台如何管理多个 Flink 版本？—— 为啥会出现多个版本？</title>
    <link href="http://www.54tianzhisheng.cn/2021/09/26/realtime-platform-flink-version/"/>
    <id>http://www.54tianzhisheng.cn/2021/09/26/realtime-platform-flink-version/</id>
    <published>2021-09-25T16:00:00.000Z</published>
    <updated>2021-11-14T03:12:49.099Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为啥会出现多个版本？"><a href="#为啥会出现多个版本？" class="headerlink" title="为啥会出现多个版本？"></a>为啥会出现多个版本？</h3><a id="more"></a><ul><li><p><strong>Flink 社区</strong>本身迭代速度非常快，目前阿里云有一大波的人专职做 Flink 开源，另外还拥有活跃的社区贡献者，所以功能开发较快，bug 修复速度较快，几乎每 4 个月一个大版本，每个大版本之间迭代的功能非常多，代码变动非常大，API 接口变动也大，动不动就干翻自己了。</p></li><li><p>社区迭代快就快呗，为什么<strong>公司</strong>也要要不断跟着社区鼻子走？社区迭代快意味着功能多，修复的 bug 多，相对于早期版本意味着稳定性也高些。除了国内一二线公司有特别多的专职人去负责这块，大多数中小公司最简单最快捷体验到稳定性最高、功能性最多、性能最好的 Flink 版本无非是直接使用最新的 Flink 版本。举个例子：Flink SQL 从最早期（1.9）的功能、性能到目前 1.14，差别真的大很多，优化了特别多的地方，增强了很多功能。原先使用 Flink SQL 完成一个流处理任务非常麻烦，还不如直接写几十行代码来的快，目前我情愿写 SQL 去处理一个流任务。那么自然会跟着升级到新版本。</p></li><li><p><strong>用户 A</strong> 问 Flink SQL 支持单独设置并行度吗？<strong>用户 B</strong> 问实时平台现在支持 Flink 1.13 版本的 Window TVF？这个要 Flink xxx 版本才能支持，要不你升级一下 Flink 版本到 xxx？这样就能支持了，类似的场景还有很多，对于<strong>中小公司的实时平台负责人</strong>来说，这无非最省事；对于<strong>大公司的负责实时开发的人</strong>来说，这无疑是一个噩梦，每次升级新版本都要将在老版本开发的各种功能都想尽办法移植到新版本上来，碰到 API 接口变动大的无非相当于重写了，或者将新版本的某些特别需要的功能通过打 patch 的方式打到老版本里面去。</p></li><li><p>新版本香是真的香，可是为啥有的人不用呢？问题就是，实时作业大多数是长期运行的，如果一个作业没啥错误，在生产运行的好好的，也不出啥故障，稳定性和性能也都能接受（并不是所有作业数据量都很大，会遇到性能问题），那么<strong>用户</strong>为啥要使用新版本？用户才不管你新版本功能多牛逼，性能多屌呢，老子升级还要改依赖版本、改接口代码、测试联调、性能测试（谁知道你说的性能提升是不是吹牛逼的）、稳定性测试（可能上线双跑一段时间验证），这些不需要时间呀，你叫我升级就升级，滚犊子吧，你知道我还有多少业务需求要做吗？</p></li></ul><p>那么就落下这个场地了，又要使用新版本的功能去解决问题，老作业的用户跟他各种扯皮也打动不了他升级作业的版本，那么自然就不断的出现了多个版本了。</p><p>这样，如果不对版本做好规划，那么摊子就逐渐越来越大，越来越难收拾了？</p><p>那么该如何管理公司的 Flink 版本？如果管理和兼容多个 Flink 版本的作业提交？如何兼容 Jar 包和 SQL 作业的提交</p><h3 id="怎么管理多个-Flink-版本的作业提交？"><a href="#怎么管理多个-Flink-版本的作业提交？" class="headerlink" title="怎么管理多个 Flink 版本的作业提交？"></a>怎么管理多个 Flink 版本的作业提交？</h3><p>尽请期待下篇文章</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;为啥会出现多个版本？&quot;&gt;&lt;a href=&quot;#为啥会出现多个版本？&quot; class=&quot;headerlink&quot; title=&quot;为啥会出现多个版本？&quot;&gt;&lt;/a&gt;为啥会出现多个版本？&lt;/h3&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何实时将应用 Error 日志告警？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/18/flink-in-action-11.5/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/18/flink-in-action-11.5/</id>
    <published>2021-08-17T16:00:00.000Z</published>
    <updated>2022-02-07T14:13:56.910Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-5-如何实时将应用-Error-日志告警？"><a href="#11-5-如何实时将应用-Error-日志告警？" class="headerlink" title="11.5 如何实时将应用 Error 日志告警？"></a>11.5 如何实时将应用 Error 日志告警？</h2><p>大数据时代，随着公司业务不断的增长，数据量自然也会跟着不断的增长，那么业务应用和集群服务器的的规模也会逐渐扩大，几百台服务器在一般的公司已经是很常见的了。那么将应用服务部署在如此多的服务器上，对开发和运维人员来说都是一个挑战。一个优秀的系统运维平台是需要将部署在这么多服务器上的应用监控信息汇总成一个统一的数据展示平台，方便运维人员做日常的监测、提升运维效率，还可以及时反馈应用的运行状态给应用开发人员。举个例子，应用的运行日志需要按照时间排序做一个展示，并且提供日志下载和日志搜索等服务，这样如果应用出现问题开发人员首先可以根据应用日志的错误信息进行问题的排查。那么该如何实时的将应用的 Error 日志推送给应用开发人员呢，接下来我们将讲解日志的处理方案。</p><a id="more"></a><h3 id="11-5-1-日志处理方案的演进"><a href="#11-5-1-日志处理方案的演进" class="headerlink" title="11.5.1 日志处理方案的演进"></a>11.5.1 日志处理方案的演进</h3><p>日志处理的方案也是有一个演进的过程，要想弄清楚整个过程，我们先来看下日志的介绍。</p><h4 id="什么是日志？"><a href="#什么是日志？" class="headerlink" title="什么是日志？"></a>什么是日志？</h4><p>日志是带时间戳的基于时间序列的数据，它可以反映系统的运行状态，包括了一些标识信息（应用所在服务器集群名、集群机器 IP、机器设备系统信息、应用名、应用 ID、应用所属项目等）</p><h4 id="日志处理方案演进"><a href="#日志处理方案演进" class="headerlink" title="日志处理方案演进"></a>日志处理方案演进</h4><p>日志处理方案的演进过程：</p><ul><li>日志处理 v1.0: 应用日志分布在很多机器上，需要人肉手动去机器查看日志信息。</li><li>日志处理 v2.0: 利用离线计算引擎统一的将日志收集，形成一个日志搜索分析平台，提供搜索让用户根据关键字进行搜索和分析，缺点就是及时性比较差。</li><li>日志处理 v3.0: 利用 Agent 实时的采集部署在每台机器上的日志，然后统一发到日志收集平台做汇总，并提供实时日志分析和搜索的功能，这样从日志产生到搜索分析出结果只有简短的延迟（在用户容忍时间范围之内），优点是快，但是日志数据量大的情况下带来的挑战也大。</li></ul><h3 id="11-5-2-日志采集工具对比"><a href="#11-5-2-日志采集工具对比" class="headerlink" title="11.5.2 日志采集工具对比"></a>11.5.2 日志采集工具对比</h3><p>上面提到的日志采集，其实现在已经有很多开源的组件支持去采集日志，比如 Logstash、Filebeat、Fluentd、Logagent 等，这里简单做个对比。</p><h4 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h4><p>Logstash 是一个开源数据收集引擎，具有实时管道功能。Logstash 可以动态地将来自不同数据源的数据统一起来，并将数据标准化到你所选择的目的地。如下图所示，Logstash 将采集到的数据用作分析、监控、告警等。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-025214.jpg" alt=""></p><p><strong>优势</strong>：Logstash 主要的优点就是它的灵活性，它提供很多插件，详细的文档以及直白的配置格式让它可以在多种场景下应用。而且现在 ELK 整个技术栈在很多公司应用的比较多，所以基本上可以在往上找到很多相关的学习资源。</p><p><strong>劣势</strong>：Logstash 致命的问题是它的性能以及资源消耗(默认的堆大小是 1GB)。尽管它的性能在近几年已经有很大提升，与它的替代者们相比还是要慢很多的，它在大数据量的情况下会是个问题。另一个问题是它目前不支持缓存，目前的典型替代方案是将 Redis 或 Kafka 作为中心缓冲池：</p><h4 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h4><p>作为 Beats 家族的一员，Filebeat 是一个轻量级的日志传输工具，它的存在正弥补了 Logstash 的缺点，Filebeat 作为一个轻量级的日志传输工具可以将日志推送到 Kafka、Logstash、ElasticSearch、Redis。它的处理流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-030138.jpg" alt=""></p><p><strong>优势</strong>：Filebeat 只是一个二进制文件没有任何依赖。它占用资源极少，尽管它还十分年轻，正式因为它简单，所以几乎没有什么可以出错的地方，所以它的可靠性还是很高的。它也为我们提供了很多可以调节的点，例如：它以何种方式搜索新的文件，以及当文件有一段时间没有发生变化时，何时选择关闭文件句柄。</p><p><strong>劣势</strong>：Filebeat 的应用范围十分有限，所以在某些场景下我们会碰到问题。例如，如果使用 Logstash 作为下游管道，我们同样会遇到性能问题。正因为如此，Filebeat 的范围在扩大。开始时，它只能将日志发送到 Logstash 和 Elasticsearch，而现在它可以将日志发送给 Kafka 和 Redis，在 5.x 版本中，它还具备过滤的能力。</p><h4 id="Fluentd"><a href="#Fluentd" class="headerlink" title="Fluentd"></a>Fluentd</h4><p>Fluentd 创建的初衷主要是尽可能的使用 JSON 作为日志输出，所以传输工具及其下游的传输线不需要猜测子字符串里面各个字段的类型。这样它为几乎所有的语言都提供库，这也意味着可以将它插入到自定义的程序中。它的处理流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-031337.png" alt=""></p><p><strong>优势</strong>：和多数 Logstash 插件一样，Fluentd 插件是用 Ruby 语言开发的非常易于编写维护。所以它数量很多，几乎所有的源和目标存储都有插件(各个插件的成熟度也不太一样)。这也意味这可以用 Fluentd 来串联所有的东西。</p><p><strong>劣势</strong>：因为在多数应用场景下得到 Fluentd 结构化的数据，它的灵活性并不好。但是仍然可以通过正则表达式来解析非结构化的数据。尽管性能在大多数场景下都很好，但它并不是最好的，它的缓冲只存在与输出端，单线程核心以及 Ruby GIL 实现的插件意味着它大的节点下性能是受限的。</p><h4 id="Logagent"><a href="#Logagent" class="headerlink" title="Logagent"></a>Logagent</h4><p>Logagent 是 Sematext 提供的传输工具，它用来将日志传输到 Logsene(一个基于 SaaS 平台的 Elasticsearch API)，因为 Logsene 会暴露 Elasticsearch API，所以 Logagent 可以很容易将数据推送到 Elasticsearch 。</p><p><strong>优势</strong>：可以获取 /var/log 下的所有信息，解析各种格式的日志，可以掩盖敏感的数据信息。它还可以基于 IP 做 GeoIP 丰富地理位置信息。同样，它轻量又快速，可以将其置入任何日志块中。Logagent 有本地缓冲，所以在数据传输目的地不可用时不会丢失日志。</p><p><strong>劣势</strong>：没有 Logstash 灵活。</p><h3 id="11-5-3-日志结构设计"><a href="#11-5-3-日志结构设计" class="headerlink" title="11.5.3 日志结构设计"></a>11.5.3 日志结构设计</h3><p>前面介绍了日志和对比了常用日志采集工具的优势和劣势，通常在不同环境，不同机器上都会部署日志采集工具，然后采集工具会实时的将新的日志采集发送到下游，因为日志数据量毕竟大，所以建议发到 MQ 中，比如 Kafka，这样再想怎么处理这些日志就会比较灵活。假设我们忽略底层采集具体是哪种，但是规定采集好的日志结构化数据如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEvent</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String type;<span class="comment">//日志的类型(应用、容器、...)</span></span><br><span class="line">    <span class="keyword">private</span> Long timestamp;<span class="comment">//日志的时间戳</span></span><br><span class="line">    <span class="keyword">private</span> String level;<span class="comment">//日志的级别(debug/info/warn/error)</span></span><br><span class="line">    <span class="keyword">private</span> String message;<span class="comment">//日志内容</span></span><br><span class="line">    <span class="comment">//日志的标识(应用 ID、应用名、容器 ID、机器 IP、集群名、...)</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; tags = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后上面这种 LogEvent 的数据（假设采集发上来的是这种结构数据的 JSON 串，所以需要在 Flink 中做一个反序列化解析）就会往 Kafka 不断的发送数据，样例数据如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"app"</span>,</span><br><span class="line"><span class="attr">"timestamp"</span>: <span class="number">1570941591229</span>,</span><br><span class="line"><span class="attr">"level"</span>: <span class="string">"error"</span>,</span><br><span class="line"><span class="attr">"message"</span>: <span class="string">"Exception in thread \"main\" java.lang.NoClassDefFoundError: org/apache/flink/api/common/ExecutionConfig$GlobalJobParameters"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"cluster_name"</span>: <span class="string">"zhisheng"</span>,</span><br><span class="line"><span class="attr">"app_name"</span>: <span class="string">"zhisheng"</span>,</span><br><span class="line"><span class="attr">"host_ip"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line"><span class="attr">"app_id"</span>: <span class="string">"21"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么在 Flink 中如何将应用异常或者错误的日志做实时告警呢？</p><h3 id="11-5-4-异常日志实时告警项目架构"><a href="#11-5-4-异常日志实时告警项目架构" class="headerlink" title="11.5.4 异常日志实时告警项目架构"></a>11.5.4 异常日志实时告警项目架构</h3><p>整个异常日志实时告警项目的架构如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-035811.png" alt=""></p><p>应用日志散列在不同的机器，然后每台机器都有部署采集日志的 Agent（可以是上面的 Filebeat、Logstash 等），这些 Agent 会实时的将分散在不同机器、不同环境的应用日志统一的采集发到 Kafka 集群中，然后告警这边是有一个 Flink 作业去实时的消费 Kafka 数据做一个异常告警计算处理。如果还想做日志的搜索分析，可以起另外一个作业去实时的将 Kafka 的日志数据写入进 ElasticSearch，再通过 Kibana 页面做搜索和分析。</p><h3 id="11-5-5-日志数据发送到-Kafka"><a href="#11-5-5-日志数据发送到-Kafka" class="headerlink" title="11.5.5 日志数据发送到 Kafka"></a>11.5.5 日志数据发送到 Kafka</h3><p>上面已经讲了日志数据 LogEvent 的结构和样例数据，因为要在服务器部署采集工具去采集应用日志数据对于本地测试来说可能稍微复杂，所以在这里就只通过代码模拟构造数据发到 Kafka 去，然后在 Flink 作业中去实时消费 Kafka 中的数据，下面演示构造日志数据发到 Kafka 的工具类，这个工具类主要分两块，构造 LogEvent 数据和发送到 Kafka。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BuildLogEventDataUtil</span> </span>&#123;</span><br><span class="line">    <span class="comment">//Kafka broker 和 topic 信息</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String BROKER_LIST = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LOG_TOPIC = <span class="string">"zhisheng_log"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeDataToKafka</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, BROKER_LIST);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        KafkaProducer producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//模拟构造 LogEvent 对象</span></span><br><span class="line">            LogEvent logEvent = <span class="keyword">new</span> LogEvent().builder()</span><br><span class="line">                    .type(<span class="string">"app"</span>)</span><br><span class="line">                    .timestamp(System.currentTimeMillis())</span><br><span class="line">                    .level(logLevel())</span><br><span class="line">                    .message(message(i + <span class="number">1</span>))</span><br><span class="line">                    .tags(mapData())</span><br><span class="line">                    .build();</span><br><span class="line"><span class="comment">//            System.out.println(logEvent);</span></span><br><span class="line">            ProducerRecord record = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(LOG_TOPIC, <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(logEvent));</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.flush();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        writeDataToKafka();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">message</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"这是第 "</span> + i + <span class="string">" 行日志！"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">logLevel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> number = random.nextInt(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">switch</span> (number) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"debug"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"info"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"warn"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"error"</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"info"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">hostIp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> number = random.nextInt(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">switch</span> (number) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.10"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.11"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.12"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.13"</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.10"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">mapData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(<span class="string">"app_id"</span>, <span class="string">"11"</span>);</span><br><span class="line">        map.put(<span class="string">"app_name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line">        map.put(<span class="string">"cluster_name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line">        map.put(<span class="string">"host_ip"</span>, hostIp());</span><br><span class="line">        map.put(<span class="string">"class"</span>, <span class="string">"BuildLogEventDataUtil"</span>);</span><br><span class="line">        map.put(<span class="string">"method"</span>, <span class="string">"main"</span>);</span><br><span class="line">        map.put(<span class="string">"line"</span>, String.valueOf(<span class="keyword">new</span> Random().nextInt(<span class="number">100</span>)));</span><br><span class="line">        <span class="comment">//add more tag</span></span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果之前 Kafka 中没有 zhisheng_log 这个 topic，运行这个工具类之后也会自动创建这个 topic 了。</p><h3 id="11-5-6-Flink-实时处理日志数据"><a href="#11-5-6-Flink-实时处理日志数据" class="headerlink" title="11.5.6 Flink 实时处理日志数据"></a>11.5.6 Flink 实时处理日志数据</h3><h3 id="11-5-7-处理应用异常日志"><a href="#11-5-7-处理应用异常日志" class="headerlink" title="11.5.7 处理应用异常日志"></a>11.5.7 处理应用异常日志</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>本章属于 Flink 实战篇，前面章节讲了很多 Flink 相关的技术知识点，这章主要是通过技术点来教大家如何去完成一些真实的需求，比如通过 State 去实时统计网站各页面一天的 PV 和 UV、通过 ProcessFunction 去做定时器处理一些延迟的事件（宕机告警）、通过 Async IO 读取告警规则、通过广播变量动态的更新告警规则、如何实时的做到日志告警。</p><p>虽然这些需求换到你们公司去可能不一样，但是这些技术知识点是可以运用到你的项目需求中去的，这里介绍的这些需求，你要学会去分析，然后去判断这些需求到底该使用什么技术来实现会更好，这样才可以做到活学活用。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-5-如何实时将应用-Error-日志告警？&quot;&gt;&lt;a href=&quot;#11-5-如何实时将应用-Error-日志告警？&quot; class=&quot;headerlink&quot; title=&quot;11.5 如何实时将应用 Error 日志告警？&quot;&gt;&lt;/a&gt;11.5 如何实时将应用 Error 日志告警？&lt;/h2&gt;&lt;p&gt;大数据时代，随着公司业务不断的增长，数据量自然也会跟着不断的增长，那么业务应用和集群服务器的的规模也会逐渐扩大，几百台服务器在一般的公司已经是很常见的了。那么将应用服务部署在如此多的服务器上，对开发和运维人员来说都是一个挑战。一个优秀的系统运维平台是需要将部署在这么多服务器上的应用监控信息汇总成一个统一的数据展示平台，方便运维人员做日常的监测、提升运维效率，还可以及时反馈应用的运行状态给应用开发人员。举个例子，应用的运行日志需要按照时间排序做一个展示，并且提供日志下载和日志搜索等服务，这样如果应用出现问题开发人员首先可以根据应用日志的错误信息进行问题的排查。那么该如何实时的将应用的 Error 日志推送给应用开发人员呢，接下来我们将讲解日志的处理方案。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何利用广播变量动态更新告警规则？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/17/flink-in-action-11.4/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/17/flink-in-action-11.4/</id>
    <published>2021-08-16T16:00:00.000Z</published>
    <updated>2022-02-07T14:05:22.257Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-4-如何利用广播变量动态更新告警规则？"><a href="#11-4-如何利用广播变量动态更新告警规则？" class="headerlink" title="11.4 如何利用广播变量动态更新告警规则？"></a>11.4 如何利用广播变量动态更新告警规则？</h2><p>一个在生产环境运行的流作业有时候会想变更一些作业的配置或者数据流的配置，然后作业可以读取并使用新的配置，而不是通过修改配置然后重启作业来读取配置，毕竟重启一个有状态的流作业代价挺大，本节将带你熟悉 Broadcast，并通过一个案例来教会你如何去动态的更新作业的配置。</p><a id="more"></a><h3 id="11-4-1-BroadcastVariable-简介"><a href="#11-4-1-BroadcastVariable-简介" class="headerlink" title="11.4.1 BroadcastVariable 简介"></a>11.4.1 BroadcastVariable 简介</h3><p>BroadcastVariable 中文意思是广播变量，其实可以理解是一个公共的共享变量（可能是固定不变的数据集合，也可能是动态变化的数据集合），在作业中将该共享变量广播出去，然后下游的所有任务都可以获取到该共享变量，这样就可以不用将这个变量拷贝到下游的每个任务中。之所以设计这个广播变量的原因主要是因为在 Flink 中多并行度的情况下，每个算子或者不同算子运行所在的 Slot 不一致，这就导致它们不会共享同一个内存，也就不可以通过静态变量的方式去获取这些共享变量值。对于这个问题，有不少读者在问过我为啥我设置的静态变量值在本地运行是可以获取到的，在集群环境运行作业就出现空指针啊，该问题其实笔者自己也在生产环境遇到过，所以接下来好好教大家使用！</p><h3 id="11-4-2-如何使用-BroadcastVariable-？"><a href="#11-4-2-如何使用-BroadcastVariable-？" class="headerlink" title="11.4.2 如何使用 BroadcastVariable ？"></a>11.4.2 如何使用 BroadcastVariable ？</h3><p>在 3.4 节中讲过如何 broadcast 算子和 BroadcastStream 如何使用，在 4.1 节中讲解了 Broadcast State 如何使用以及需要注意的地方，注意 BroadcastVariable 只能应用在批作业中，如果要应用在流作业中则需要要使用 BroadcastStream。</p><p>在批作业中通过使用 <code>withBroadcastSet(DataSet, String)</code> 来广播一个 DataSet 数据集合，并可以给这份数据起个名字，如果要获取数据的时候，可以通过 <code>getRuntimeContext().getBroadcastVariable(String)</code> 获取广播出去的变量数据。下面演示一下广播一个 DataSet 变量和获取变量的样例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> ParameterTool params = ParameterTool.fromArgs(args);</span><br><span class="line"><span class="keyword">final</span> ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line"><span class="comment">//1. 待广播的数据</span></span><br><span class="line">DataSet&lt;Integer&gt; toBroadcast = env.fromElements(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">env.fromElements(<span class="string">"a"</span>, <span class="string">"b"</span>)</span><br><span class="line">        .map(<span class="keyword">new</span> RichMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            List&lt;Integer&gt; broadcastData;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">// 3. 获取广播的 DataSet 数据 作为一个 Collection</span></span><br><span class="line">                broadcastData = getRuntimeContext().getBroadcastVariable(<span class="string">"zhisheng"</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> String <span class="title">map</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> broadcastData.get(<span class="number">1</span>) + value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).withBroadcastSet(toBroadcast, <span class="string">"zhisheng"</span>)<span class="comment">// 2. 广播 DataSet</span></span><br><span class="line">        .print();</span><br></pre></td></tr></table></figure><p>注意广播的时候设置的名称和获取的名称要一致，然后运行的结果如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-013429.png" alt=""></p><p>流作业中通常使用 BroadcastStream 的方式将变量集合在数据流中传递，可能数据集合会做修改更新，但是修改后其实并不想重启作业去读取这些新修改的配置，因为对于一个流作业来说重启带来的代价很高（需要考虑数据堆积和如何恢复至重启前的状态等问题），那么这种情况下就可以在广播数据流处定时查询数据，这样就能够获取更改后的数据，通常在这种广播数据处获取数据只需要设置一个并行度就好，时间根据需求来判断及时性，一般 1 分钟内的数据变更延迟都是在容忍范围之内。广播流中的元素保证流所有的元素最终都会发到下游的所有并行实例，但是元素到达下游的并行实例的顺序可能不相同。因此，对广播状态的修改不能依赖于输入数据的顺序。在进行 Checkpoint 时，所有的任务都会 Checkpoint 下它们的广播状态。</p><p>另外需要注意的是：广播出去的变量存在于每个节点的内存中，所以这个数据集不能太大，因为广播出去的数据，会一致在内存中存在，除非程序执行结束。个人建议：如果数据集在几十兆或者百兆的时候，可以选择进行广播，如果数据集的大小上 G 的话，就不建议进行广播了。</p><p>上面介绍了下广播变量的在批作业的使用方式，下面通过一个案例来教大家如何在流作业中使用广播变量。</p><h3 id="11-4-3-利用广播变量动态更新告警规则数据需求分析"><a href="#11-4-3-利用广播变量动态更新告警规则数据需求分析" class="headerlink" title="11.4.3 利用广播变量动态更新告警规则数据需求分析"></a>11.4.3 利用广播变量动态更新告警规则数据需求分析</h3><p>在 11.3.3 节中有设计一张简单的告警规则表，通常告警规则是会对外提供接口进行增删改查的，那么随着业务应用上线，开发人员会对其应用服务新增或者修改告警规则（更改之前规则中的阈值），那么更改之后就需要让告警的作业能够去感知到之前的规则发生了变动，所以就需要在作业中想个什么办法去获取到更改后的数据。有两种方式可以让作业知道规则的变更： push 和 pull 模式。</p><p>push 模式则需要在更新、删除、新增接口中不仅操作数据库，还需要额外的发送更新、删除、新增规则的事件到消息队列中，然后作业消费消息队列的数据再去做更新、删除、新增规则，这种及时性有保证，但是可能会有数据不统一的风险（如果消息队列的数据丢了，但是在接口中还是将规则的数据变更存储到数据库）；pull 模式下就需要作业定时去查找一遍所有的告警规则数据，然后存在作业内存中，这个时间可以设置的比较短，比如 1 分钟，这样就能既保证数据的一致性，时间延迟也是在容忍范围之内。</p><p>对于这种动态变化的规则数据，在 Flink 中通常是使用广播流来处理的。那么接下来就演示下如何利用广播变量动态更新告警规则数据，假设我们在数据库中新增告警规则或者修改告警规则指标的阈值，然后看作业中是否会出现相应的变化。</p><h3 id="11-4-4-读取告警规则数据"><a href="#11-4-4-读取告警规则数据" class="headerlink" title="11.4.4 读取告警规则数据"></a>11.4.4 读取告警规则数据</h3><h3 id="11-4-5-监控数据连接规则数据"><a href="#11-4-5-监控数据连接规则数据" class="headerlink" title="11.4.5 监控数据连接规则数据"></a>11.4.5 监控数据连接规则数据</h3><h3 id="11-4-6-小结与反思"><a href="#11-4-6-小结与反思" class="headerlink" title="11.4.6 小结与反思"></a>11.4.6 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-4-如何利用广播变量动态更新告警规则？&quot;&gt;&lt;a href=&quot;#11-4-如何利用广播变量动态更新告警规则？&quot; class=&quot;headerlink&quot; title=&quot;11.4 如何利用广播变量动态更新告警规则？&quot;&gt;&lt;/a&gt;11.4 如何利用广播变量动态更新告警规则？&lt;/h2&gt;&lt;p&gt;一个在生产环境运行的流作业有时候会想变更一些作业的配置或者数据流的配置，然后作业可以读取并使用新的配置，而不是通过修改配置然后重启作业来读取配置，毕竟重启一个有状态的流作业代价挺大，本节将带你熟悉 Broadcast，并通过一个案例来教会你如何去动态的更新作业的配置。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何利用 Async I/O 读取告警规则？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/16/flink-in-action-11.3/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/16/flink-in-action-11.3/</id>
    <published>2021-08-15T16:00:00.000Z</published>
    <updated>2022-02-07T14:03:38.105Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-3-如何利用-Async-I-O-读取告警规则？"><a href="#11-3-如何利用-Async-I-O-读取告警规则？" class="headerlink" title="11.3 如何利用 Async I/O 读取告警规则？"></a>11.3 如何利用 Async I/O 读取告警规则？</h2><p>Async 中文是异步的意思，在流计算中，使用异步 I/O 能够提升作业整体的计算能力，本节中不仅会讲解异步 I/O 的 API 原理，还会通过一个实战需求（读取告警规则）来讲解异步 I/O 的使用。</p><a id="more"></a><h3 id="11-3-1-为什么需要-Async-I-O？"><a href="#11-3-1-为什么需要-Async-I-O？" class="headerlink" title="11.3.1 为什么需要 Async I/O？"></a>11.3.1 为什么需要 Async I/O？</h3><p>在大多数情况下，IO 操作都是一个耗时的过程，尤其在流计算中，如果在具体的算子里面还有和第三方外部系统（比如数据库、Redis、HBase 等存储系统）做交互，比如在一个 MapFunction 中每来一条数据就要去查找 MySQL 中某张表的数据，然后跟查询出来的数据做关联（同步交互）。查询请求到数据库，再到数据库响应返回数据的整个流程的时间对于流作业来说是比较长的。那么该 Map 算子处理数据的速度就会降下来，在大数据量的情况下很可能会导致整个流作业出现反压问题（在 9.1 节中讲过），那么整个作业的消费延迟就会增加，影响作业整体吞吐量和实时性，从而导致最终该作业处于不可用的状态。</p><p>这种同步（Sync）的与数据库做交互操作，会因耗时太久导致整个作业延迟，如果换成异步的话，就可以同时处理很多请求并同时可以接收响应，这样的话，等待数据库响应的时间就会与其他发送请求和接收响应的时间重叠，相同的等待时间内会处理多个请求，从而比同步的访问要提高不少流处理的吞吐量。虽然也可以通过增大该算子的并行度去执行查数据库，但是这种解决办法需要消耗更多的资源（并行度增加意味着消费的 slot 个数也会增加），这种方法和使用异步处理的方法对比一下，还是使用异步的查询数据库这种方法值得使用。同步操作（Sync I/O）和异步操作（Async I/O）的处理流程如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-12-121929.png" alt=""></p><p>左侧表示的是在流处理中同步的数据库请求，右侧是异步的数据库请求。假设左侧是数据流中 A 数据来了发送一个查询数据库的请求看是否之前存在 A，然后等待查询结果返回，只有等 A 整个查询请求响应后才会继续开始 B 数据的查询请求，依此继续；而右侧是连续的去数据库查询是否存在 A、B、C、D，后面哪个请求先响应就先处理哪个，不需要和左侧的一样要等待上一个请求全部完成才可以开始下一个请求，所以异步的话吞吐量自然就高起来了。但是得注意的是：使用异步这种方法前提是要数据库客户端支持异步的请求，否则可能需要借助线程池来实现异步请求，但是现在主流的数据库通常都支持异步的操作，所以不用太担心。</p><h3 id="11-3-2-Async-I-O-API"><a href="#11-3-2-Async-I-O-API" class="headerlink" title="11.3.2 Async I/O API"></a>11.3.2 Async I/O API</h3><p>Flink 的 Async I/O API 允许用户在数据流处理中使用异步请求，并且还支持超时处理、处理顺序、事件时间、容错。在 Flink 中，如果要使用 Async I/O API，是非常简单的，需要通过下面三个步骤来执行对数据库的异步操作。</p><ul><li>继承 RichAsyncFunction 抽象类或者实现用来分发请求的 AsyncFunction 接口</li><li>返回异步请求的结果的 Future</li><li>在 DataStream 上使用异步操作</li></ul><p>官网也给出案例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AsyncDatabaseRequest</span> <span class="keyword">extends</span> <span class="title">RichAsyncFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据库的客户端，它可以发出带有 callback 的并发请求</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> DatabaseClient client;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        client = <span class="keyword">new</span> DatabaseClient(host, post, credentials);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">asyncInvoke</span><span class="params">(String key, <span class="keyword">final</span> ResultFuture&lt;Tuple2&lt;String, String&gt;&gt; resultFuture)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//发出异步请求，接收 future 的结果</span></span><br><span class="line">        <span class="keyword">final</span> Future&lt;String&gt; result = client.query(key);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置客户端请求完成后执行的 callback，callback 只是将结果转发给 ResultFuture</span></span><br><span class="line">        CompletableFuture.supplyAsync(<span class="keyword">new</span> Supplier&lt;String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> result.get();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).thenAccept( (String dbResult) -&gt; &#123;</span><br><span class="line">            resultFuture.complete(Collections.singleton(<span class="keyword">new</span> Tuple2&lt;&gt;(key, dbResult)));</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//原始数据</span></span><br><span class="line">DataStream&lt;String&gt; stream = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">//应用异步 I/O 转换</span></span><br><span class="line">DataStream&lt;Tuple2&lt;String, String&gt;&gt; resultStream =</span><br><span class="line">    AsyncDataStream.unorderedWait(stream, <span class="keyword">new</span> AsyncDatabaseRequest(), <span class="number">1000</span>, TimeUnit.MILLISECONDS, <span class="number">100</span>);</span><br></pre></td></tr></table></figure><p>注意：ResultFuture 在第一次调用 resultFuture.complete 时就已经完成了，后面所有 resultFuture.complete  的调用都会被忽略。</p><p>下面两个参数控制了异步操作：</p><ul><li>Timeout：timeout 定义了异步操作过了多长时间后会被丢弃，这个参数是防止了死的或者失败的请求</li><li>Capacity：这个参数定义可以同时处理多少个异步请求。虽然异步请求会带来更好的吞吐量，但是该操作仍然可能成为流作业的性能瓶颈。限制并发请求的数量可确保操作不会不断累积处理请求，一旦超过 Capacity 值，它将触发反压。</li></ul><h4 id="超时处理"><a href="#超时处理" class="headerlink" title="超时处理"></a>超时处理</h4><h4 id="结果顺序"><a href="#结果顺序" class="headerlink" title="结果顺序"></a>结果顺序</h4><h4 id="事件时间"><a href="#事件时间" class="headerlink" title="事件时间"></a>事件时间</h4><h4 id="容错性保证"><a href="#容错性保证" class="headerlink" title="容错性保证"></a>容错性保证</h4><h4 id="实践技巧"><a href="#实践技巧" class="headerlink" title="实践技巧"></a>实践技巧</h4><h4 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h4><h3 id="11-3-3-利用-Async-I-O-读取告警规则需求分析"><a href="#11-3-3-利用-Async-I-O-读取告警规则需求分析" class="headerlink" title="11.3.3 利用 Async I/O 读取告警规则需求分析"></a>11.3.3 利用 Async I/O 读取告警规则需求分析</h3><h4 id="监控数据样例"><a href="#监控数据样例" class="headerlink" title="监控数据样例"></a>监控数据样例</h4><h4 id="告警规则表设计"><a href="#告警规则表设计" class="headerlink" title="告警规则表设计"></a>告警规则表设计</h4><h4 id="告警规则实体类"><a href="#告警规则实体类" class="headerlink" title="告警规则实体类"></a>告警规则实体类</h4><h3 id="11-3-4-如何使用-Async-I-O-读取告警规则数据"><a href="#11-3-4-如何使用-Async-I-O-读取告警规则数据" class="headerlink" title="11.3.4 如何使用 Async I/O 读取告警规则数据"></a>11.3.4 如何使用 Async I/O 读取告警规则数据</h3><h3 id="11-3-5-小结与反思"><a href="#11-3-5-小结与反思" class="headerlink" title="11.3.5 小结与反思"></a>11.3.5 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-3-如何利用-Async-I-O-读取告警规则？&quot;&gt;&lt;a href=&quot;#11-3-如何利用-Async-I-O-读取告警规则？&quot; class=&quot;headerlink&quot; title=&quot;11.3 如何利用 Async I/O 读取告警规则？&quot;&gt;&lt;/a&gt;11.3 如何利用 Async I/O 读取告警规则？&lt;/h2&gt;&lt;p&gt;Async 中文是异步的意思，在流计算中，使用异步 I/O 能够提升作业整体的计算能力，本节中不仅会讲解异步 I/O 的 API 原理，还会通过一个实战需求（读取告警规则）来讲解异步 I/O 的使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何使用 Flink ProcessFunction 处理宕机告警?</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/15/flink-in-action-11.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/15/flink-in-action-11.2/</id>
    <published>2021-08-14T16:00:00.000Z</published>
    <updated>2022-02-07T14:01:37.985Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-2-如何使用-Flink-ProcessFunction-处理宕机告警"><a href="#11-2-如何使用-Flink-ProcessFunction-处理宕机告警" class="headerlink" title="11.2 如何使用 Flink ProcessFunction 处理宕机告警?"></a>11.2 如何使用 Flink ProcessFunction 处理宕机告警?</h2><p>在 3.3 节中讲解了 Process 算子的概念，本节中将更详细的讲解 Flink ProcessFunction，然后教大家如何使用 ProcessFunction 来解决公司中常见的问题 —— 宕机，这个宕机不仅仅包括机器宕机，还包含应用宕机，通常出现宕机带来的影响是会很大的，所以能及时收到告警会减少损失。</p><a id="more"></a><h3 id="11-2-1-ProcessFunction-简介"><a href="#11-2-1-ProcessFunction-简介" class="headerlink" title="11.2.1 ProcessFunction 简介"></a>11.2.1 ProcessFunction 简介</h3><p>在 1.2.5 节中讲了 Flink 的 API 分层，其中可以看见 Flink 的底层 API 就是 ProcessFunction，它是一个低阶的流处理操作，它可以访问流处理程序的基础构建模块：Event、State、Timer。ProcessFunction 可以被认为是一种提供了对 KeyedState 和定时器访问的 FlatMapFunction。每当数据源中接收到一个事件，就会调用来此函数来处理。对于容错的状态，ProcessFunction 可以通过 RuntimeContext 访问 KeyedState。</p><p>定时器可以对处理时间和事件时间的变化做一些处理。每次调用 processElement() 都可以获得一个 Context 对象，通过该对象可以访问元素的事件时间戳以及 TimerService。TimerService 可以为尚未发生的事件时间/处理时间实例注册回调。当定时器到达某个时刻时，会调用 onTimer() 方法。在调用期间，所有状态再次限定为定时器创建的 key，允许定时器操作 KeyedState。如果要访问 KeyedState 和定时器，那必须在 KeyedStream 上使用 KeyedProcessFunction，比如在 keyBy 算子之后使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(...).process(<span class="keyword">new</span> KeyedProcessFunction&lt;&gt;()&#123;</span><br><span class="line">    </span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>KeyedProcessFunction 是 ProcessFunction 函数的一个扩展，它可以在 onTimer 和 processElement 方法中获取到分区的 Key 值，这对于数据传递是很有帮助的，因为经常有这样的需求，经过 keyBy 算子之后可能还需要这个 key 字段，那么在这里直接构建成一个新的对象（新增一个 key 字段），然后下游的算子直接使用这个新对象中的 key 就好了，而不在需要重复的拼一个唯一的 key。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(String value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    System.out.println(ctx.getCurrentKey());</span><br><span class="line">    out.collect(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">long</span> timestamp, OnTimerContext ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    System.out.println(ctx.getCurrentKey());</span><br><span class="line">    <span class="keyword">super</span>.onTimer(timestamp, ctx, out);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="11-2-2-CoProcessFunction-简介"><a href="#11-2-2-CoProcessFunction-简介" class="headerlink" title="11.2.2 CoProcessFunction 简介"></a>11.2.2 CoProcessFunction 简介</h3><p>如果要在两个输入流上进行操作，可以使用 CoProcessFunction，这个函数可以传入两个不同的数据流输入，并为来自两个不同数据源的事件分别调用 processElement1() 和  processElement2() 方法。可以按照下面的步骤来实现一个典型的 Join 操作：</p><ul><li>为一个数据源的数据建立一个状态对象</li><li>从数据源处有新数据流过来的时候更新这个状态对象</li><li>在另一个数据源接收到元素时，关联状态对象并对其产生出连接的结果</li></ul><p>比如，将监控的 metric 数据和告警规则数据进行一个连接，在流数据的状态中存储了告警规则数据，当有监控数据过来时，根据监控数据的 metric 名称和一些 tag 去找对应告警规则计算表达式，然后通过规则的表达式对数据进行加工处理，判断是否要告警，如果是要告警则会关联构造成一个新的对象，新对象中不仅有初始的监控 metric 数据，还有含有对应的告警规则数据以及通知策略数据，组装成这样一条数据后，下游就可以根据这个数据进行通知，通知还会在状态中存储这个告警状态，表示它在什么时间告过警了，下次有新数据过来的时候，判断新数据是否是恢复的，如果属于恢复则把该状态清除。</p><h3 id="11-2-3-Timer-简介"><a href="#11-2-3-Timer-简介" class="headerlink" title="11.2.3 Timer 简介"></a>11.2.3 Timer 简介</h3><p>Timer 提供了一种定时触发器的功能，通过 TimerService 接口注册 timer。TimerService 在内部维护两种类型的定时器（处理时间和事件时间定时器）并排队执行。处理时间定时器的触发依赖于 ProcessingTimeService，它负责管理所有基于处理时间的触发器，内部使用 ScheduledThreadPoolExecutor 调度定时任务；事件时间定时器的触发依赖于系统当前的 Watermark。需要注意的一点就是：<strong>Timer 只能在 KeyedStream 中使用</strong>。</p><p>TimerService 会删除每个 Key 和时间戳重复的定时器，即每个 Key 在同一个时间戳上最多有一个定时器。如果为同一时间戳注册了多个定时器，则只会调用一次 onTimer（） 方法。Flink 会同步调用 onTimer() 和  processElement() 方法，因此不必担心状态的并发修改问题。TimerService 不仅提供了注册和删除 Timer 的功能，还可以通过它来获取当前的系统时间和 Watermark 的值。TimerService 类中的方法如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-12-070737.png" alt=""></p><h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><p>定时器具有容错能力，并且会与应用程序的状态一起进行 Checkpoint，如果发生故障重启会从 Checkpoint／Savepoint 中恢复定时器的状态。如果有处理时间定时器原本是要在恢复起来的那个时间之前触发的，那么在恢复的那一刻会立即触发该定时器。定时器始终是异步的进行 Checkpoint（除 RocksDB 状态后端存储、增量的 Checkpoint、基于堆的定时器外）。因为定时器实际上也是一种特殊状态的状态，在 Checkpoint 时会写入快照中，所以如果有大量的定时器，则无非会增加一次 Checkpoint 所需要的时间，必要的话得根据实际情况合并定时器。</p><h4 id="合并定时器"><a href="#合并定时器" class="headerlink" title="合并定时器"></a>合并定时器</h4><p>由于 Flink 仅为每个 Key 和时间戳维护一个定时器，因此可以通过降低定时器的频率来进行合并以减少定时器的数量。对于频率为 1 秒的定时器（基于事件时间或处理时间），可以将目标时间向下舍入为整秒数，则定时器最多提前 1 秒触发，但不会迟于我们的要求，精确到毫秒。因此，每个键每秒最多有一个定时器。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> coalescedTime = ((ctx.timestamp() + timeout) / <span class="number">1000</span>) * <span class="number">1000</span>;</span><br><span class="line">ctx.timerService().registerProcessingTimeTimer(coalescedTime);</span><br></pre></td></tr></table></figure><p>由于事件时间计时器仅在 Watermark 到达时才触发，因此可以将当前 Watermark 与下一个 Watermark 的定时器一起调度和合并：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> coalescedTime = ctx.timerService().currentWatermark() + <span class="number">1</span>;</span><br><span class="line">ctx.timerService().registerEventTimeTimer(coalescedTime);</span><br></pre></td></tr></table></figure><p>定时器也可以类似下面这样移除：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//删除处理时间定时器</span></span><br><span class="line"><span class="keyword">long</span> timestampOfTimerToStop = ...</span><br><span class="line">ctx.timerService().deleteProcessingTimeTimer(timestampOfTimerToStop);</span><br><span class="line"></span><br><span class="line"><span class="comment">//删除事件时间定时器</span></span><br><span class="line"><span class="keyword">long</span> timestampOfTimerToStop = ...</span><br><span class="line">ctx.timerService().deleteEventTimeTimer(timestampOfTimerToStop);</span><br></pre></td></tr></table></figure><p>如果没有该时间戳的定时器，则删除定时器无效。</p><h3 id="11-2-4-如果利用-ProcessFunction-处理宕机告警？"><a href="#11-2-4-如果利用-ProcessFunction-处理宕机告警？" class="headerlink" title="11.2.4 如果利用 ProcessFunction 处理宕机告警？"></a>11.2.4 如果利用 ProcessFunction 处理宕机告警？</h3><h4 id="宕机告警需求分析"><a href="#宕机告警需求分析" class="headerlink" title="宕机告警需求分析"></a>宕机告警需求分析</h4><h4 id="宕机告警代码实现"><a href="#宕机告警代码实现" class="headerlink" title="宕机告警代码实现"></a>宕机告警代码实现</h4><h3 id="11-2-5-小结与反思"><a href="#11-2-5-小结与反思" class="headerlink" title="11.2.5 小结与反思"></a>11.2.5 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-2-如何使用-Flink-ProcessFunction-处理宕机告警&quot;&gt;&lt;a href=&quot;#11-2-如何使用-Flink-ProcessFunction-处理宕机告警&quot; class=&quot;headerlink&quot; title=&quot;11.2 如何使用 Flink ProcessFunction 处理宕机告警?&quot;&gt;&lt;/a&gt;11.2 如何使用 Flink ProcessFunction 处理宕机告警?&lt;/h2&gt;&lt;p&gt;在 3.3 节中讲解了 Process 算子的概念，本节中将更详细的讲解 Flink ProcessFunction，然后教大家如何使用 ProcessFunction 来解决公司中常见的问题 —— 宕机，这个宕机不仅仅包括机器宕机，还包含应用宕机，通常出现宕机带来的影响是会很大的，所以能及时收到告警会减少损失。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何统计网站各页面一天内的 PV 和 UV？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/14/flink-in-action-11.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/14/flink-in-action-11.1/</id>
    <published>2021-08-13T16:00:00.000Z</published>
    <updated>2022-02-07T13:59:31.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第十一章-——-Flink-实战"><a href="#第十一章-——-Flink-实战" class="headerlink" title="第十一章 —— Flink 实战"></a>第十一章 —— Flink 实战</h1><p>本章主要是 Flink 实战，介绍了一些常见的需求，比如实时统计网站页面的 PV/UV、宕机告警、动态更新配置、应用 Error 日志实时告警等，然后分别去分析这些需求的实现方式，明白该使用 Flink 中的哪些知识点才能够很好的完成这种需求，并提供完整的案例代码供大家参考。在实现完成这些需求之后，笔者还将会更深一步的去讲解下这些知识点背后的实现方式，希望可以加深你对这些知识点的印象，以便后面你可以灵活的处理类似的需求。</p><h2 id="11-1-如何统计网站各页面一天内的-PV-和-UV？"><a href="#11-1-如何统计网站各页面一天内的-PV-和-UV？" class="headerlink" title="11.1 如何统计网站各页面一天内的 PV 和 UV？"></a>11.1 如何统计网站各页面一天内的 PV 和 UV？</h2><p>大数据开发最常统计的需求可能就是 PV、UV。PV 全拼 PageView，即页面访问量，用户每次对网站的访问均被记录，按照访问量进行累计，假如用户对同一页面访问了 5 次，那该页面的 PV 就应该加 5。UV 全拼为 UniqueVisitor，即独立访问用户数，访问该页面的一台电脑客户端为一个访客，假如用户对同一页面访问了 5 次，那么该页面的 UV 只应该加 1，因为 UV 计算的是去重后的用户数而不是访问次数。当然如果是按天统计，那么当天 0 点到 24 点相同的客户端只被计算一次，如果过了今天 24 点，第二天该用户又访问了该页面，那么第二天该页面的 UV 应该加 1。 概念明白了那如何使用 Flink 来统计网站各页面的 PV 和 UV 呢？通过本节来详细描述。</p><a id="more"></a><h3 id="11-1-1-统计网站各页面一天内的-PV"><a href="#11-1-1-统计网站各页面一天内的-PV" class="headerlink" title="11.1.1 统计网站各页面一天内的 PV"></a>11.1.1 统计网站各页面一天内的 PV</h3><p>在 9.5.2 节端对端如何保证 Exactly Once 中的幂等性写入如何保证端对端 Exactly Once 部分已经用案例讲述了如何通过 Flink 的状态来计算 APP 的 PV，并能够保证 Exactly Once。如果在工作中需要计算网站各页面一天内的 PV，只需要将案例中的 APP 替换成各页面的 id 或者各页面的 url 进行统计即可，按照各页面 id 和日期组合做为 key 进行 keyBy，相同页面、相同日期的数据发送到相同的实例中进行 PV 值的累加，每个 key 对应一个 ValueState，将 PV 值维护在 ValueState 即可。如果一些页面属于爆款页面，例如首页或者活动页面访问特别频繁就可能出现某些 subtask 上的数据量特别大，导致各个 subtask 之前出现数据倾斜的问题，关于数据倾斜的解决方案请参考 9.6 节。</p><h3 id="11-1-2-统计网站各页面一天内-UV-的三种方案"><a href="#11-1-2-统计网站各页面一天内-UV-的三种方案" class="headerlink" title="11.1.2 统计网站各页面一天内 UV 的三种方案"></a>11.1.2 统计网站各页面一天内 UV 的三种方案</h3><p>PV 统计相对来说比较简单，每来一条用户的访问日志只需要从日志中提取出相应的页面 id 和日期，将其对应的 PV 值加一即可。相对而言统计 UV 就有难度了，同一个用户一天内多次访问同一个页面，只能计数一次。所以每来一条日志，日志中对应页面的 UV 值是否需要加一呢？存在两种情况：如果该用户今天第一次访问该页面，那么 UV 应该加一。如果该用户今天不是第一次访问该页面，表示 UV 中已经记录了该用户，UV 要基于用户去重，所以此时 UV 值不应该加一。难点就在于如何判断该用户今天是不是第一次访问该页面呢？</p><p>把问题简单化，先不考虑日期，现在统计网站各页面的累积 UV，可以为每个页面维护一个 Set 集合，假如网站有 10 个页面，那么就维护 10 个 Set 集合，集合中存放着所有访问过该页面用户的 user_id。每来一条用户的访问日志，我们都需要从日志中解析出相应的页面 id 和用户 user_id，去该页面 id 对应的 Set 中查找该 user_id 之前有没有访问过该页面，如果 Set 中包含该 user_id 表示该用户之前访问过该页面，所以该页面的 UV 值不应该加一，如果 Set 中不包含该 user_id 表示该用户之前没有访问过该页面，所以该页面的 UV 值应该加一，并且将该 user_id 插入到该页面对应的 Set 中，表示该用户访问过该页面了。要按天去统计各页面 UV，只需要将日期和页面 id 看做一个整体 key，每个 key 对应一个 Set，其他流程与上述类似。具体的程序流程图如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-11-151250.png" alt=""></p><h4 id="使用-Redis-的-set-来维护用户集合"><a href="#使用-Redis-的-set-来维护用户集合" class="headerlink" title="使用 Redis 的 set 来维护用户集合"></a>使用 Redis 的 set 来维护用户集合</h4><p>每个 key 都需要维护一个 Set，这个 Set 存放在哪里呢？这里每条日志都需要访问一次 Set，对 Set 访问比较频繁，对存储介质的延迟要求比较高，所以可以使用 Redis 的 set 数据结构，Redis 的 set 数据结构也会对数据进行去重。可以将页面 id 和日期拼接做为 Redis 的 key，通过 Redis 的 sadd 命令将 user_id 放到 key 对应的 set 中即可。Redis 的 set 中存放着今天访问过该页面所有用户的 user_id。</p><p>在真实的工作中，Flink 任务可能不需要维护一个 UV 值，Flink 任务承担的角色是实时计算，而查询 UV 可能是一个 Java Web 项目。Web 项目只需要去 Redis 查询相应 key 对应的 set 中元素的个数即可，Redis 的 set 数据结构有 scard 命令可以查询 set 中元素个数，这里的元素个数就是我们所要统计的网站各页面每天的 UV 值。所以使用 Redis set 数据结构的方案 Flink 任务的代码很简单，只需要从日志中解析出相应的日期、页面id 和 user_id，将日期和页面 id 组合做为 Redis 的 key，最后将 user_id 通过 sadd 命令添加到 set 中，Flink 任务的工作就结束了，之后 Web 项目就能从 Redis 中查询到实时增加的 UV 了。下面来看详细的代码实现。</p><p>用户访问网站页面的日志实体类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserVisitWebEvent</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 日志的唯一 id</span></span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">    <span class="comment">// 日期，如：20191025</span></span><br><span class="line">    <span class="keyword">private</span> String date;</span><br><span class="line">    <span class="comment">// 页面 id</span></span><br><span class="line">    <span class="keyword">private</span> Integer pageId;</span><br><span class="line">    <span class="comment">// 用户的唯一标识，用户 id</span></span><br><span class="line">    <span class="keyword">private</span> String userId;</span><br><span class="line">    <span class="comment">// 页面的 url</span></span><br><span class="line">    <span class="keyword">private</span> String url;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成测试数据的核心代码如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">String yyyyMMdd = <span class="keyword">new</span> DateTime(System.currentTimeMillis()).toString(<span class="string">"yyyyMMdd"</span>);</span><br><span class="line"><span class="keyword">int</span> pageId = random.nextInt(<span class="number">10</span>);    <span class="comment">// 随机生成页面 id</span></span><br><span class="line"><span class="keyword">int</span> userId = random.nextInt(<span class="number">100</span>);   <span class="comment">// 随机生成用户 id</span></span><br><span class="line"></span><br><span class="line">UserVisitWebEvent userVisitWebEvent = UserVisitWebEvent.builder()</span><br><span class="line">        .id(UUID.randomUUID().toString())   <span class="comment">// 日志的唯一 id</span></span><br><span class="line">        .date(yyyyMMdd)                     <span class="comment">// 日期</span></span><br><span class="line">        .pageId(pageId)                     <span class="comment">// 页面 id</span></span><br><span class="line">        .userId(Integer.toString(userId))   <span class="comment">// 用户 id</span></span><br><span class="line">        .url(<span class="string">"url/"</span> + pageId)               <span class="comment">// 页面的 url</span></span><br><span class="line">        .build();</span><br><span class="line"><span class="comment">// 对象序列化为 JSON 发送到 Kafka</span></span><br><span class="line">ProducerRecord record = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(topic,</span><br><span class="line">        <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(userVisitWebEvent));</span><br><span class="line">producer.send(record);</span><br></pre></td></tr></table></figure><p>统计 UV 的核心代码如下，对 Redis Connector 不熟悉的请参阅 3.11 节如何使用 Flink Connectors —— Redis：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisSetUvExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//  省略了 env初始化及 Checkpoint 相关配置</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, UvExampleUtil.broker_list);</span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"app-uv-stat"</span>);</span><br><span class="line"></span><br><span class="line">        FlinkKafkaConsumerBase&lt;String&gt; kafkaConsumer = <span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">                UvExampleUtil.topic, <span class="keyword">new</span> SimpleStringSchema(), props)</span><br><span class="line">                .setStartFromLatest();</span><br><span class="line"></span><br><span class="line">        FlinkJedisPoolConfig conf = <span class="keyword">new</span> FlinkJedisPoolConfig</span><br><span class="line">                .Builder().setHost(<span class="string">"192.168.30.244"</span>).build();</span><br><span class="line"></span><br><span class="line">        env.addSource(kafkaConsumer)</span><br><span class="line">                .map(string -&gt; &#123;</span><br><span class="line">                    <span class="comment">// 反序列化 JSON</span></span><br><span class="line">                    UserVisitWebEvent userVisitWebEvent = GsonUtil.fromJson(</span><br><span class="line">                            string, UserVisitWebEvent.class);</span><br><span class="line">                    <span class="comment">// 生成 Redis key，格式为 日期_pageId，如: 20191026_0</span></span><br><span class="line">                    String redisKey = userVisitWebEvent.getDate() + <span class="string">"_"</span></span><br><span class="line">                            + userVisitWebEvent.getPageId();</span><br><span class="line">                    <span class="keyword">return</span> Tuple2.of(redisKey, userVisitWebEvent.getUserId());</span><br><span class="line">                &#125;)</span><br><span class="line">                .returns(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;String, String&gt;&gt;()&#123;&#125;)</span><br><span class="line">                .addSink(<span class="keyword">new</span> RedisSink&lt;&gt;(conf, <span class="keyword">new</span> RedisSaddSinkMapper()));</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">"Redis Set UV Stat"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 数据与 Redis key 的映射关系</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisSaddSinkMapper</span> </span></span><br><span class="line"><span class="class">            <span class="keyword">implements</span> <span class="title">RedisMapper</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt;&gt; </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> RedisCommandDescription <span class="title">getCommandDescription</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">//  这里必须是 sadd 操作</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RedisCommandDescription(RedisCommand.SADD);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getKeyFromData</span><span class="params">(Tuple2&lt;String, String&gt; data)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> data.f0;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getValueFromData</span><span class="params">(Tuple2&lt;String, String&gt; data)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> data.f1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Redis 中统计结果如下图所示，左侧展示的 Redis key，20191026_1 表示 2019年10月26日浏览过 pageId 为 1 的页面对应的 key，右侧展示 key 对应的 set 集合，表示 userId 为 [0,6,27,30,66,67,79,88] 的用户在 2019年10月26日浏览过 pageId 为 1 的页面。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-31-174242.jpg" style="zoom:50%;" /></p><p>要想获取 20191026_1 对应的 UV 值，可通过 scard 命令获取 set 中 user_id 的数量，具体操作如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span> scard 20191026_1</span><br><span class="line">8</span><br></pre></td></tr></table></figure><p>通过上述代码即可通过 Redis 的 set 数据结构来统计网站各页面的 UV。</p><h4 id="使用-Flink-的-KeyedState-来维护用户集合"><a href="#使用-Flink-的-KeyedState-来维护用户集合" class="headerlink" title="使用 Flink 的 KeyedState 来维护用户集合"></a>使用 Flink 的 KeyedState 来维护用户集合</h4><h4 id="使用-Redis-的-HyperLogLog-来统计-UV"><a href="#使用-Redis-的-HyperLogLog-来统计-UV" class="headerlink" title="使用 Redis 的 HyperLogLog 来统计 UV"></a>使用 Redis 的 HyperLogLog 来统计 UV</h4><h3 id="11-1-3-小结与反思"><a href="#11-1-3-小结与反思" class="headerlink" title="11.1.3 小结与反思"></a>11.1.3 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第十一章-——-Flink-实战&quot;&gt;&lt;a href=&quot;#第十一章-——-Flink-实战&quot; class=&quot;headerlink&quot; title=&quot;第十一章 —— Flink 实战&quot;&gt;&lt;/a&gt;第十一章 —— Flink 实战&lt;/h1&gt;&lt;p&gt;本章主要是 Flink 实战，介绍了一些常见的需求，比如实时统计网站页面的 PV/UV、宕机告警、动态更新配置、应用 Error 日志实时告警等，然后分别去分析这些需求的实现方式，明白该使用 Flink 中的哪些知识点才能够很好的完成这种需求，并提供完整的案例代码供大家参考。在实现完成这些需求之后，笔者还将会更深一步的去讲解下这些知识点背后的实现方式，希望可以加深你对这些知识点的印象，以便后面你可以灵活的处理类似的需求。&lt;/p&gt;
&lt;h2 id=&quot;11-1-如何统计网站各页面一天内的-PV-和-UV？&quot;&gt;&lt;a href=&quot;#11-1-如何统计网站各页面一天内的-PV-和-UV？&quot; class=&quot;headerlink&quot; title=&quot;11.1 如何统计网站各页面一天内的 PV 和 UV？&quot;&gt;&lt;/a&gt;11.1 如何统计网站各页面一天内的 PV 和 UV？&lt;/h2&gt;&lt;p&gt;大数据开发最常统计的需求可能就是 PV、UV。PV 全拼 PageView，即页面访问量，用户每次对网站的访问均被记录，按照访问量进行累计，假如用户对同一页面访问了 5 次，那该页面的 PV 就应该加 5。UV 全拼为 UniqueVisitor，即独立访问用户数，访问该页面的一台电脑客户端为一个访客，假如用户对同一页面访问了 5 次，那么该页面的 UV 只应该加 1，因为 UV 计算的是去重后的用户数而不是访问次数。当然如果是按天统计，那么当天 0 点到 24 点相同的客户端只被计算一次，如果过了今天 24 点，第二天该用户又访问了该页面，那么第二天该页面的 UV 应该加 1。 概念明白了那如何使用 Flink 来统计网站各页面的 PV 和 UV 呢？通过本节来详细描述。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何设置 Flink Job RestartStrategy（重启策略）？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/13/flink-in-action-10.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/13/flink-in-action-10.2/</id>
    <published>2021-08-12T16:00:00.000Z</published>
    <updated>2022-01-23T12:10:45.524Z</updated>
    
    <content type="html"><![CDATA[<h2 id="10-2-如何使用-Flink-ParameterTool-读取配置？"><a href="#10-2-如何使用-Flink-ParameterTool-读取配置？" class="headerlink" title="10.2 如何使用 Flink ParameterTool 读取配置？"></a>10.2 如何使用 Flink ParameterTool 读取配置？</h2><p>在使用 Flink 中不知道你有没有觉得配置的管理很不方便，比如像算子的并行度配置、Kafka 数据源的配置（broker 地址、topic 名、group.id）、Checkpoint 是否开启、状态后端存储路径、数据库地址、用户名和密码等，反正各种各样的配置都杂乱在一起，当然你可能说我就在代码里面写死不就好了，但是你有没有想过你的作业是否可以不修改任何配置就直接在各种环境（开发、测试、预发、生产）运行呢？可能每个环境的这些配置对应的值都是不一样的，如果你是直接在代码里面写死的配置，那这下子就比较痛苦了，每次换个环境去运行测试你的作业，你都要重新去修改代码中的配置，然后编译打包，提交运行，这样你就要花费很多时间在这些重复的劳动力上了。有没有什么办法可以解决这种问题呢？</p><a id="more"></a><h3 id="10-2-1-Flink-Job-配置"><a href="#10-2-1-Flink-Job-配置" class="headerlink" title="10.2.1 Flink Job 配置"></a>10.2.1 Flink Job 配置</h3><p>在 Flink 中其实是有几种方法来管理配置，下面分别来讲解一下。</p><h4 id="使用-Configuration"><a href="#使用-Configuration" class="headerlink" title="使用 Configuration"></a>使用 Configuration</h4><p>Flink 提供了 withParameters 方法，它可以传递 Configuration 中的参数给，要使用它，需要实现那些 Rich 函数，比如实现 RichMapFunction，而不是 MapFunction，因为 Rich 函数中有 open 方法，然后可以重写 open 方法通过 Configuration 获取到传入的参数值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// Configuration 类来存储参数</span></span><br><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">configuration.setString(<span class="string">"name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line"></span><br><span class="line">env.fromElements(WORDS)</span><br><span class="line">        .flatMap(<span class="keyword">new</span> RichFlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            String name;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">//读取配置</span></span><br><span class="line">                name = parameters.getString(<span class="string">"name"</span>, <span class="string">""</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                String[] splits = value.toLowerCase().split(<span class="string">"\\W+"</span>);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> (String split : splits) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (split.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        out.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(split + name, <span class="number">1</span>));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).withParameters(configuration)    <span class="comment">//将参数传递给函数</span></span><br><span class="line">        .print();</span><br></pre></td></tr></table></figure><p>但是要注意这个 withParameters 只在批程序中支持，流程序中是没有该方法的，并且这个 withParameters 要在每个算子后面使用才行，并不是一次使用就所有都可以获取到，如果所有算子都要该配置，那么就重复设置多次就会比较繁琐。</p><h3 id="10-2-2-ParameterTool-管理配置"><a href="#10-2-2-ParameterTool-管理配置" class="headerlink" title="10.2.2 ParameterTool 管理配置"></a>10.2.2 ParameterTool 管理配置</h3><p>上面通过 Configuration 的局限性很大，其实在 Flink 中还可以通过使用 ParameterTool 类读取配置，它可以读取环境变量、运行参数、配置文件，下面分别讲下每种如何使用。</p><h4 id="读取运行参数"><a href="#读取运行参数" class="headerlink" title="读取运行参数"></a>读取运行参数</h4><p>我们知道 Flink UI 上是支持为每个 Job 单独传入 arguments（参数）的，它的格式要求是如下这种。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--brokers 127.0.0.1:9200</span><br><span class="line">--username admin</span><br><span class="line">--password 123456</span><br></pre></td></tr></table></figure><p>或者这种</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-brokers 127.0.0.1:9200</span><br><span class="line">-username admin</span><br><span class="line">-password 123456</span><br></pre></td></tr></table></figure><p>然后在 Flink 程序中你可以直接使用 <code>ParameterTool.fromArgs(args)</code> 获取到所有的参数，然后如果你要获取某个参数对应的值的话，可以通过 <code>parameterTool.get(&quot;username&quot;)</code> 方法。那么在这个地方其实你就可以将配置放在一个第三方的接口，然后这个参数值中传入一个接口，拿到该接口后就能够通过请求去获取更多你想要的配置。</p><h4 id="读取系统属性"><a href="#读取系统属性" class="headerlink" title="读取系统属性"></a>读取系统属性</h4><p>ParameterTool 还支持通过 <code>ParameterTool.fromSystemProperties()</code> 方法读取系统属性。</p><h4 id="读取配置文件"><a href="#读取配置文件" class="headerlink" title="读取配置文件"></a>读取配置文件</h4><p>除了上面两种外，ParameterTool 还支持 <code>ParameterTool.fromPropertiesFile(&quot;/application.properties&quot;)</code> 读取 properties 配置文件。你可以将所有要配置的地方（比如并行度和一些 Kafka、MySQL 等配置）都写成可配置的，然后其对应的 key 和 value 值都写在配置文件中，最后通过 ParameterTool 去读取配置文件获取对应的值。</p><h4 id="ParameterTool-获取值"><a href="#ParameterTool-获取值" class="headerlink" title="ParameterTool 获取值"></a>ParameterTool 获取值</h4><p>ParameterTool 类提供了很多便捷方法去获取值，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-09-134119.png" alt=""></p><p>你可以在应用程序的 main() 方法中直接使用这些方法返回的值，例如：你可以按如下方法来设置一个算子的并行度：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ParameterTool parameters = ParameterTool.fromArgs(args);</span><br><span class="line"><span class="keyword">int</span> parallelism = parameters.get(<span class="string">"mapParallelism"</span>, <span class="number">2</span>);</span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts = data.flatMap(<span class="keyword">new</span> Tokenizer()).setParallelism(parallelism);</span><br></pre></td></tr></table></figure><p>因为 ParameterTool 是可序列化的，所以你可以将它当作参数进行传递给自定义的函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ParameterTool parameters = ParameterTool.fromArgs(args);</span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts = dara.flatMap(<span class="keyword">new</span> Tokenizer(parameters));</span><br></pre></td></tr></table></figure><p>然后在函数内部使用 ParameterTool 来获取命令行参数，这样就意味着你在作业任何地方都可以获取到参数，而不是像 withParameters 一样需要每次都设置。</p><h4 id="注册全局参数"><a href="#注册全局参数" class="headerlink" title="注册全局参数"></a>注册全局参数</h4><p>在 ExecutionConfig 中可以将 ParameterTool 注册为全作业参数的参数，这样就可以被 JobManager 的 web 端以及用户自定义函数中以配置值的形式访问。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.getConfig().setGlobalJobParameters(ParameterTool.fromArgs(args));</span><br></pre></td></tr></table></figure><p>然后就可以在用户自定义的 Rich 函数中像如下这样获取到参数值了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">env.addSource(<span class="keyword">new</span> RichSourceFunction&lt;String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;String&gt; sourceContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ParameterTool parameterTool = (ParameterTool) getRuntimeContext().getExecutionConfig().getGlobalJobParameters();</span><br><span class="line">            sourceContext.collect(System.currentTimeMillis() + parameterTool.get(<span class="string">"os.name"</span>) + parameterTool.get(<span class="string">"user.home"</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>在笔者公司内通常是以 Job 运行的环境变量为准，比如我们是运行在 K8s 上面，那么我们会为我们的这个 Flink Job 设置很多环境变量，设置的环境变量的值就得通过 ParameterTool 类去获取，我们是会优先根据环境变量的值为准，如果环境变量的值没有就会去读取应用运行参数，如果应用运行参数也没有才会去读取之前已经写好在配置文件中的配置。大概代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ParameterTool <span class="title">createParameterTool</span><span class="params">(<span class="keyword">final</span> String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ParameterTool</span><br><span class="line">            .fromPropertiesFile(ExecutionEnv.class.getResourceAsStream(<span class="string">"/application.properties"</span>))</span><br><span class="line">            .mergeWith(ParameterTool.fromArgs(args))</span><br><span class="line">            .mergeWith(ParameterTool.fromSystemProperties())</span><br><span class="line">            .mergeWith(ParameterTool.fromMap(getenv()));<span class="comment">// mergeWith 会使用最新的配置</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取 Job 设置的环境变量</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">getenv</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry : System.getenv().entrySet()) &#123;</span><br><span class="line">        map.put(entry.getKey().toLowerCase().replace(<span class="string">'_'</span>, <span class="string">'.'</span>), entry.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> map;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样如果 Job 要更改一些配置，直接在 Job 在 K8s 上面的环境变量进行配置就好了，修改配置后然后重启 Job 就可以运行起来了，整个过程都不需要再次将作业重新编译打包的。但是这样其实也有一定的坏处，重启一个作业的代价很大，因为在重启后你又要去保证状态要恢复到之前未重启时的状态，尽管 Flink 中的 Checkpoint 和 Savepoint 已经很强大了，但是对于复杂的它来说我们多一事不如少一事，所以其实更希望能够直接动态的获取配置，如果配置做了更改，作业能够感知到。在 Flink 中有的配置是不能够动态设置的，但是比如应用业务配置却是可以做到动态的配置，这时就需要使用比较强大的广播变量，广播变量在之前 3.4 节已经介绍过了，如果忘记可以再回去查看，另外在 11.4 节中会通过一个实际案例来教你如何使用广播变量去动态的更新配置数据。</p><h3 id="10-2-3-ParameterTool-源码分析"><a href="#10-2-3-ParameterTool-源码分析" class="headerlink" title="10.2.3 ParameterTool 源码分析"></a>10.2.3 ParameterTool 源码分析</h3><h3 id="10-2-4-自定义配置参数类"><a href="#10-2-4-自定义配置参数类" class="headerlink" title="10.2.4 自定义配置参数类"></a>10.2.4 自定义配置参数类</h3><h3 id="10-2-5-小结与反思"><a href="#10-2-5-小结与反思" class="headerlink" title="10.2.5 小结与反思"></a>10.2.5 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>本章讲了两个实践相关的内容，一个是作业的重启策略，从分析真实线上故障来教大家如何去配置重启策略，以及介绍重启策略的种类，另一个是使用 ParameterTool 去管理配置。两个实践都是比较真实且有一定帮助作用的，希望你也可以应用在你的项目中去。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;10-2-如何使用-Flink-ParameterTool-读取配置？&quot;&gt;&lt;a href=&quot;#10-2-如何使用-Flink-ParameterTool-读取配置？&quot; class=&quot;headerlink&quot; title=&quot;10.2 如何使用 Flink ParameterTool 读取配置？&quot;&gt;&lt;/a&gt;10.2 如何使用 Flink ParameterTool 读取配置？&lt;/h2&gt;&lt;p&gt;在使用 Flink 中不知道你有没有觉得配置的管理很不方便，比如像算子的并行度配置、Kafka 数据源的配置（broker 地址、topic 名、group.id）、Checkpoint 是否开启、状态后端存储路径、数据库地址、用户名和密码等，反正各种各样的配置都杂乱在一起，当然你可能说我就在代码里面写死不就好了，但是你有没有想过你的作业是否可以不修改任何配置就直接在各种环境（开发、测试、预发、生产）运行呢？可能每个环境的这些配置对应的值都是不一样的，如果你是直接在代码里面写死的配置，那这下子就比较痛苦了，每次换个环境去运行测试你的作业，你都要重新去修改代码中的配置，然后编译打包，提交运行，这样你就要花费很多时间在这些重复的劳动力上了。有没有什么办法可以解决这种问题呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何设置 Flink Job RestartStrategy（重启策略）？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/12/flink-in-action-10.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/12/flink-in-action-10.1/</id>
    <published>2021-08-11T16:00:00.000Z</published>
    <updated>2022-01-23T12:08:58.313Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第十章-——-Flink-最佳实践"><a href="#第十章-——-Flink-最佳实践" class="headerlink" title="第十章 —— Flink 最佳实践"></a>第十章 —— Flink 最佳实践</h1><p>本章将介绍两个最佳实践，第一个是如何合理的配置重启策略，笔者通过自己的亲身经历来讲述配置重启策略的重要性，接着介绍了 Flink 中的重启策略和恢复策略的发展实现过程；第二个是如何去管理 Flink 作业的配置。两个实践大家可以参考，不一定要照搬运用在自己的公司，同时也希望你可以思考下自己是否有啥最佳实践可以分享。</p><h2 id="10-1-如何设置-Flink-Job-RestartStrategy（重启策略）？"><a href="#10-1-如何设置-Flink-Job-RestartStrategy（重启策略）？" class="headerlink" title="10.1 如何设置 Flink Job RestartStrategy（重启策略）？"></a>10.1 如何设置 Flink Job RestartStrategy（重启策略）？</h2><p>从使用 Flink 到至今，遇到的 Flink 有很多，解决的问题更多（含帮助微信好友解决问题），所以对于 Flink 可能遇到的问题及解决办法都比较清楚，那么在这章就给大家讲解下几个 Flink 中比较常遇到的问题的解决办法。</p><a id="more"></a><h3 id="10-1-1-常见错误导致-Flink-作业重启"><a href="#10-1-1-常见错误导致-Flink-作业重启" class="headerlink" title="10.1.1 常见错误导致 Flink 作业重启"></a>10.1.1 常见错误导致 Flink 作业重启</h3><p>不知道大家是否有遇到过这样的问题：整个 Job 一直在重启，并且还会伴随着一些错误（可以通过 UI 查看 Exceptions 日志），以下三张图片中的错误信息是笔者曾经生产环境遇到过的一些问题。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-04-152844.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-140519.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-26-2019-05-14_00-59-25.png" alt=""></p><p>笔者就曾因为上图中的一个异常报错，作业一直重启，在深夜线上发版的时候，同事发现这个问题，凌晨两点的时候打电话把我叫醒起来修 BUG，真是惨的教训，哈哈哈，估计这辈子都忘不掉了！</p><p>其实遇到上面这种问题比较常见的，比如有时候因为数据的问题（不合规范、为 null 等），这时在处理这些脏数据的时候可能就会遇到各种各样的异常错误，比如空指针、数组越界、数据类型转换错误等。可能你会说只要过滤掉这种脏数据就行了，或者进行异常捕获就不会导致 Job 不断重启的问题了。</p><p>确实如此，如果做好了脏数据的过滤和异常的捕获，Job 的稳定性确实有保证，但是复杂的 Job 下每个算子可能都会产生出脏数据（包含源数据可能也会为空或者不合法的数据），你不可能在每个算子里面也用一个大的 try catch 做一个异常捕获，所以脏数据和异常简直就是防不胜防，不过我们还是要尽力的保证代码的健壮性，但是也要配置好 Flink Job 的 RestartStrategy（重启策略）。</p><h3 id="10-1-2-RestartStrategy-简介"><a href="#10-1-2-RestartStrategy-简介" class="headerlink" title="10.1.2 RestartStrategy 简介"></a>10.1.2 RestartStrategy 简介</h3><p>RestartStrategy，重启策略，在遇到机器或者代码等不可预知的问题时导致 Job 或者 Task 挂掉的时候，它会根据配置的重启策略将 Job 或者受影响的 Task 拉起来重新执行，以使得作业恢复到之前正常执行状态。Flink 中的重启策略决定了是否要重启 Job 或者 Task，以及重启的次数和每次重启的时间间隔。</p><h3 id="10-1-3-为什么需要-RestartStrategy？"><a href="#10-1-3-为什么需要-RestartStrategy？" class="headerlink" title="10.1.3 为什么需要 RestartStrategy？"></a>10.1.3 为什么需要 RestartStrategy？</h3><p>重启策略会让 Job 从上一次完整的 Checkpoint 处恢复状态，保证 Job 和挂之前的状态保持一致，另外还可以让 Job 继续处理数据，不会出现 Job 挂了导致消息出现大量堆积的问题，合理的设置重启策略可以减少 Job 不可用时间和避免人工介入处理故障的运维成本，因此重启策略对于 Flink Job 的稳定性来说有着举足轻重的作用。</p><h3 id="10-1-4-如何配置-RestartStrategy？"><a href="#10-1-4-如何配置-RestartStrategy？" class="headerlink" title="10.1.4 如何配置 RestartStrategy？"></a>10.1.4 如何配置 RestartStrategy？</h3><p>既然 Flink 中的重启策略作用这么大，那么该如何配置呢？其实如果 Flink Job 没有单独设置重启重启策略的话，则会使用集群启动时加载的默认重启策略，如果 Flink Job 中单独设置了重启策略则会覆盖默认的集群重启策略。默认重启策略可以在 Flink 的配置文件 <code>flink-conf.yaml</code> 中设置，由 <code>restart-strategy</code> 参数控制，有 fixed-delay（固定延时重启策略）、failure-rate（故障率重启策略）、none（不重启策略）三种可以选择，如果选择的参数不同，对应的其他参数也不同。下面分别介绍这几种重启策略和如何配置。</p><h4 id="FixedDelayRestartStrategy（固定延时重启策略）"><a href="#FixedDelayRestartStrategy（固定延时重启策略）" class="headerlink" title="FixedDelayRestartStrategy（固定延时重启策略）"></a>FixedDelayRestartStrategy（固定延时重启策略）</h4><p>FixedDelayRestartStrategy 是固定延迟重启策略，程序按照集群配置文件中或者程序中额外设置的重启次数尝试重启作业，如果尝试次数超过了给定的最大次数，程序还没有起来，则停止作业，另外还可以配置连续两次重启之间的等待时间，在 <code>flink-conf.yaml</code> 中可以像下面这样配置。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">fixed-delay</span></span><br><span class="line"><span class="string">restart-strategy.fixed-delay.attempts:</span> <span class="number">3</span>  <span class="comment">#表示作业重启的最大次数，启用 checkpoint 的话是 Integer.MAX_VALUE，否则是 1。</span></span><br><span class="line"><span class="string">restart-strategy.fixed-delay.delay:</span> <span class="number">10</span> <span class="string">s</span>  <span class="comment">#如果设置分钟可以类似 1 min，该参数表示两次重启之间的时间间隔，当程序与外部系统有连接交互时延迟重启可能会有帮助，启用 checkpoint 的话，延迟重启的时间是 10 秒，否则使用 akka.ask.timeout 的值。</span></span><br></pre></td></tr></table></figure><p>在程序中设置固定延迟重启策略的话如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 尝试重启的次数</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 延时</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure><h4 id="FailureRateRestartStrategy（故障率重启策略）"><a href="#FailureRateRestartStrategy（故障率重启策略）" class="headerlink" title="FailureRateRestartStrategy（故障率重启策略）"></a>FailureRateRestartStrategy（故障率重启策略）</h4><p>FailureRateRestartStrategy 是故障率重启策略，在发生故障之后重启作业，如果固定时间间隔之内发生故障的次数超过设置的值后，作业就会失败停止，该重启策略也支持设置连续两次重启之间的等待时间。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">failure-rate</span></span><br><span class="line"><span class="string">restart-strategy.failure-rate.max-failures-per-interval:</span> <span class="number">3</span>  <span class="comment">#固定时间间隔内允许的最大重启次数，默认 1</span></span><br><span class="line"><span class="string">restart-strategy.failure-rate.failure-rate-interval:</span> <span class="number">5</span> <span class="string">min</span>  <span class="comment">#固定时间间隔，默认 1 分钟</span></span><br><span class="line"><span class="string">restart-strategy.failure-rate.delay:</span> <span class="number">10</span> <span class="string">s</span> <span class="comment">#连续两次重启尝试之间的延迟时间，默认是 akka.ask.timeout</span></span><br></pre></td></tr></table></figure><p>可以在应用程序中这样设置来配置故障率重启策略：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.failureRateRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 固定时间间隔允许 Job 重启的最大次数</span></span><br><span class="line">  Time.of(<span class="number">5</span>, TimeUnit.MINUTES), <span class="comment">// 固定时间间隔</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 两次重启的延迟时间</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure><h4 id="NoRestartStrategy（不重启策略）"><a href="#NoRestartStrategy（不重启策略）" class="headerlink" title="NoRestartStrategy（不重启策略）"></a>NoRestartStrategy（不重启策略）</h4><p>NoRestartStrategy 作业不重启策略，直接失败停止，在 <code>flink-conf.yaml</code> 中配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">none</span></span><br></pre></td></tr></table></figure><p>在程序中如下设置即可配置不重启：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.noRestart());</span><br></pre></td></tr></table></figure><h4 id="Fallback（备用重启策略）"><a href="#Fallback（备用重启策略）" class="headerlink" title="Fallback（备用重启策略）"></a>Fallback（备用重启策略）</h4><p>如果程序没有启用 Checkpoint，则采用不重启策略，如果开启了 Checkpoint 且没有设置重启策略，那么采用固定延时重启策略，最大重启次数为 Integer.MAX_VALUE。</p><p>在应用程序中配置好了固定延时重启策略，可以测试一下代码异常后导致 Job 失败后重启的情况，然后观察日志，可以看到 Job 重启相关的日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Try to restart or fail the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) if no longer possible.</span><br><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) switched from state FAILING to RESTARTING.</span><br><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Restarting the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0).</span><br></pre></td></tr></table></figure><p>最后重启次数达到配置的最大重启次数后 Job 还没有起来的话，则会停止 Job 并打印日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[flink-akka.actor.default-dispatcher-2] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Could not restart the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) because the restart strategy prevented it.</span><br></pre></td></tr></table></figure><p>Flink 中几种重启策略的设置如上，大家可以根据需要选择合适的重启策略，比如如果程序抛出了空指针异常，但是你配置的是一直无限重启，那么就会导致 Job 一直在重启，这样无非再浪费机器资源，这种情况下可以配置重试固定次数，每次隔多久重试的固定延时重启策略，这样在重试一定次数后 Job 就会停止，如果对 Job 的状态做了监控告警的话，那么你就会收到告警信息，这样也会提示你去查看 Job 的运行状况，能及时的去发现和修复 Job 的问题。</p><h3 id="10-1-5-RestartStrategy-源码分析"><a href="#10-1-5-RestartStrategy-源码分析" class="headerlink" title="10.1.5 RestartStrategy 源码分析"></a>10.1.5 RestartStrategy 源码分析</h3><p>再介绍重启策略应用程序代码配置的时候不知道你有没有看到设置重启策略都是使用 RestartStrategies 类，通过该类的方法就可以创建不同的重启策略，在 RestartStrategies 类中提供了五个方法用来创建四种不同的重启策略（有两个方法是创建 FixedDelay 重启策略的，只不过方法的参数不同），如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151745.png" alt=""></p><p>在每个方法内部其实调用的是 RestartStrategies 中的内部静态类，分别是 NoRestartStrategyConfiguration、FixedDelayRestartStrategyConfiguration、FailureRateRestartStrategyConfiguration、FallbackRestartStrategyConfiguration，这四个类都继承自 RestartStrategyConfiguration 抽象类，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151617.png" alt=""></p><p>上面是定义的四种重启策略的配置类，在 Flink 中是靠 RestartStrategyResolving 类中的 resolve 方法来解析 RestartStrategies.RestartStrategyConfiguration，然后根据配置使用 RestartStrategyFactory 创建 RestartStrategy。RestartStrategy 是一个接口，它有 canRestart 和 restart 两个方法，它有四个实现类： FixedDelayRestartStrategy、FailureRateRestartStrategy、ThrowingRestartStrategy、NoRestartStrategy，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151311.png" alt=""></p><h3 id="10-1-6-Failover-Strategies（故障恢复策略）"><a href="#10-1-6-Failover-Strategies（故障恢复策略）" class="headerlink" title="10.1.6 Failover Strategies（故障恢复策略）"></a>10.1.6 Failover Strategies（故障恢复策略）</h3><h4 id="重启所有的任务"><a href="#重启所有的任务" class="headerlink" title="重启所有的任务"></a>重启所有的任务</h4><h4 id="基于-Region-的局部故障重启策略"><a href="#基于-Region-的局部故障重启策略" class="headerlink" title="基于 Region 的局部故障重启策略"></a>基于 Region 的局部故障重启策略</h4><h3 id="10-1-7-小结与反思"><a href="#10-1-7-小结与反思" class="headerlink" title="10.1.7 小结与反思"></a>10.1.7 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第十章-——-Flink-最佳实践&quot;&gt;&lt;a href=&quot;#第十章-——-Flink-最佳实践&quot; class=&quot;headerlink&quot; title=&quot;第十章 —— Flink 最佳实践&quot;&gt;&lt;/a&gt;第十章 —— Flink 最佳实践&lt;/h1&gt;&lt;p&gt;本章将介绍两个最佳实践，第一个是如何合理的配置重启策略，笔者通过自己的亲身经历来讲述配置重启策略的重要性，接着介绍了 Flink 中的重启策略和恢复策略的发展实现过程；第二个是如何去管理 Flink 作业的配置。两个实践大家可以参考，不一定要照搬运用在自己的公司，同时也希望你可以思考下自己是否有啥最佳实践可以分享。&lt;/p&gt;
&lt;h2 id=&quot;10-1-如何设置-Flink-Job-RestartStrategy（重启策略）？&quot;&gt;&lt;a href=&quot;#10-1-如何设置-Flink-Job-RestartStrategy（重启策略）？&quot; class=&quot;headerlink&quot; title=&quot;10.1 如何设置 Flink Job RestartStrategy（重启策略）？&quot;&gt;&lt;/a&gt;10.1 如何设置 Flink Job RestartStrategy（重启策略）？&lt;/h2&gt;&lt;p&gt;从使用 Flink 到至今，遇到的 Flink 有很多，解决的问题更多（含帮助微信好友解决问题），所以对于 Flink 可能遇到的问题及解决办法都比较清楚，那么在这章就给大家讲解下几个 Flink 中比较常遇到的问题的解决办法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何处理 Flink 中数据倾斜问题？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/11/flink-in-action-9.6/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/11/flink-in-action-9.6/</id>
    <published>2021-08-10T16:00:00.000Z</published>
    <updated>2022-01-23T12:05:28.185Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-6-如何处理-Flink-中数据倾斜问题？"><a href="#9-6-如何处理-Flink-中数据倾斜问题？" class="headerlink" title="9.6 如何处理 Flink 中数据倾斜问题？"></a>9.6 如何处理 Flink 中数据倾斜问题？</h2><p>在大数据计算场景，无论使用 MapReduce、Spark 还是 Flink 计算框架，无论是批处理还是流处理都存在数据倾斜的问题，通过本节学习产生数据倾斜的原因及如何在生产环境解决数据倾斜。</p><a id="more"></a><h3 id="9-6-1-数据倾斜简介"><a href="#9-6-1-数据倾斜简介" class="headerlink" title="9.6.1 数据倾斜简介"></a>9.6.1 数据倾斜简介</h3><p>分析一个计算各 app PV 的案例，如下图所示，圆球表示 app1 的日志，方块表示 app2 的日志，Source 端从外部系统读取用户上报的各 app 行为日志，要计算各 app 的 PV，所以按照 app 进行 keyBy，相同 app 的数据发送到同一个 Operator 实例中处理，keyBy 后对 app 的 PV 值进行累加来，最后将计算的 PV 结果输出到外部 Sink 端。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004442.jpg" alt=""></p><p>可以看到在任务运行过程中，计算 Count 的算子有两个并行度，其中一个并行度处理 app1 的数据，另一个并行度处理 app2 的数据。由于 app1 比较热门，所以 app1 的日志量远大于 app2 的日志量，造成计算 app1 PV 的并行度压力过大成为整个系统的瓶颈，而计算 app2 PV 的并行度数据量较少所以 CPU、内存以及网络资源的使用率整体都比较低，这就是产生数据倾斜的案例。</p><p>随着业务的不断发展，如果 app1 的日志量暴增，单个节点的单个并行度已经承担不了计算 app1 PV 的任务，此时如何来解决呢？对于不了解数据倾斜的同学看到 Flink 任务出现了延迟，结合之前学习的反压章节，定位整个 Flink 任务的瓶颈在于 Count 算子，所以认为 Count 算子的并行度不够，于是解决思路就是调大 Count 算子的并行度至 4 来提高 Count 算子的计算能力，调大并行度以后发现 Flink 任务的吞吐量并没有提升，而且通过反压机制定位到系统的瓶颈还在于 Count 算子，难道 Count 算子的并行度需要从 2 调大到 10 吗？No，上述情况就算把并行度调大到 100，依然不能解决任务瓶颈。为什么出现这种情况呢？要计算各 app 的 PV 数据，那么相同 app 的数据必然要发送到相同的 Operator 实例去处理，现在只有两个 app，最多只能分配到两个并行度上去执行，如果 Count 算子的并行度大于 2，意味着肯定有一些并行度分配不到数据，所以上述情况调大 Count 算子的并行度不能解决问题。那使用 Flink 如何来解决数据倾斜呢，我们先学习 Flink 中如何来判断是否发生了数据倾斜。</p><h3 id="9-6-2-判断是否存在数据倾斜"><a href="#9-6-2-判断是否存在数据倾斜" class="headerlink" title="9.6.2 判断是否存在数据倾斜"></a>9.6.2 判断是否存在数据倾斜</h3><p>这里再通过一个案例来讲述 Flink 任务如何来判断是否存在数据倾斜，如下图所示，是 Flink Web UI Job 页面展示的任务执行计划，可以看到任务经过 Operator Chain 后，总共有两个 Task，上游 Task 将数据 keyBy 后发送到下游 Task，如何判断第二个 Task 计算的数据是否存在数据呢？</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004443.jpg" alt=""></p><p>如下图所示，通过 Flink Web UI 中 Job 页面的第一个 Subtasks 选项卡，可以看到任务的两个 Task，点击 Task，可以看到 Task 相应的 Subtask 详情。例如 Subtask 的启动时间、结束时间、持续时长、接收数据量的字节数以及接收数据的个数。图中可以看到，相同 Task 的多个 Subtask 中，有的 Subtask 接收到 1.69 TB 的数据量，有的 Subtask 接收到 17.6 TB 的数据量，通过 Flink Web UI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜，接下来学习 Flink 中如何来解决数据倾斜。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004431.jpg" alt=""></p><h3 id="9-6-3-分析和解决数据倾斜问题"><a href="#9-6-3-分析和解决数据倾斜问题" class="headerlink" title="9.6.3 分析和解决数据倾斜问题"></a>9.6.3 分析和解决数据倾斜问题</h3><p>在 Flink 中，很多因素都会导致数据倾斜，例如 9.6.1 节描述的 keyBy 后的聚合操作存在数据倾斜。keyBy 之前的数据直接来自于数据源，一般不会出现数据倾斜，除非数据源中的数据发生了数据倾斜。本小节将从多个角度来解决数据倾斜。</p><h5 id="keyBy-后的聚合操作存在数据倾斜"><a href="#keyBy-后的聚合操作存在数据倾斜" class="headerlink" title="keyBy 后的聚合操作存在数据倾斜"></a>keyBy 后的聚合操作存在数据倾斜</h5><h5 id="keyBy-之前发生数据倾斜"><a href="#keyBy-之前发生数据倾斜" class="headerlink" title="keyBy 之前发生数据倾斜"></a>keyBy 之前发生数据倾斜</h5><h3 id="9-6-4-小结与反思"><a href="#9-6-4-小结与反思" class="headerlink" title="9.6.4 小结与反思"></a>9.6.4 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>在前一章中讲解了 Flink 监控系统的重要性，这章主要讲解 Flink 作业的性能调优。当作业出现各种各样的问题时，其实这时就体现了前面章节提到的监控的重要性，所以本章的内容也比较依赖于监控系统，然后才能够更好的去排查问题，然后去解决问题。</p><p>在本章中讲解的反压问题、并行度设置问题、数据倾斜问题等都是开发作业时要注意的点，本章不仅讲解了这些问题出现后的解决方案，还深入的剖析了这些问题为啥会出现，只有知其原因后，后面开发新的作业时才会去注意这些问题。本章的内容属于高阶玩家要掌握的，希望你也能够好好理解，在你们公司遇到同样问题的时候可以站出来去解决。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-6-如何处理-Flink-中数据倾斜问题？&quot;&gt;&lt;a href=&quot;#9-6-如何处理-Flink-中数据倾斜问题？&quot; class=&quot;headerlink&quot; title=&quot;9.6 如何处理 Flink 中数据倾斜问题？&quot;&gt;&lt;/a&gt;9.6 如何处理 Flink 中数据倾斜问题？&lt;/h2&gt;&lt;p&gt;在大数据计算场景，无论使用 MapReduce、Spark 还是 Flink 计算框架，无论是批处理还是流处理都存在数据倾斜的问题，通过本节学习产生数据倾斜的原因及如何在生产环境解决数据倾斜。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 中如何保证 Exactly Once？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/11/flink-in-action-9.5/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/11/flink-in-action-9.5/</id>
    <published>2021-08-10T16:00:00.000Z</published>
    <updated>2022-01-23T12:03:10.112Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-5-Flink-中如何保证-Exactly-Once？"><a href="#9-5-Flink-中如何保证-Exactly-Once？" class="headerlink" title="9.5 Flink 中如何保证 Exactly Once？"></a>9.5 Flink 中如何保证 Exactly Once？</h2><p>在分布式场景下，我们的应用程序随时可能出现任何形式的故障，例如：机器硬件故障、程序 OOM 等。当应用程序出现故障时，Flink 为了保证数据消费的 Exactly Once，需要有相应的故障容错能力。Flink 是通过周期性 Checkpoint 的方式来实现故障容错，这里使用的是基于 Chandy-Lamport 改进的算法。本节会介绍 Flink 内部如何保证 Exactly Once 以及端对端如何保证 Exactly Once。</p><a id="more"></a><h3 id="9-5-1-Flink-内部如何保证-Exactly-Once？"><a href="#9-5-1-Flink-内部如何保证-Exactly-Once？" class="headerlink" title="9.5.1 Flink 内部如何保证 Exactly Once？"></a>9.5.1 Flink 内部如何保证 Exactly Once？</h3><p>Flink 官网的定义是 Stateful Computations over Data Streams（数据流上的有状态计算），那到底什么是状态呢？举一个无状态计算的例子，比如：我们只是进行一个字符串拼接，输入a，输出a_666,输入b，输出 b_666。无状态表示计算输出的结果跟之前的状态没关系，符合幂等性。幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生副作用。而计算 PV、UV 就属于有状态计算。实时计算 PV 时，每次都需要从某个存储介质的结果表中拿到之前的 PV 值，+1 后 set 到结果表中。有状态计算表示输出的结果跟之前的状态有关系，不符合幂等性，访问多次，PV 会增加。</p><h4 id="Flink的-Checkpoint-功能简介"><a href="#Flink的-Checkpoint-功能简介" class="headerlink" title="Flink的 Checkpoint 功能简介"></a>Flink的 Checkpoint 功能简介</h4><p>Flink Checkpoint 机制的存在就是为了解决 Flink 任务在运行过程中由于各种原因导致任务失败后，能够正常恢复任务。那 Checkpoint 具体做了哪些功能，为什么任务挂掉之后，通过 Checkpoint 机制能使得任务恢复呢？Checkpoint 是通过给程序做快照的方式使得将整个程序某些时刻的状态保存下来，当任务挂掉之后，默认从最近一次保存的完整快照处进行恢复任务。问题来了，快照是什么东西？SnapShot翻译为快照，是指将程序中某些信息存一份，后期可以用这些信息来恢复任务。对于一个 Flink 任务来讲，快照里面到底保存着什么信息呢？理论知识一般比较晦涩难懂，我们分析一个案例，用案例辅助大家理解快照里面到底存储什么信息。计算各个 app 的 PV，使用 Flink 该怎么统计呢？</p><p>可以把要统计的 app_id 做为 key，对应的 PV 值做为 value，将统计的结果放到一个 Map 集合中，这个 Map 集合可以是内存里的 HashMap 或其他 kv 数据库，例如放到Redis 的 key、value 结构中。从 Kafka 读取到一条条日志，由于要统计各 app 的 PV，所以我们需要从日志中解析出 app_id 字段，每来一条日志，只需要从 Map 集合将相应 app_id 的 PV 值拿出来，+1 后 put 到 Map 中，这样我们的 Map 中永远保存着所有 app 最新的 PV 数据。详细流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151541.jpg" alt="flink任务task图.png" style="zoom:50%;" /></p><p>图中包含三部分：第一个是 Kafka 的一个名为 test 的 Topic，我们的数据来源于这个 Topic，第二个是 Flink 的 Source Task，是 Flink 应用程序读取数据的 Task，第三个是计算 PV 的 Flink Task，用于统计各个 app 的 PV 值，并将 PV 结果输出到 Map 集合。</p><p>Flink 的 Source Task 记录了当前消费到 test Topic 所有 partition 的 offset，为了方便理解 Checkpoint 的作用，这里先用一个 partition 进行讲解，假设名为 test 的 Topic只有一个partition0。例：（0，60000）表示0号partition 目前消费到 offset 为 60000 的数据。Flink 的 PV task 记录了当前计算的各 app 的 PV 值，为了方便讲解，这里假设有两个app：app1、app2。例：（app1，50000）（app2，10000）表示 app1 当前 PV 值为50000、app2 当前 PV 值为 10000。计算过程中，每来一条数据，只需要确定相应 app_id，将相应的 PV 值 +1 后 put 到 map 中即可。</p><p>该案例中，Checkpoint 到底记录了什么信息呢？记录的其实就是第 n 次 Checkpoint 消费的 offset 信息和各app 的 PV 值信息，记录下发生 Checkpoint 当前的状态信息，并将该状态信息保存到相应的状态后端。（注：<strong>状态后端是保存状态的地方</strong>，决定状态如何保存，如何保证状态高可用，我们只需要知道，我们能从状态后端拿到 offset 信息和 PV 信息即可。状态后端必须是高可用的，否则我们的状态后端经常出现故障，会导致无法通过 Checkpoint 来恢复我们的应用程序）。下面列出了第 100 次 Checkpoint 的时候，状态后端保存的状态信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chk-100</span><br><span class="line">- offset：（0，60000）</span><br><span class="line">- PV：（app1，50000）（app2，10000）</span><br></pre></td></tr></table></figure><p>该状态信息表示第 100 次 Checkpoint 的时候， partition 0 offset 消费到了 60000，PV 统计结果为（app1，50000）（app2，10000） 。如果任务挂了，如何恢复？</p><p>假如我们设置了一分钟进行一次 Checkpoint，第 100 次 Checkpoint 成功后，过了十秒钟，offset已经消费到 （0，60100），PV 统计结果变成了（app1，50080）（app2，10020），突然任务挂了，怎么办？其实很简单，Flink 只需要从最近一次成功的 Checkpoint，也就是从第 100 次 Checkpoint 保存的 offset（0，60000）处接着消费即可，当然 PV 值也要从第 100 次 Checkpoint 里保存的 PV 值（app1，50000）（app2，10000）进行累加，不能从（app1，50080）（app2，10020）处进行累加，因为 <strong>partition 0 offset消费到 60000 时，对应的 PV 统计结果为（app1，50000）（app2，10000）</strong>。当然如果你想从offset （0，60100）PV（app1，50080）（app2，10020）这个状态恢复，也是做不到的，因为那个时刻程序突然挂了，这个状态根本没有保存下来，只有在 Checkpoint 的时候，才会把这些完整的状态保存到状态后端，供我们恢复任务。我们能做的最高效方式就是从最近一次成功的 Checkpoint 处恢复，也就是一直所说的 chk-100。以上基本就是 Checkpoint 承担的工作，为了方便理解，描述的业务场景比较简单。</p><p>补充两个问题：计算 PV 的 task 在一直运行，它怎么知道什么时候去做 Checkpoint 呢？计算 PV 的 task 怎么保证它自己计算的 PV 值（app1，50000）（app2，10000）就是offset（0，60000）那一刻的统计结果呢？Flink 在数据中加了一个叫做 barrier（栅栏） 的东西，如下图所示，用圈标注的就是 barrier。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151548.jpg" style="zoom:20%;" /></p><p>barrier 从 Source Task 处生成，一直流到 Sink Task，期间所有的 Task 只要碰到 barrier，就会触发自身进行快照。如上图所示，Checkpoint barrier n-1 处做的快照就是指 Job 从开始处理到 barrier n-1 所有的状态数据，barrier n 处做的快照就是指从 Job 开始到处理到 barrier n 所有的状态数据。对应到 PV 案例中就是，Source Task 接收到 JobManager 的编号为 chk-100 的 Checkpoint 触发请求后，发现自己恰好接收到 kafka offset（0，60000）处的数据，所以会往 offset（0，60000）数据之后 offset（0，60001）数据之前插入一个barrier，然后自己开始做快照，也就是将offset（0，60000）保存到状态后端 chk-100 中。然后，Source Task 会把 barrier 和我们要处理的数据一块往下游发送，当统计 PV 的 task 接收到 barrier 后，意味着 barrier 之前的数据已经被 PV task 处理完了，此时也会暂停处理 barrier 之后的数据，将自己内存中保存的 PV 信息（app1，50000）（app2，10000）保存到状态后端 chk-100 中。Flink 大概就是通过以上过程来保存快照的。</p><p>上述过程中，barrier 的作用就是为了把数据区分开，barrier 之前的数据是本次 Checkpoint 之前必须处理完的数据，barrier 之后的数据在本次 Checkpoint 之前不能被处理。Checkpoint 过程中有一个同步做快照的环节不能处理 barrier 之后的数据，为什么呢？如果做快照的同时，也在处理数据，那么处理的数据可能会修改快照内容，所以先暂停处理数据，把内存中快照保存好后，再处理数据。结合案例来讲就是，PV task 在对（app1，50000）（app2，10000）做快照的同时，如果 barrier 之后的数据还在处理，可能会导致状态信息还没保存到磁盘，状态已经变成了（app1，50001）（app2，10001），导致我们最后快照里保存的 PV 值变成了（app1，50001）（app2，10001），这样如果从 Checkpoint 恢复任务时，我们从 offset 60000 开始消费，PV 值从 （app1，50001）（app2，10001） 开始累加，就会造成计算的 PV 结果偏高，结果不准确，就不能保证 Exactly Once。所以，Checkpoint 同步做快照的过程中，不能处理 barrier 之后的数据。Checkpoint 将快照信息写入到磁盘后，为了保证快照信息的高可用，需要将快照上传到 HDFS，这个上传快照到 HDFS 的过程是异步进行的，这个过程也可以处理 barrier 之后的数据，处理 barrier 之后的数据不会影响到磁盘上的快照信息。</p><p>从 PV 案例再分析 Flink 是如何做 Checkpoint 并从 Checkpoint 处恢复任务的，首先 JobManager 端会向所有 SourceTask 发送 Checkpoint，Source Task 会在数据流中安插 Checkpoint barrier，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151547.jpg" alt="单并行度 PV 案例 Checkpoint 过程图示1" style="zoom:13%;" /></p><p>Source Task 安插好 barrier 后，会将 barrier 跟数据一块发送给下游，然后自身开始做快照，并将快照信息 offset (0,60000) 发送到高可用的持久化存储介质，例如 HDFS 上，发送流程如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151542.jpg" alt="单并行度 PV 案例 Checkpoint 过程图示2" style="zoom:13%;" /></p><p>下游的 PV task 接收到 barrier 后，也会做快照，并将快照信息 PV：(app1,50000) (app2,10000) 发送到 HDFS 上，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151543.jpg" style="zoom:13%;" /></p><p>假设第 100 次 Checkpoint 完成后，一段时间后任务挂了，Flink 任务会自动从状态后端恢复任务。Source Task 去读取自己需要的状态信息 offset (0,60000) ，并从 offset 为 60000 的位置接着开始消费数据，PV task 也会去读取需要的状态信息 PV：(app1,50000) (app2,10000)，并在该状态值的基础上，往上累积计算 PV 值，流程如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151544.jpg" style="zoom:13%;" /></p><h4 id="多并行度、多-Operator-情况下，Checkpoint-的过程"><a href="#多并行度、多-Operator-情况下，Checkpoint-的过程" class="headerlink" title="多并行度、多 Operator 情况下，Checkpoint 的过程"></a>多并行度、多 Operator 情况下，Checkpoint 的过程</h4><p>上一节中讲述了单并行度情况下 Checkpoint 的过程，但是生产环境中，一般都是多并行度，而且算子也会比较多，这种情况下 Checkpoint 的过程就会变得复杂。分布式状态容错面临的问题与挑战：</p><ul><li>如何确保状态拥有<strong>精确一次</strong>的容错保证？</li><li>如何在分布式场景下替多个拥有本地状态的算子产生<strong>一个全域一致的快照</strong>？</li><li>如何在<strong>不中断运算</strong>的前提下产生快照？</li></ul><p>多并行度、多 Operator 实例的情况下，如何做全域一致的快照？所有的 Operator 运行过程中接收到所有上游算子发送 barrier 后，对自身的状态进行一次快照，保存到相应状态后端，流程如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151553.jpg" style="zoom: 13%;" /></p><p>当任务从状态恢复时，每个 Operator 从状态后端读取自己相应的状态信息，数据源会从状态中保存的位置开始重新消费，后续的其他算子也会基于 Checkpoint 中保存的状态进行计算，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151556.jpg" alt="多并行度下，任务从 Checkpoint 恢复图示" style="zoom:13%;" /></p><p>整个 Checkpoint 的过程跟之前单并行度类似，图中有 4 个带状态的 Operator 实例，相应的状态后端就可以想象成 4 个格子。整个 Checkpoint 的过程可以当做 Operator 实例填自己格子的过程，Operator 实例将自身的状态写到状态后端中相应的格子，当所有的格子填满可以简单的认为一次完整的 Checkpoint 做完了。</p><p>上面只是快照的过程，Checkpoint 执行过程如下：</p><p>1、JobManager 端的 CheckPointCoordinator 向所有 Source Task 发送 CheckPointTrigger，Source Task会在数据流中安插 Checkpoint barrier</p><p>2、当 task 收到所有的 barrier 后，向自己的下游继续传递 barrier，然后自身执行快照，并将自己的状态<strong>异步写入到持久化存储</strong>中</p><ul><li>增量 CheckPoint 只是把最新的一部分数据更新写入到外部存储</li><li>为了下游尽快开始做 CheckPoint，所以会先发送 barrier 到下游，自身再同步进行快照</li></ul><p>3、当 task 对状态的快照信息完成备份后，会将备份数据的地址（state handle）通知给 JobManager 的 CheckPointCoordinator</p><p>如果 Checkpoint 的持续时长超过了 Checkpoint 设定的超时时间，CheckPointCoordinator 还没有收集完所有的 State Handle，CheckPointCoordinator就会认为本次 Checkpoint 失败，会把这次 Checkpoint 产生的所有 状态数据全部删除</p><p>4、CheckPointCoordinator 把整个 StateHandle 封装成 Completed Checkpoint Meta，写入到 HDFS，整个 Checkpoint 结束</p><h4 id="barrier-对齐"><a href="#barrier-对齐" class="headerlink" title="barrier 对齐"></a>barrier 对齐</h4><p>什么是 barrier 对齐？如图所示，当前的 Operator 实例接收上游两个流的数据，一个是字母流，一个是数字流。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151558.jpg" style="zoom:10%;" /></p><p>当 Checkpoint 时，上游字母流和数字流都会往 Operator 实例发送 Checkpoint barrier，但是由于每个算子的执行速率不同，所以不可能保证上游两个流的 barrier 同时到达 Operator 实例，那图中的 Operator 实例到底什么时候进行快照呢？接收到任意一个 barrier 就可以开始进行快照了吗，还是接收到所有的 barrier 才能开始进行快照呢？答案是：当一个 Operator 实例有多个输入流时，Operator 实例需要在做快照之前进行 barrier 对齐，等待所有输入流的 barrier 都到达。barrier 对齐的详细过程如下所示：</p><p>1、对于一个有多个输入流的 Operator 实例，当 Operator 实例从其中一个输入流接收到 Checkpoint barrier n 时，就不能处理来自该流的任何数据记录了，直到它从其他所有输入流接收到 barrier n为止，否则 <strong>Operator 实例 Checkpoint n 的快照会混入快照 n 的记录和快照 n + 1 的记录</strong>。如上图中第 1 个小图所示，数字流的 barrier 先到达了。</p><p>2、接收到 barrier n 的流暂时被搁置，从这些流接收的记录不会被处理，而是放入输入缓冲区。图 2 中，我们可以看到虽然数字流对应的 barrier 已经到达了，但是barrier之后的 1、2、3 这些数据只能放到缓冲区中，等待字母流的barrier到达。</p><p>3、一旦最后所有输入流都接收到 barrier n，Operator 实例就会把 barrier 之前所有已经处理完成的数据和 barrier n 一块发送给下游。然后 Operator 实例就可以对状态信息进行快照。如图 3 所示，Operator 实例接收到上游所有流的 barrier n，此时 Operator 实例就可以将 barrier 和 barrier 之前的数据发送到下游，然后自身状态进行快照。</p><p>4、快照做完后，Operator 实例将继续处理缓冲区的记录，然后就可以处理输入流的数据。如图 4 所示，先处理完缓冲区数据，就可以正常处理输入流的数据了。</p><p>上面的过程就是 Flink 在 Operator 实例有多个输入流的情况下，整个 barrier 对齐的过程。那什么是 barrier 不对齐呢？barrier 不对齐是指当还有其他流的 barrier 还没到达时，为了提高 Operator 实例的处理性能，Operator 实例会直接处理 barrier 之后的数据，等到所有流的 barrier 都到达后，就可以对该 Operator 做 Checkpoint 快照了。对应到图中就是，barrier 不对齐时会直接把 barrier 之后的数据 1、2、3 直接处理掉，而<strong>不是</strong>放到缓冲区中等待其他的输入流的 barrier 到达，当所有输入流的 barrier 都到达后，才开始对 Operator 实例的状态信息进行快照，这样会导致做快照之前，Operator 实例已经处理了一些 barrier n 之后的数据。Checkpoint 的目的是为了保存快照信息，如果 barrier 不对齐，那么 Operator 实例在做第 n 次 Checkpoint 之前，已经处理了一些 barrier n 之后的数据，当程序从第 n 次 Checkpoint 恢复任务时，程序会从第 n 次 Checkpoint 保存的 offset 位置开始消费数据，就会导致一些数据被处理了两次，就出现了重复消费。如果进行 barrier 对齐，就不会出现这种重复消费的问题，所以 <strong>barrier 对齐就可以实现 Exactly Once，barrier 不对齐就变成了At Least Once。</strong></p><p>再结合计算 PV 的案例来证明一下，为什么 barrier 对齐就可以实现 Exactly Once，barrier 不对齐就变成了 At Least Once。之前的案例为了简单，描述的 kafka topic 只有 1 个 partition，这里为了讲述 barrier 对齐，假设 topic 有 2 个 partittion，且计算的是我们平台的总 PV，也就是说不需要区分 app，每条一条数据，我们都需要将其 PV 值 +1 即可。如下图所示，Flink 应用程序有两个 Source Task，一个计算 PV 的 Task，这里计算 PV 的 Task 就出现了存在多个输入流的情况。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151546.jpg" style="zoom:13%;" /></p><p>假设 barrier 不对齐，那么 Checkpoint 过程是怎么样呢？如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151554.jpg" style="zoom:12%;" /></p><p>如上图左部分所示，Source Subtask 0 和 Subtask 1 已经完成了快照操作，他们的状态信息为 offset(0,10000)(1,10005) 表示 partition0 消费到 offset 为 10000 的位置，partition 1 消费到 offset 为 10005 的位置。当 Source Subtask 1 的 barrier 到达 PV task 时，计算的 PV 结果为 20002，但 PV task 还没有接收到 Source Subtask 0 发送的 barrier，所以 PV task 还不能对自身状态信息进行快照。由于设置的 barrier 不对齐，所以此时 PV task 会继续处理 Source Subtask 0 和 Source Subtask 1 传来的数据。很快，如上图右部分所示，PV task 接收到 Source Subtask 0 发来的 barrier，但是 PV task 已经处理了 Source Subtask 1 barrier 之后的三条数据，所以 PV 值目前已经为 20008了，这里的 PV=20008 实际上已经处理到 partition 1 offset 为 10008 的位置，此时 PV task 会对自身的状态信息（PV = 20008）做快照，整体的快照信息为 offset(0,10000)(1,10005)  PV=20008。</p><p>接着程序在继续运行，过了 10 秒，由于某个服务器故障，导致我们的 Operator 实例有一个挂了，所以 Flink 会从最近一次 Checkpoint 保存的状态恢复。那具体是怎么恢复的呢？Flink 同样会起三个 Operator 实例，我还称他们是 Source Subtask 0 、Source Subtask 1 和 PV task。三个 Operator 会从状态后端读取保存的状态信息。Source Subtask 0 会从 partition 0 offset 为 10000 的位置开始消费，Source Subtask 1 会从 partition 1 offset 为 10005 的位置开始消费，PV task 会基于 PV=20008 进行累加统计。然后就会发现的 PV 值 20008 实际上已经包含了 partition 1 的 offset 10005~10008 的数据，所以 partition 1 从 offset 10005 恢复任务时，partition1 的 offset 10005~10008 的数据被消费了两次，出现了重复消费的问题，所以 barrier 不对齐只能保证 At Least Once。</p><p>如果设置为 barrier 对齐，这里能保证 Exactly Once 吗？如下图所示，当 PV task 接收到 Source Subtask 1 的 barrier 后，并不会处理 Source Subtask 1 barrier 之后的数据，而是把这些数据放到 PV task 的输入缓冲区中，直到等到 Source Subtask 0 的 barrier 到达后，PV task 才会对自身状态信息进行快照，此时 PV task 会把 PV=20005 保存到快照信息中，整体的快照状态信息为 offset(0,10000)(1,10005)  PV=20005，当任务从 Checkpoint 恢复时，Source Subtask 0 会从 partition 0 offset 为 10000 的位置开始消费，Source Subtask 1 会从 partition 1 offset 为 10005 的位置开始消费，PV task 会基于 PV=20005 进行累加统计，所以 barrier 对齐能保证 Flink 内部的 Exactly Once。在 Flink 应用程序中，当 Checkpoint 语义设置 Exactly Once 或 At Least Once 时，唯一的区别就是 barrier 对不对齐。当设置为 Exactly Once 时，就会 barrier 对齐，当设置为 At Least Once 时，就会 barrier 不对齐。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151555.jpg" style="zoom:12%;" /></p><p>通过本案例，我们应该发现了 barrier 在 Flink 的 Checkpoint 中起着非常大的作用。barrier 告诉 Flink 应用程序，Checkpoint 之前哪些数据不应该被处理，barrier 对齐的过程其实就是为了防止 Flink 应用程序处理重复的数据。总结一下，满足哪些条件时，会出现 barrier 对齐？在代码中设置了 Flink 的 Checkpoint 语义是 Exactly Once，其次 Operator 实例必须有多个输入流才会出现 barrier 对齐。对齐，汉语词汇，释义为使两个以上事物配合或接触得整齐。由汉语解释可得对齐肯定需要两个以上事物，所以必须有多个输入流才可能存在对齐。barrier 对齐就是上游多个流配合使得数据对齐的过程。言外之意：如果 Operator 实例只有一个输入流，就根本不存在 barrier 对齐，自己跟自己默认永远都是对齐的，所以当我们的应用程序从 Source 到 Sink 所有算子的并行度都是 1 的话，就算设置的 At Least Once，无形中也实现了 barrier 对齐，此时 Checkpoint 设置成 Exactly Once 和 At Least Once 一点区别都没有，都可以保证 Exactly Once。看到这里你应该已经知道了哪种情况会出现重复消费了，也应该要掌握为什么 barrier 对齐就能保证 Exactly Once，为什么 barrier 不对齐就是 At Least Once。</p><p>barrier 对齐其实是要付出代价的，从 barrier 对齐的过程可以看出，PV task 明明可以更高效的处理数据，但因为 barrier 对齐，导致 Source Subtask 1 barrier 之后的数据被放到缓冲区中，暂时性地没有被处理，假如生产环境中，Source Subtask 0 的 barrier 迟迟没有到达，比 Source Subtask 1 延迟了 30 秒，那么这 30 秒期间，Source Subtask 1 barrier 之后的数据不能被处理，所以 PV task 相当于被闲置了。所以，当我们的一些业务场景对 Exactly Once 要求不高时，我们可以设置 Flink 的 Checkpoint 语义是 At Least Once 来小幅度的提高应用程序的执行效率。Flink Web UI 的 Checkpoint 选项卡中可以看到 barrier 对齐的耗时，如果发现耗时比较长，且对 Exactly Once 语义要求不高时，可以考虑使用该优化方案。</p><p>前面提到如何在不中断运算的前提下产生快照？在 Flink 的 Checkpoint 过程中，无论下游算子有没有做完快照，只要上游算子将 barrier 发送到下游且上游算子自身已经做完快照时，那么上游算子就可以处理 barrier 之后的数据了，从而使得整个系统 Checkpoint 的过程影响面尽量缩到最小，来提升系统整体的吞吐量。</p><p>在整个 Checkpoint 的过程中，还存在一个问题，假设我们设置的 10 分钟一次 Checkpoint。在第 n 次 Checkpoint 成功后，过了 9 分钟，任务突然挂了，我们需要从最近一次成功的 Checkpoint 处恢复任务，也就是从 9 分钟之前的状态恢复任务，就需要把这 9分钟的数据全部再消费一次，成本比较大。有的同学可能会想，那可以不可以设置为 100 ms就做一次 Checkpoint 呢？这样的话，当任务出现故障时，就不需要从 9 分钟前的状态进行恢复了，直接从 100 ms之前的状态恢复即可，恢复就会很快，不需要处理大量重复数据了。但是，这样做会导致应用程序频繁的访问状态后端，一般我们为了高可用，会把状态里的数据比如 offset：（0，60000）PV：（app1，50000）（app2，10000） 信息保存到 HDFS 中，如果频繁访问 HDFS，肯定会造成吞吐量下降，所以一般我们的 Checkpoint 时间间隔可以设置为分钟级别，例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，我们甚至可以设置为 5 分钟一次 Checkpoint，毕竟我们的应用程序挂的概率并不高，偶尔一次从 5 分钟前的状态恢复，我们是可以接受的。可以根据业务场景合理地调节 Checkpoint 的间隔时长，对于状态很小的 Job Checkpoint 会很快，我们可以调小时间间隔，对于状态比较大的 Job Checkpoint 会比较慢，我们可以调大 Checkpoint 时间间隔。</p><p>有的同学可能还有疑问，明明说好的 Exactly Once，但在 Checkpoint 成功后 10s 发生了故障，从最近一次成功的 Checkpoint 处恢复时，由于发生故障前的 10s Flink 也在处理数据，所以 Flink 应用程序肯定是把一些数据重复处理了呀。在面对任意故障时，不可能保证每个算子中用户定义的逻辑在每个事件中只执行一次，因为用户代码被部分执行的可能性是永远存在的。那么，当引擎声明 Exactly Once 处理语义时，它们能保证什么呢？如果不能保证用户逻辑只执行一次，那么哪些逻辑只执行一次？当引擎声明 Exactly Once 处理语义时，它们实际上是在说，它们可以保证引擎管理的状态更新只提交一次到持久的后端存储。换言之，无论以什么维度计算 PV、无论 Flink 应用程序发生多少次故障导致重启从 Checkpoint 恢复，Flink 都可以保证 PV 结果是准确的，不会因为各种任务重启而导致 PV 值计算偏高。</p><p>为了下游尽快做 Checkpoint，所以会先发送 barrier 到下游，自身再同步进行快照。这一步，如果向下发送barrier后，自己同步快照慢怎么办？下游已经同步好了，自己还没？可能会出现下游比上游快照还早的情况，但是这不影响快照结果，只是下游做快照更及时了，我只要保证下游把barrier之前的数据都处理了，并且不处理 barrier 之后的数据，然后做快照，那么下游也同样支持 Exactly Once。这个问题不要从全局思考，单独思考上游和下游的实例，你会发现上下游的状态都是准确的，既没有丢，也没有重复计算。这里需要注意，如果有一个Operator 的 Checkpoint 失败了或者因为 Checkpoint 超时也会导致失败，那么 JobManager 会认为整个 Checkpoint 失败。失败的 Checkpoint 是不能用来恢复任务的，必须所有的算子的 Checkpoint 都成功，那么这次 Checkpoint 才能认为是成功的，才能用来恢复任务。对应到 PV 案例就是，PV task 做快照速度较快，PV=20005 较早地写入到了 HDFS，但是 offset(0,10000)(1,10005) 过了几秒才写入到 HDFS，这种情况就算出现了，也不会影响计算结果，因为我们的快照信息是完全正确的。</p><p>再分享一个案例，Flink 的 Checkpoint 语义设置了 Exactly Once，程序中设置了 1 分钟 1 次 Checkpoint，5 秒向 MySQL 写一次数据，并commit。最后发现 MySQL 中数据重复了。为什么会重复呢？Flink要求端对端的 Exactly Once 都必须实现 TwoPhaseCommitSinkFunction。如果你的 Checkpoint 成功了，过了30秒突然程序挂了，由于 5 秒 commit 一次，所以在应用程序挂之前的 30 秒实际上已经写入了 6 批数据进入 MySQL。从 Checkpoint 处恢复时，之前提交的 6 批数据就会重复写入，所以出现了重复消费。Flink 的 Exactly Once 有两种情况，一个是我们本节所讲的 Flink 内部的 Exactly Once，一个是端对端的 Exactly Once。关于端对端如何保证 Exactly Once，我们在下一节中深入分析。</p><h3 id="9-5-2-端对端如何保证-Exactly-Once？"><a href="#9-5-2-端对端如何保证-Exactly-Once？" class="headerlink" title="9.5.2 端对端如何保证 Exactly Once？"></a>9.5.2 端对端如何保证 Exactly Once？</h3><p>Flink 与外部存储介质之间进行数据交互统称为端对端或 end to end 数据传输。上一节讲述了 Flink 内部如何保证 Exactly Once，这一节来分析端对端的 Exactly Once。正如上述 Flink 写 MySQL 的案例所示，在第 n 次 Checkpoint 结束后，第 n+1 次 Checkpoint 之前，如果 Flink 应用程序已经向外部的存储介质中成功写入并提交了一些数据后，Flink 应用程序由于某些原因挂了，导致任务从第 n 次 Checkpoint 处恢复。这种情况下，就会导致第 n 次 Checkpoint 结束后且任务失败之前往外部存储介质中写入的那一部分数据重复写入两次，可能会导致相同的数据在存储介质中存储了两份，从而端对端的一致性语义保证从 Exactly Once 退化为 At Least Once。这里只考虑了数据重复的情况，为什么不考虑丢数据的情况呢？在写数据时可以对异常进行捕获增加重试策略，如果重试多次还没有成功可以让 Flink 任务失败，Flink 任务就会从最近一次成功的 Checkpoint 处恢复，就不会出现丢数据的情况，所以我们本节内容主要用来解决数据重复的问题。</p><p>针对上述端对端 Exactly Once 的问题，我们可以使用以下方案来解决：</p><p>1、假如我们使用的存储介质支持按照全局主键去重，那么比较容易实现 Exactly Once，无论相同的数据往外部存储中写入了几次，外部存储都会进行去重，只保留一条数据。例如，app1 的 PV 值为 10，现在把 （key=app1，value=10） 往 Redis 中写入 10 次，只是说把 value 值覆盖了 10次，并不会导致结果错误，这种方案属于幂等性写入。</p><p>2、我们上述案例中为什么会导致重复写入数据到外部存储呢？是因为在下一次 Checkpoint 之前如果任务失败时，一些数据已经成功写入到了外部存储中，没办法删除那些数据。既然问题是这样，那可以想办法把 “向外部存储中提交数据” 与 “Checkpoint” 强关联，两次 Checkpoint 之间不允许向外部存储介质中提交数据，Checkpoint 的时候再向外部存储提交。如果提交成功，则 Checkpoint 成功，提交失败，则 Checkpoint 也失败。这样在下一次 Checkpoint 之前，如果任务失败，也没有重复数据被提交到外部存储。这里只是描述一下大概思想，好多细节这里并没有详细描述，会在下文中详细描述。基于上述思想，Flink 实现了 TwoPhaseCommitSinkFunction，它提取了两阶段提交协议的通用逻辑，使得通过 Flink 来构建端到端的Exactly Once 程序成为可能。它提供了一个抽象层，用户只需要实现少数方法就能实现端到端的 Exactly Once 语义。不过这种方案必须要求我们的输出端 (Sink 端) 必须支持事务。</p><p>下面我们通过两部分来详细介绍上述两种方案。</p><h4 id="幂等性写入如何保证端对端的-Exactly-Once"><a href="#幂等性写入如何保证端对端的-Exactly-Once" class="headerlink" title="幂等性写入如何保证端对端的 Exactly Once"></a>幂等性写入如何保证端对端的 Exactly Once</h4><p>实时 ETL 当 HBase 做为 Sink 端时，就是典型的应用场景。把日志中的主键做为 HBase 的 RowKey，就可以保证数据不重复，实现比较简单，这里不多赘述。</p><p>继续探讨实时计算各 app PV 的案例，将统计结果以普通键值对的形式保存到 Redis 中供业务方查询。到底如何实现，才能保证 Redis 中的结果是精准的呢？在之前 Strom 或 Spark Streaming 的方案中，将统计的 PV 结果保存在 Redis 中，每来一条数据，从 Redis 中获取相应 app 对应的 PV 值然后内存中进行 +1 后，再将 PV 值 put 到 Redis 中。例如：Redis 中保存 app1 的 PV 为 10，现在来了一条 app1 的日志，首先从 Redis 中获取 app1 的 PV 值=10，内存中 10+1=11，将 (app1,11) put 到 Redis 中，这里的 11 就是我们统计的 app1 的 PV 结果。可以将这种方案优化为 incr 或 incrby，直接对 Redis 中的 10 进行累加，不需要手动在内存中进行累加操作。当然 Flink 也可以用上述的这种方案来统计各 app 的 PV，但是上述方案并不能保证 Exactly Once，为什么呢？当第 n 次 Checkpoint 时，app1 的 PV 结果为 10000，第 n 次 Checkpoint 结束后运行了 10 秒，Redis 中 app1 的 PV 结果已经累加到了 10200。此时如果任务挂了，从第 n 次 Checkpoint 恢复任务时，会继续按照 Redis 中保存的 PV=10200 进行累加，但是正确的结果应该是从 PV=10000 开始累加。如果按照上面的方案统计 PV，就可能会出现统计值偏高的情况。这里也证实了一点：并不是说 Flink 程序的 Checkpoint 语义设置为 Exactly Once，就能保证我们的统计结果或者各种输出结果都能满足 Exactly Once。为了编写真正满足 Exactly Once 的代码，我们需要对 Flink 的 Checkpoint 原理做一些了解，编写对 Exactly Once 友好的代码。</p><p>那如何编写代码才能使得最后在 Redis 中保存的 PV 结果满足 Exactly Once 呢？上一节中，讲述了 Flink 内部状态可以保证 Exactly Once，这里可以将统计的 PV 结果保存在 Flink 内部的状态里，每次基于状态进行累加操作，并将累加到的结果 put 到 Redis 中，这样当任务从 Checkpoint 处恢复时，并不是基于 Redis 中实时统计的 PV 值进行累加，而是基于 Checkpoint 中保存的 PV 值进行累加，Checkpoint 中会保存每次 Checkpoint 时对应的 PV 快照信息，例如：第 n 次 Checkpoint 会把当时 pv=10000 保存到快照信息里，同时状态后端还保存着一份实时的状态信息用于实时累加。示例代码如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// 1 分钟一次Checkpoint</span></span><br><span class="line">env.enableCheckpointing(TimeUnit.MINUTES.toMillis(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">CheckpointConfig checkpointConf = env.getCheckpointConfig();</span><br><span class="line"><span class="comment">// Checkpoint 语义 EXACTLY ONCE</span></span><br><span class="line">checkpointConf.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line">checkpointConf.enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);</span><br><span class="line"></span><br><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"localhost:9092"</span>);</span><br><span class="line">props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"app-pv-stat"</span>);</span><br><span class="line"></span><br><span class="line">DataStreamSource&lt;String&gt; appInfoSource = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">        <span class="comment">// kafka topic， String 序列化</span></span><br><span class="line">        <span class="string">"app-topic"</span>,  <span class="keyword">new</span> SimpleStringSchema(), props));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 按照 appId 进行 keyBy</span></span><br><span class="line">appInfoSource.keyBy((KeySelector&lt;String, String&gt;) appId -&gt; appId)</span><br><span class="line">        .map(<span class="keyword">new</span> RichMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">            <span class="keyword">private</span> ValueState&lt;Long&gt; pvState;</span><br><span class="line">            <span class="keyword">private</span> <span class="keyword">long</span> pv = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">super</span>.open(parameters);</span><br><span class="line">                <span class="comment">// 初始化状态</span></span><br><span class="line">                pvState = getRuntimeContext().getState(</span><br><span class="line">                        <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">"pvStat"</span>,</span><br><span class="line">                        TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Long&gt;() &#123;&#125;)));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Long&gt; <span class="title">map</span><span class="params">(String appId)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">// 从状态中获取该 app 的 PV 值，+1后，update 到状态中</span></span><br><span class="line">                <span class="keyword">if</span>(<span class="keyword">null</span> == pvState.value())&#123;</span><br><span class="line">                    pv = <span class="number">1</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    pv = pvState.value();</span><br><span class="line">                    pv += <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                pvState.update(pv);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(appId, pv);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        .print();</span><br><span class="line"></span><br><span class="line">env.execute(<span class="string">"Flink PV stat"</span>);</span><br></pre></td></tr></table></figure><p>代码中设置 1 分钟一次 Checkpoint，Checkpoint 语义 EXACTLY ONCE，从 Kafka 中读取数据，这里为了简化代码，所以 Kafka 中读取的直接就是 String 类型的 appId，按照 appId KeyBy 后，执行 RichMapFunction，RichMapFunction 的 open 方法中会初始化 ValueState<Long> 类型的 pvState，pvState 就是上文一直强调的状态信息，每次 Checkpoint 的时候，会把 pvState 的状态信息快照一份到 HDFS 来提供恢复。这里按照 appId 进行 keyBy，所以每一个 appId 都会对应一个 pvState，pvState 里存储着该 appId 对应的 pv 值。每来一条数据都会执行一次 map 方法，当这条数据对应的 appId 是新 app 时，pvState 里就没有存储这个 appId 当前的 pv 值，将 pv 值赋值为 1，当 pvState 里存储的 value 不为 null 时，拿出 pv 值 +1后 update 到 pvState 里。map 方法再将 appId 和 pv 值发送到下游算子，下游直接调用了 print 进行输出，这里完全可以替换成相应的 RedisSink 或 HBaseSink。本案例中计算 pv 的工作交给了 Flink 内部的 ValueState，不依赖外部存储介质进行累加，外部介质承担的角色仅仅是提供数据给业务方查询，所以无论下游使用什么形式的 Sink，只要 Sink 端能够按照主键去重，该统计方案就可以保证 Exactly Once。本案例使用的 ValueState，关于 State 的详细使用请参阅第3.1节。</p><h4 id="TwoPhaseCommitSinkFunction-如何保证端对端的-Exactly-Once"><a href="#TwoPhaseCommitSinkFunction-如何保证端对端的-Exactly-Once" class="headerlink" title="TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once"></a>TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once</h4><p>Flink 的源码中有这么一段注释：This is a recommended base class for all of the {@link SinkFunction} that intend to implement exactly-once semantic。意思是对于打算实现 Exactly Once 语义的所有 SinkFunction 都推荐继承该抽象类。在介绍 TwoPhaseCommitSinkFunction 之前，先了解一下 2PC 分布式一致性协议。</p><p>在分布式系统中，每一个机器节点虽然都能明确地知道自己在进行事务操作过程中的结果是成功或失败，但无法直接获取到其他分布式节点的操作结果。因此，当一个事务操作需要跨越多个分布式节点的时候，为了让每个节点都能够获取到其他节点的事务执行状况，需要引入一个”协调者（Coordinator）”节点来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点被称为”参与者（Participant）”。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务真正的提交。<br>普通的事务可以保证单个事务内所有操作要么全部成功，要么全部失败，而分布式系统中具体如何保证多台节点上执行的事务要么所有节点事务都成功，要么所有节点事务都失败呢？先了解一下 2PC 一致性协议。</p><p>2PC 是 Two-Phase Commit 的缩写，即两阶段提交。2PC 将分布式事务分为了两个阶段，分别是提交事务请求（投票）和执行事务提交。协调者会根据参与者在第一阶段的投票结果，来决定第二阶段是否真正的执行事务，具体流程如下。</p><h5 id="提交事务请求（投票）阶段"><a href="#提交事务请求（投票）阶段" class="headerlink" title="提交事务请求（投票）阶段"></a>提交事务请求（投票）阶段</h5><p>提交事务请求阶段如下所示：</p><ul><li>协调者向所有参与者发送 prepare 请求与事务内容，询问是否可以准备事务提交，并等待参与者的响应</li><li>各参与者执行事务操作，并记录 Undo日志（用于回滚）和 Redo日志（用于重放），但不真正提交</li><li>参与者向协调者返回事务操作的执行结果，执行成功返回 Yes，否则返回 No</li></ul><h5 id="执行事务提交阶段"><a href="#执行事务提交阶段" class="headerlink" title="执行事务提交阶段"></a>执行事务提交阶段</h5><p>分为成功与失败两种情况：</p><ul><li>若第一阶段所有参与者都返回 Yes，说明事务可以提交<ul><li>协调者向所有参与者发送 Commit 请求</li><li>参与者收到 Commit 请求后，会正式执行事务提交操作，并在提交完成后释放事务资源</li><li>完成事务提交后，向协调者发送 Ack 消息</li><li>协调者收到所有参与者的 Ack 消息，完成事务</li></ul></li></ul><p>事务提交成功的流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151552.jpg" style="zoom:12%;" /></p><ul><li>若第一阶段有参与者返回 No 或者超时未返回，说明事务中断，需要回滚<ul><li>协调者向所有参与者发送 Rollback 请求</li><li>参与者收到 Rollback 请求后，根据 Undo日志回滚到事务执行前的状态，释放占用的事务资源</li><li>参与者在完成事务回滚后，向协调者返回 Ack</li><li>协调者收到所有参与者的 Ack 消息，事务回滚完成</li></ul></li></ul><p>事务提交中断，需要回滚的流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151557.jpg" style="zoom:12%;" /></p><p>简单来讲，2PC 将一个事务的处理过程分为了投票和执行两个阶段，其核心是每个事务都采用先尝试后提交的处理方式。2PC 的优缺点如下所示：</p><p>优点：原理简单，实现方便</p><p>缺点：</p><ul><li>协调者单点问题：协调者在整个 2PC 协议中非常重要，一旦协调者故障，则 2PC 将无法运转</li><li>过于保守：在 2PC 的阶段一，如果参与者出现故障而导致协调者无法获取到参与者的响应信息，这时协调者只能依靠自身的超时机制来判断是否需要中断事务，这种策略比较保守。换言之，2PC 没有涉及较为完善的容错机制，任意一个节点失败都会导致整个事务的失败</li><li>同步阻塞：执行过程是完全同步的，各个参与者在等待其他参与者投票响应的的过程中，将无法进行其他任何操作</li><li>数据不一致：在二阶段提交协议的阶段二，当协调者向所有的参与者发送 Commit 请求后，出现了局部网络异常或局部参与者机器故障等因素导致一部分的参与者执行了 Commit 操作，而发生故障的参与者没有执行 Commit，于是整个分布式系统便出现了数据不一致现象</li></ul><p>Flink 的 TwoPhaseCommitSinkFunction 是基于 2PC 实现的。Flink 的 JobManager 对应到 2PC 中的协调者，Operator 实例对应到 2PC 中的参与者。TwoPhaseCommitSinkFunction 实现了 CheckpointedFunction 和 CheckpointListener 接口。CheckpointedFunction 接口中有两个方法 snapshotState 和 initializeState，snapshotState 方法会在 Checkpoint 时且做快照之前被调用，initializeState 方法会在自定义 Function 初始化恢复状态时被调用。CheckpointListener 接口中有一个 notifyCheckpointComplete 方法，Operator 实例的 Checkpoint 成功后，会反馈给 JobManager，当 JobManager 接收到所有 Operator 实例 Checkpoint 成功的通知后，就认为本次 Checkpoint 成功了，会给所有 Operator 实例发送一个 Checkpoint 完成的通知，Operator 实例接收到通知后，就会调用 notifyCheckpointComplete 方法。</p><p>TwoPhaseCommitSinkFunction定义了如下 5 个抽象方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 处理每一条数据</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(TXN transaction, IN value, Context context)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 开始一个事务，返回事务信息的句柄</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> TXN <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 预提交（即提交请求）阶段的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">preCommit</span><span class="params">(TXN transaction)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 正式提交阶段的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">(TXN transaction)</span></span>;</span><br><span class="line"><span class="comment">// 取消事务,Rollback 相关的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">abort</span><span class="params">(TXN transaction)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="9-5-3-分析-FlinkKafkaConsumer-的设计思想"><a href="#9-5-3-分析-FlinkKafkaConsumer-的设计思想" class="headerlink" title="9.5.3 分析 FlinkKafkaConsumer 的设计思想"></a>9.5.3 分析 FlinkKafkaConsumer 的设计思想</h3><h4 id="kafka-offset-存储及如何实现-Consumer-实例消费-partition-的负载均衡"><a href="#kafka-offset-存储及如何实现-Consumer-实例消费-partition-的负载均衡" class="headerlink" title="kafka offset 存储及如何实现 Consumer 实例消费 partition 的负载均衡"></a>kafka offset 存储及如何实现 Consumer 实例消费 partition 的负载均衡</h4><h4 id="Source-端并行度改变了，如何来恢复-offset"><a href="#Source-端并行度改变了，如何来恢复-offset" class="headerlink" title="Source 端并行度改变了，如何来恢复 offset"></a>Source 端并行度改变了，如何来恢复 offset</h4><h4 id="如何实现自动发现当前消费-topic-下新增的-partition"><a href="#如何实现自动发现当前消费-topic-下新增的-partition" class="headerlink" title="如何实现自动发现当前消费 topic 下新增的 partition"></a>如何实现自动发现当前消费 topic 下新增的 partition</h4><h3 id="9-5-4-小结与反思"><a href="#9-5-4-小结与反思" class="headerlink" title="9.5.4 小结与反思"></a>9.5.4 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-5-Flink-中如何保证-Exactly-Once？&quot;&gt;&lt;a href=&quot;#9-5-Flink-中如何保证-Exactly-Once？&quot; class=&quot;headerlink&quot; title=&quot;9.5 Flink 中如何保证 Exactly Once？&quot;&gt;&lt;/a&gt;9.5 Flink 中如何保证 Exactly Once？&lt;/h2&gt;&lt;p&gt;在分布式场景下，我们的应用程序随时可能出现任何形式的故障，例如：机器硬件故障、程序 OOM 等。当应用程序出现故障时，Flink 为了保证数据消费的 Exactly Once，需要有相应的故障容错能力。Flink 是通过周期性 Checkpoint 的方式来实现故障容错，这里使用的是基于 Chandy-Lamport 改进的算法。本节会介绍 Flink 内部如何保证 Exactly Once 以及端对端如何保证 Exactly Once。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何合理的设置 Flink 作业并行度？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/10/flink-in-action-9.4/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/10/flink-in-action-9.4/</id>
    <published>2021-08-09T16:00:00.000Z</published>
    <updated>2022-01-23T12:03:10.122Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-4-如何合理的设置-Flink-作业并行度？"><a href="#9-4-如何合理的设置-Flink-作业并行度？" class="headerlink" title="9.4 如何合理的设置 Flink 作业并行度？"></a>9.4 如何合理的设置 Flink 作业并行度？</h2><p>在 9.2 节中讲解了 Flink Job 中的执行计划，并详细分析了 Flink 中的 operator chain 在一起的各种条件，在 9.3 节中也通过真实生产环境的案例来分享并行度与 Slot 的概念与关系。相信大家也都有一定的理解，但是有时候生产环境如果 Job 突然消费不及时了，或者 Job 就根本不在消费数据了，那么该怎么办？首先得看下相关的监控查看 Job 是否在正常运行，是否出现反压的情况，是否这会生产数据量过大然而并行度却是根据之前数据量设置的，种种原因都需要一个个排查一下，然后找到根因才能够对应的去解决。这节来讲解下遇到这种问题后如何合理配置并行度呢？</p><a id="more"></a><h3 id="9-4-1-Source-端并行度的配置"><a href="#9-4-1-Source-端并行度的配置" class="headerlink" title="9.4.1 Source 端并行度的配置"></a>9.4.1 Source 端并行度的配置</h3><p>假设数据源端是 Kafka，在出现作业消费不及时的时候，首先看下 Kafka 的监控是不是现在生产者生产的数据上涨速度较快，从而导致作业目前的消费速度就是跟不上 Kafka 生产者的生产速度，如果是这样的话，那么就得查看作业的并行度和 Kafka 的分区数是否一致，如果小于 Kafka 的分区数，那么可以增大并行度至 Kafka 的分区数，然后再观察作业消费速度是否可以跟上数据生产速度；如果已经等于 Kafka 的分区数了，那得考虑下是否 Kafka 要扩大分区，但是这样可能会带来 Kafka 其他的问题，这个操作需要谨慎。</p><p>Kafka 中数据出现堆积的话，还可以分析下数据的类型，如果数据不重要，但是又要保证数据的及时性，可以修改作业让作业始终从最新的数据开始消费，丢弃之前堆积的数据，这样就可以保证数据的及时性。举个例子，假如一个实时告警作业它突然消费不及时，Kafka 中堆积了几亿条数据（数据延迟几个小时），那么如果作业调高并行度重启后，它还是从上一次提交的 offset 处开始消费的话，这样告警作业即使现在消费速度跟的上了，但是它要处理掉之前堆积的几亿条数据也是要一段时间的，那么就意味着这个作业仍将有段时间处于 ‘不可用’。因为即使判断出来要告警，可能这个告警信息的原数据已经是几个小时前的了，没准这个告警此时已经恢复了，但是还发出来告警这就意味着延迟性比较大，还会对告警消息接收者造成一定的干扰，所以这种场景下建议重启作业就直接开始从最新的数据开始消费。当然不同的场景可能不一样，如果金融行业的交易数据，那么是肯定不能允许这样丢数据的，即使堆积了，也要慢慢的去消费堆积的数据，直到后面追平至最新的数据。</p><p>在 Source 端设置并行度的话，如果数据源是 Kafka 的话，建议并行度不要超过 Kafka 的分区数，因为一个并行度会去处理一至多个分区的数据，如果设置过多的话，会出现部分并行度空闲。如果是其他的数据源，可以根据实际情况合理增大并行度来提高作业的处理数据能力。</p><h3 id="9-4-2-中间-Operator-并行度的配置"><a href="#9-4-2-中间-Operator-并行度的配置" class="headerlink" title="9.4.2 中间 Operator 并行度的配置"></a>9.4.2 中间 Operator 并行度的配置</h3><p>数据从 Source 端流入后，通常会进行一定的数据转换、聚合才能够满足需求，在数据转换中可能会和第三方系统进行交互，在交互的过程中可能会因为网络原因或者第三方服务原因导致有一定的延迟，从而导致这个数据交互的算子处理数据的吞吐量会降低，可能会造成反压，从而会影响上游的算子的消费。那么在这种情况下这些与第三方系统有交互的算子得稍微提高并行度，防止出现这种反压问题（当然反压问题不一定就这样可以解决，具体如何处理参见 9.1 节）。</p><p>除了这种与第三方服务做交互的外，另外可能的性能瓶颈也会出现在这类算子中，比如你 Kafka 过来的数据是 JSON 串的 String，然后需要转换成对象，在大数据量的情况下这个转换也是比较耗费性能的。</p><p>所以数据转换中间过程的算子也是非常重要的，如果哪一步算子的并行度设置的不合理，可能就会造成各种各样的问题出现。</p><h3 id="9-4-3-Sink-端并行度的配置"><a href="#9-4-3-Sink-端并行度的配置" class="headerlink" title="9.4.3 Sink 端并行度的配置"></a>9.4.3 Sink 端并行度的配置</h3><p>Sink 端是数据流向下游的地方，可以根据 Sink 端的数据量进行评估，可能有的作业是 Source 端的数据量最大，然后数据量不断的变少，最后到 Sink 端的数据就一点点了，比较常见的就是监控告警的场景。Source 端的数据是海量的，但是通过逐层的过滤和转换，到最后判断要告警的数据其实已经减少很多很多了，那么在最后的这个地方就可以将并行度设置的小一些。</p><p>当然也可能会有这样的情况，在 Source 端的数据量是最小的，拿到 Source 端流过来的数据后做了细粒度的拆分，那么数据量就不断的增加了，到 Sink 端的数据量就非常非常的大了。那么在 Sink 到下游的存储中间件的时候就需要提高并行度。</p><p>另外 Sink 端也是要与下游的服务进行交互，并行度还得根据下游的服务抗压能力来设置，如果在 Flink Sink 这端的数据量过大的话，然后在 Sink 处并行度也设置的很大，但是下游的服务完全撑不住这么大的并发写入，也是可能会造成下游服务直接被写挂的，下游服务可能还要对外提供一些其他的服务，如果稳定性不能保证的话，会造成很大的影响，所以最终还是要在 Sink 处的并行度做一定的权衡。</p><h3 id="9-4-4-Operator-Chain"><a href="#9-4-4-Operator-Chain" class="headerlink" title="9.4.4 Operator Chain"></a>9.4.4 Operator Chain</h3><p>对于一般的作业（无特殊耗性能处），可以尽量让算子的并行度从 Source 端到 Sink 端都保持一致，这样可以尽可能的让 Job 中的算子进行 chain 在一起，形成链，数据在链中可以直接传输，而不需要再次进行序列化与反序列化，这样带来的性能消耗就会得到降低。在 9.2 节中具体讲解了算子 chain 在一起的条件，忘记的话可以去回顾一下。</p><h3 id="9-4-5-小结与反思"><a href="#9-4-5-小结与反思" class="headerlink" title="9.4.5 小结与反思"></a>9.4.5 小结与反思</h3><p>本节讲了作业执行过程中 Source 端、中间算子和 Sink 端的并行度设置的一些技巧。并行度修改后（增大或者减小）重启 Job，如果是减小并行度，之前原有的并行度的状态该怎么办；如果是新增并行度，如何确保和原来的并行度状态保持一致？</p><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-4-如何合理的设置-Flink-作业并行度？&quot;&gt;&lt;a href=&quot;#9-4-如何合理的设置-Flink-作业并行度？&quot; class=&quot;headerlink&quot; title=&quot;9.4 如何合理的设置 Flink 作业并行度？&quot;&gt;&lt;/a&gt;9.4 如何合理的设置 Flink 作业并行度？&lt;/h2&gt;&lt;p&gt;在 9.2 节中讲解了 Flink Job 中的执行计划，并详细分析了 Flink 中的 operator chain 在一起的各种条件，在 9.3 节中也通过真实生产环境的案例来分享并行度与 Slot 的概念与关系。相信大家也都有一定的理解，但是有时候生产环境如果 Job 突然消费不及时了，或者 Job 就根本不在消费数据了，那么该怎么办？首先得看下相关的监控查看 Job 是否在正常运行，是否出现反压的情况，是否这会生产数据量过大然而并行度却是根据之前数据量设置的，种种原因都需要一个个排查一下，然后找到根因才能够对应的去解决。这节来讲解下遇到这种问题后如何合理配置并行度呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink Parallelism 和 Slot 深度理解</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/09/flink-in-action-9.3/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/09/flink-in-action-9.3/</id>
    <published>2021-08-08T16:00:00.000Z</published>
    <updated>2022-01-23T11:58:52.936Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-3-Flink-Parallelism-和-Slot-深度理解"><a href="#9-3-Flink-Parallelism-和-Slot-深度理解" class="headerlink" title="9.3 Flink Parallelism 和 Slot 深度理解"></a>9.3 Flink Parallelism 和 Slot 深度理解</h2><p>相信使用过 Flink 的你或多或少遇到过下面这个问题（笔者自己的项目曾经也出现过这样的问题），错误信息如下：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Caused by: akka.pattern.AskTimeoutException: </span><br><span class="line">Ask timed out on [Actor[akka://flink/user/taskmanager_0#15608456]] after [10000 ms]. </span><br><span class="line">Sender[null] sent message of type &quot;org.apache.flink.runtime.rpc.messages.LocalRpcInvocation&quot;.</span><br></pre></td></tr></table></figure><p>错误信息的完整截图如下图所示。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/FkaM6A.jpg" alt=""></p><p>跟着这问题在 Flink 的 Issue 列表里看到了一个类似的问题：<a href="https://issues.apache.org/jira/browse/FLINK-9056">FLINK-9056 issues</a>，看到该 Issue 下面的评论说出现该问题的原因是因为 TaskManager 的 Slot 数量不足导致的 Job 提交失败，在 Flink 1.63 中已经修复了，变成抛出异常了，修复的代码如下图所示。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/p4Tr9Z.jpg" alt=""></p><p>竟然知道了是因为 Slot 不足的原因了，那么我们就要先了解下 Slot 是什么呢？不过在了解 Slot 之前这里先介绍下 Parallelism。</p><h3 id="9-3-1-Parallelism-简介"><a href="#9-3-1-Parallelism-简介" class="headerlink" title="9.3.1 Parallelism 简介"></a>9.3.1 Parallelism 简介</h3><p>Parallelism 翻译成中文是并行的意思，在 Flink 作业里面代表算子的并行度，适当的提高并行度可以大大提高 Job 的执行效率，比如你的 Job 消费 Kafka 数据过慢，适当调大可能就消费正常了。那么在 Flink 中怎么设置并行度呢？</p><h3 id="9-3-2-如何设置-Parallelism？"><a href="#9-3-2-如何设置-Parallelism？" class="headerlink" title="9.3.2 如何设置 Parallelism？"></a>9.3.2 如何设置 Parallelism？</h3><p>在 Flink 配置文件中默认并行度是 1，你可以通过下面的命令查看到配置文件中的默认并行度：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat flink-conf.yaml | grep parallelism</span><br></pre></td></tr></table></figure><p>结果如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-055925.png" alt=""></p><p>所以如果在你的 Flink Job 里面不设置任何 Parallelism 的话，那么它也会有一个默认的 Parallelism（默认为 1），那也意味着可以修改这个配置文件的默认并行度来提高 Job 的执行效率。如果是使用命令行启动你的 Flink Job，那么你也可以这样设置并行度(使用 -p n 参数)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run -p 10 /Users/zhisheng/word-count.jar</span><br></pre></td></tr></table></figure><p>你也可以在作业中通过 <code>env.setParallelism(n)</code> 代码来设置整个作业程序的并行度。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setParallelism(10);</span><br></pre></td></tr></table></figure><p>注意：这样设置的并行度是整个程序的并行度，那么后面如果每个算子不单独设置并行度覆盖的话，那么后面每个算子的并行度就都是以这里设置的并行度为准了。如何给每个算子单独设置并行度呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data.keyBy(<span class="keyword">new</span> xxxKey())</span><br><span class="line">    .flatMap(<span class="keyword">new</span> XxxFlatMapFunction()).setParallelism(<span class="number">5</span>)</span><br><span class="line">    .map(<span class="keyword">new</span> XxxMapFunction).setParallelism(<span class="number">5</span>)</span><br><span class="line">    .addSink(<span class="keyword">new</span> XxxSink()).setParallelism(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>如上就是给每个算子单独设置并行度，这样的话，就算程序设置了 <code>env.setParallelism(10)</code> 也是会被覆盖的。这也说明优先级是：算子设置并行度 &gt; env 设置并行度 &gt; 配置文件默认并行度。</p><p>并行度讲到这里应该都懂了，下面就继续讲什么是 Slot？</p><h3 id="9-3-3-Slot-简介"><a href="#9-3-3-Slot-简介" class="headerlink" title="9.3.3 Slot 简介"></a>9.3.3 Slot 简介</h3><p>其实 Slot 的概念在 1.2 节中已经提及到，这里再细讲一点。Flink 的作业提交的架构流程如下图所示：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/r19yJh.jpg" alt=""></p><p>图中 TaskManager 是从 JobManager 处接收需要部署的 Task，任务能配置的最大并行度由 TaskManager 上可用的 Slot 决定。每个任务代表分配给任务槽的一组资源，Slot 在 Flink 里面可以认为是资源组，Flink 将每个任务分成子任务并且将这些子任务分配到 Slot 中，这样就可以并行的执行程序。</p><p>例如，如果 TaskManager 有四个 Slot，那么它将为每个 Slot 分配 25％ 的内存。 可以在一个 Slot 中运行一个或多个线程。 同一 Slot 中的线程共享相同的 JVM。 同一 JVM 中的任务共享 TCP 连接和心跳消息。TaskManager 的一个 Slot 代表一个可用线程，该线程具有固定的内存，注意 Slot 只对内存隔离，没有对 CPU 隔离。默认情况下，Flink 允许子任务共享 Slot，即使它们是不同 Task 的 subtask，只要它们来自相同的 Job，这种共享模式可以大大的提高资源利用率。</p><p>如下图所示，有两个 TaskManager，每个 TaskManager 有三个 Slot，这样我们的算子最大并行度那么就可以达到 6 个，在同一个 Slot 里面可以执行 1 至多个子任务。那么再看下图，source/map/keyby/window/apply 算子最大可以设置 6 个并行度，sink 只设置了 1 个并行度。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/ECv5y2.jpg" alt=""></p><p>每个 Flink TaskManager 在集群中提供 Slot，Slot 的数量通常与每个 TaskManager 的可用 CPU 内核数成比例（一般情况下 Slot 个数是每个 TaskManager 的 CPU 核数）。Flink 配置文件中设置的一个 TaskManager 默认的 Slot 是 1，配置如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-062913.png" alt=""></p><p><code>taskmanager.numberOfTaskSlots: 1</code> 该参数可以根据实际情况做一定的修改。</p><h3 id="9-3-4-Slot-和-Parallelism-的关系"><a href="#9-3-4-Slot-和-Parallelism-的关系" class="headerlink" title="9.3.4 Slot 和 Parallelism 的关系"></a>9.3.4 Slot 和 Parallelism 的关系</h3><h3 id="9-3-5-可能会遇到-Slot-和-Parallelism-的问题"><a href="#9-3-5-可能会遇到-Slot-和-Parallelism-的问题" class="headerlink" title="9.3.5 可能会遇到 Slot 和 Parallelism 的问题"></a>9.3.5 可能会遇到 Slot 和 Parallelism 的问题</h3><h3 id="9-3-6-小结与反思"><a href="#9-3-6-小结与反思" class="headerlink" title="9.3.6 小结与反思"></a>9.3.6 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-3-Flink-Parallelism-和-Slot-深度理解&quot;&gt;&lt;a href=&quot;#9-3-Flink-Parallelism-和-Slot-深度理解&quot; class=&quot;headerlink&quot; title=&quot;9.3 Flink Parallelism 和 Slot 深度理解&quot;&gt;&lt;/a&gt;9.3 Flink Parallelism 和 Slot 深度理解&lt;/h2&gt;&lt;p&gt;相信使用过 Flink 的你或多或少遇到过下面这个问题（笔者自己的项目曾经也出现过这样的问题），错误信息如下：&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何查看 Flink 作业执行计划？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/08/flink-in-action-9.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/08/flink-in-action-9.2/</id>
    <published>2021-08-07T16:00:00.000Z</published>
    <updated>2022-01-23T11:56:40.501Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-2-如何查看-Flink-作业执行计划？"><a href="#9-2-如何查看-Flink-作业执行计划？" class="headerlink" title="9.2 如何查看 Flink 作业执行计划？"></a>9.2 如何查看 Flink 作业执行计划？</h2><p>当一个应用程序需求比较简单的情况下，数据转换涉及的 operator（算子）可能不多，但是当应用的需求变得越来越复杂时，可能在一个 Job 里面算子的个数会达到几十个、甚至上百个，在如此多算子的情况下，整个应用程序就会变得非常复杂，所以在编写 Flink Job 的时候要是能够随时知道 Job 的执行计划那就很方便了。</p><a id="more"></a><p>刚好，Flink 是支持可以获取到整个 Job 的执行计划的，另外 Flink 官网还提供了一个可视化工具 visualizer（可以将执行计划 JSON 绘制出执行图），如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082247.png" alt=""></p><h3 id="9-2-1-如何获取执行计划-JSON？"><a href="#9-2-1-如何获取执行计划-JSON？" class="headerlink" title="9.2.1 如何获取执行计划 JSON？"></a>9.2.1 如何获取执行计划 JSON？</h3><p>既然知道了将执行计划 JSON 绘制出可查看的执行图的工具，那么该如何获取执行计划 JSON 呢？方法很简单，你只需要在你的 Flink Job 的 Main 方法 里面加上这么一行代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(env.getExecutionPlan());</span><br></pre></td></tr></table></figure><p>然后就可以在 IDEA 中右键 Run 一下你的 Flink Job，从打印的日志里面可以查看到执行计划的 JSON 串，例如下面这种：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"nodes"</span>:[&#123;<span class="attr">"id"</span>:<span class="number">1</span>,<span class="attr">"type"</span>:<span class="string">"Source: Custom Source"</span>,<span class="attr">"pact"</span>:<span class="string">"Data Source"</span>,<span class="attr">"contents"</span>:<span class="string">"Source: Custom Source"</span>,<span class="attr">"parallelism"</span>:<span class="number">5</span>&#125;,&#123;<span class="attr">"id"</span>:<span class="number">2</span>,<span class="attr">"type"</span>:<span class="string">"Sink: flink-connectors-kafka"</span>,<span class="attr">"pact"</span>:<span class="string">"Data Sink"</span>,<span class="attr">"contents"</span>:<span class="string">"Sink: flink-connectors-kafka"</span>,<span class="attr">"parallelism"</span>:<span class="number">5</span>,<span class="attr">"predecessors"</span>:[&#123;<span class="attr">"id"</span>:<span class="number">1</span>,<span class="attr">"ship_strategy"</span>:<span class="string">"FORWARD"</span>,<span class="attr">"side"</span>:<span class="string">"second"</span>&#125;]&#125;]&#125;</span><br></pre></td></tr></table></figure><p>IDEA 中运行打印出来的执行计划的 JSON 串如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082318.png" alt=""></p><h3 id="9-2-2-生成执行计划图"><a href="#9-2-2-生成执行计划图" class="headerlink" title="9.2.2 生成执行计划图"></a>9.2.2 生成执行计划图</h3><p>获取到执行计划 JSON 了，那么利用 Flink 自带的工具来绘出执行计划图，将获得到的 JSON 串复制粘贴到刚才那网址去，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082318.png" alt=""></p><p>点击上图的 <code>Draw</code> 按钮，就会生成如下图所示的执行流程图了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082351.png" alt=""></p><p>从图中我们可以看到哪些内容呢？</p><ul><li>operator name（算子）：比如 source、sink</li><li>每个 operator 的并行度：比如 Parallelism: 5</li><li>数据下发的类型：比如 FORWARD</li></ul><p>你还可以点击下图中的 <code>Data Source(ID = 1)</code> 查看具体详情，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082424.png" alt=""></p><p>随着需求的不段增加，可能算子的个数会增加，所以执行计划也会变得更为复杂，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082457.png" alt=""></p><p>看到上图是不是觉得就有点很复杂了，笔者相信可能你自己的业务需求比这还会复杂得更多，不过从这图我们可以看到比上面那个简单的执行计划图多了一种数据下发类型就是 HASH。但是大家可能会好奇的说：为什么我平时从 Flink UI 上查看到的 Job ”执行计划图“ 却不是这样子的呀？</p><p>这里我们复现一下这个问题，我们把这个稍微复杂的 Flink Job 提交到 Flink UI 上去查看一下到底它在 UI 上的执行计划图是个什么样子？我们提交 Jar 包后不运行，直接点击 show plan 的结果如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-08-27-093209.jpg" alt=""></p><p>我们再运行一下，查看运行的时候的展示的 “执行计划图” 又是不一样的，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082540.png" alt=""></p><h3 id="9-2-3-深入探究-Flink-作业执行计划"><a href="#9-2-3-深入探究-Flink-作业执行计划" class="headerlink" title="9.2.3 深入探究 Flink 作业执行计划"></a>9.2.3 深入探究 Flink 作业执行计划</h3><p>我们可以发现这两个 “执行计划图” 都和在 Flink 官网提供的 visualizer 工具生成的执行计划图是不一样的。粗略观察可以发现：在 Flink UI 上面的 “执行计划图” 变得更加简洁了，有些算子合在一起了，所以整体看起来就没这么复杂了。其实，这是 Flink 内部做的一个优化。我们先来看下 env.getExecutionPlan() 这段代码它背后的逻辑：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates the plan with which the system will execute the program, and</span></span><br><span class="line"><span class="comment"> * returns it as a String using a JSON representation of the execution data</span></span><br><span class="line"><span class="comment"> * flow graph. Note that this needs to be called, before the plan is</span></span><br><span class="line"><span class="comment"> * executed.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> The execution plan of the program, as a JSON String.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getExecutionPlan</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> getStreamGraph().getStreamingPlanAsJSON();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码注释的大概意思是：</p><blockquote><p>创建程序执行计划，并将执行数据流图的 JSON 作为 String 返回，请注意，在执行计划之前需要调用此方法。</p></blockquote><p>这个 getExecutionPlan 方法有两步操作：</p><p>1、获取到 Job 的 StreamGraph</p><p>关于如何获取到 StreamGraph，笔者在博客里面写了篇源码解析 <a href="https://t.zsxq.com/qRFIm6I">如何获取 StreamGraph？</a> 。</p><p>2、将 StreamGraph 转换成 JSON</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getStreamingPlanAsJSON</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> JSONGenerator(<span class="keyword">this</span>).getJSON();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"JSON plan creation failed"</span>, e);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>跟进 getStreamingPlanAsJSON 方法看见它构造了一个 JSONGenerator 对象（含参 StreamGraph），然后调用 getJSON 方法，我们来看下这个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getJSON</span><span class="params">()</span> </span>&#123;</span><br><span class="line">ObjectNode json = mapper.createObjectNode();</span><br><span class="line">ArrayNode nodes = mapper.createArrayNode();</span><br><span class="line">json.put(<span class="string">"nodes"</span>, nodes);</span><br><span class="line">List&lt;Integer&gt; operatorIDs = <span class="keyword">new</span> ArrayList&lt;Integer&gt;(streamGraph.getVertexIDs());</span><br><span class="line">Collections.sort(operatorIDs, <span class="keyword">new</span> Comparator&lt;Integer&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Integer idOne, Integer idTwo)</span> </span>&#123;</span><br><span class="line"><span class="keyword">boolean</span> isIdOneSinkId = streamGraph.getSinkIDs().contains(idOne);</span><br><span class="line"><span class="keyword">boolean</span> isIdTwoSinkId = streamGraph.getSinkIDs().contains(idTwo);</span><br><span class="line"><span class="comment">// put sinks at the back</span></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">visit(nodes, operatorIDs, <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;());</span><br><span class="line"><span class="keyword">return</span> json.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一开始构造外部的对象，然后调用 visit 方法继续构造内部的对象，visit 方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(ArrayNode jsonArray, List&lt;Integer&gt; toVisit,</span></span></span><br><span class="line"><span class="function"><span class="params">Map&lt;Integer, Integer&gt; edgeRemapings)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">Integer vertexID = toVisit.get(<span class="number">0</span>);</span><br><span class="line">StreamNode vertex = streamGraph.getStreamNode(vertexID);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (streamGraph.getSourceIDs().contains(vertexID)</span><br><span class="line">|| Collections.disjoint(vertex.getInEdges(), toVisit)) &#123;</span><br><span class="line"></span><br><span class="line">ObjectNode node = mapper.createObjectNode();</span><br><span class="line">decorateNode(vertexID, node);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!streamGraph.getSourceIDs().contains(vertexID)) &#123;</span><br><span class="line">ArrayNode inputs = mapper.createArrayNode();</span><br><span class="line">node.put(PREDECESSORS, inputs);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (StreamEdge inEdge : vertex.getInEdges()) &#123;</span><br><span class="line"><span class="keyword">int</span> inputID = inEdge.getSourceId();</span><br><span class="line"></span><br><span class="line">Integer mappedID = (edgeRemapings.keySet().contains(inputID)) ? edgeRemapings</span><br><span class="line">.get(inputID) : inputID;</span><br><span class="line">decorateEdge(inputs, inEdge, mappedID);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">jsonArray.add(node);</span><br><span class="line">toVisit.remove(vertexID);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">Integer iterationHead = -<span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> (StreamEdge inEdge : vertex.getInEdges()) &#123;</span><br><span class="line"><span class="keyword">int</span> operator = inEdge.getSourceId();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (streamGraph.vertexIDtoLoopTimeout.containsKey(operator)) &#123;</span><br><span class="line">iterationHead = operator;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ObjectNode obj = mapper.createObjectNode();</span><br><span class="line">ArrayNode iterationSteps = mapper.createArrayNode();</span><br><span class="line">obj.put(STEPS, iterationSteps);</span><br><span class="line">obj.put(ID, iterationHead);</span><br><span class="line">obj.put(PACT, <span class="string">"IterativeDataStream"</span>);</span><br><span class="line">obj.put(PARALLELISM, streamGraph.getStreamNode(iterationHead).getParallelism());</span><br><span class="line">obj.put(CONTENTS, <span class="string">"Stream Iteration"</span>);</span><br><span class="line">ArrayNode iterationInputs = mapper.createArrayNode();</span><br><span class="line">obj.put(PREDECESSORS, iterationInputs);</span><br><span class="line">toVisit.remove(iterationHead);</span><br><span class="line">visitIteration(iterationSteps, toVisit, iterationHead, edgeRemapings, iterationInputs);</span><br><span class="line">jsonArray.add(obj);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!toVisit.isEmpty()) &#123;</span><br><span class="line">visit(jsonArray, toVisit, edgeRemapings);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后就将这个 StreamGraph 构造成一个 JSON 串返回出去，所以其实这里返回的执行计划图就是 Flink Job 的 StreamGraph，然而我们在 Flink UI 上面看到的 “执行计划图” 是对应 Flink 中的 JobGraph，同样，笔者在博客里面也写了篇源码解析的文章 <a href="https://t.zsxq.com/naaMf6y">源码解析——如何获取 JobGraph？</a>。</p><h3 id="9-2-4-Flink-中算子链接（chain）起来的条件"><a href="#9-2-4-Flink-中算子链接（chain）起来的条件" class="headerlink" title="9.2.4 Flink 中算子链接（chain）起来的条件"></a>9.2.4 Flink 中算子链接（chain）起来的条件</h3><p>Flink 在内部会将多个算子串在一起作为一个 operator chain（执行链）来执行，每个执行链会在 TaskManager 上的一个独立线程中执行，这样不仅可以减少线程的数量及线程切换带来的资源消耗，还能降低数据在算子之间传输序列化与反序列化带来的消耗。</p><p>举个例子，拿一个 Flink Job （算子的并行度都设置为 5）生成的 StreamGraph JSON 渲染出来的执行流程图如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082620.png" alt=""></p><p>提交到 Flink UI 上的 JobGraph 如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082641.png" alt=""></p><p>可以看到 Flink 它内部将三个算子（source、filter、sink）都串成在一个执行链里。但是我们修改一下 filter 这个算子的并行度为 4，我们再次提交到 Flink UI 上运行，效果如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082702.png" alt=""></p><p>你会发现它竟然拆分成三个了，我们继续将 sink 的并行度也修改成 4，继续打包运行后的效果如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-15-082742.png" alt=""></p><p>神奇不，它变成了 2 个了，将 filter 和 sink 算子串在一起了执行了。经过简单的测试，我们可以发现其实如果想要把两个不一样的算子串在一起执行确实还不是那么简单的，的确，它背后的条件可是比较复杂的，这里笔者给出源码出来，感兴趣的可以独自阅读下源码。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isChainable</span><span class="params">(StreamEdge edge, StreamGraph streamGraph)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//获取StreamEdge的源和目标StreamNode</span></span><br><span class="line">StreamNode upStreamVertex = edge.getSourceVertex();</span><br><span class="line">StreamNode downStreamVertex = edge.getTargetVertex();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取源和目标StreamNode中的StreamOperator</span></span><br><span class="line">StreamOperator&lt;?&gt; headOperator = upStreamVertex.getOperator();</span><br><span class="line">StreamOperator&lt;?&gt; outOperator = downStreamVertex.getOperator();</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> downStreamVertex.getInEdges().size() == <span class="number">1</span></span><br><span class="line">&amp;&amp; outOperator != <span class="keyword">null</span></span><br><span class="line">&amp;&amp; headOperator != <span class="keyword">null</span></span><br><span class="line">&amp;&amp; upStreamVertex.isSameSlotSharingGroup(downStreamVertex)</span><br><span class="line">&amp;&amp; outOperator.getChainingStrategy() == ChainingStrategy.ALWAYS</span><br><span class="line">&amp;&amp; (headOperator.getChainingStrategy() == ChainingStrategy.HEAD ||</span><br><span class="line">headOperator.getChainingStrategy() == ChainingStrategy.ALWAYS)</span><br><span class="line">&amp;&amp; (edge.getPartitioner() <span class="keyword">instanceof</span> ForwardPartitioner)</span><br><span class="line">&amp;&amp; upStreamVertex.getParallelism() == downStreamVertex.getParallelism()</span><br><span class="line">&amp;&amp; streamGraph.isChainingEnabled();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从源码最后的 return 可以看出它有九个条件：</p><p>…</p><p>所以看到上面的这九个条件，你是不是在想如果我们代码能够合理的写好，那么就有可能会将不同的算子串在一个执行链中，这样也就可以提高代码的执行效率了。</p><h3 id="9-2-5-如何禁止-Operator-chain？"><a href="#9-2-5-如何禁止-Operator-chain？" class="headerlink" title="9.2.5 如何禁止 Operator chain？"></a>9.2.5 如何禁止 Operator chain？</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="9-2-6-小结与反思"><a href="#9-2-6-小结与反思" class="headerlink" title="9.2.6 小结与反思"></a>9.2.6 小结与反思</h3><p>本节内容从查看作业的执行计划来分析作业的执行情况，接着分析了作业算子 chain 起来的条件，并通过程序演示来验证，最后讲解了如何禁止算子 chain 起来。</p><p>本节代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-examples/src/main/java/com/zhisheng/examples/streaming/chain">chain</a></p><p><a href="https://flink.apache.org/visualizer/">Job visualizer 工具</a></p><p><a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">源码解析——如何获取 StreamGraph</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-2-如何查看-Flink-作业执行计划？&quot;&gt;&lt;a href=&quot;#9-2-如何查看-Flink-作业执行计划？&quot; class=&quot;headerlink&quot; title=&quot;9.2 如何查看 Flink 作业执行计划？&quot;&gt;&lt;/a&gt;9.2 如何查看 Flink 作业执行计划？&lt;/h2&gt;&lt;p&gt;当一个应用程序需求比较简单的情况下，数据转换涉及的 operator（算子）可能不多，但是当应用的需求变得越来越复杂时，可能在一个 Job 里面算子的个数会达到几十个、甚至上百个，在如此多算子的情况下，整个应用程序就会变得非常复杂，所以在编写 Flink Job 的时候要是能够随时知道 Job 的执行计划那就很方便了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何处理 Flink Job BackPressure （反压）问题?</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/07/flink-in-action-9.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/07/flink-in-action-9.1/</id>
    <published>2021-08-06T16:00:00.000Z</published>
    <updated>2022-01-23T11:50:39.790Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第九章-——-Flink-性能调优"><a href="#第九章-——-Flink-性能调优" class="headerlink" title="第九章 —— Flink 性能调优"></a>第九章 —— Flink 性能调优</h1><p>通过第八章的监控图表信息，我们可以发现问题，在发现问题后，需要去分析为什么会发生这些问题以及我们该如何去解决这些问题。本章将会介绍很多 Flink 生产环境遇到的问题，比如作业出现反压、作业并行度配置不合理、作业数据倾斜等，除了引出这种常见问题之外，笔者还将和你一起去分析这种问题造成的原因以及如何去优化作业。比如合理的配置并行度、让作业算子尽可能的 chain 在一起已达到最优等。希望通过本章的内容，你可以将这些解决方法运用在你的公司，帮助公司解决类似的问题。</p><h2 id="9-1-如何处理-Flink-Job-BackPressure-（反压）问题"><a href="#9-1-如何处理-Flink-Job-BackPressure-（反压）问题" class="headerlink" title="9.1 如何处理 Flink Job BackPressure （反压）问题?"></a>9.1 如何处理 Flink Job BackPressure （反压）问题?</h2><p>反压（BackPressure）机制被广泛应用到实时流处理系统中，流处理系统需要能优雅地处理反压问题。反压通常产生于这样的场景：短时间的负载高峰导致系统接收数据的速率远高于它处理数据的速率。许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或遇到大促、秒杀活动导致流量陡增。反压如果不能得到正确的处理，可能会导致资源耗尽甚至系统崩溃。反压机制是指系统能够自己检测到被阻塞的 Operator，然后自适应地降低源头或上游数据的发送速率，从而维持整个系统的稳定。Flink 任务一般运行在多个节点上，数据从上游算子发送到下游算子需要网络传输，若系统在反压时想要降低数据源头或上游算子数据的发送速率，那么肯定也需要网络传输。所以下面先来了解一下 Flink 的网络流控（Flink 对网络数据流量的控制）机制。</p><a id="more"></a><h3 id="9-1-1-Flink-流处理为什么需要网络流控"><a href="#9-1-1-Flink-流处理为什么需要网络流控" class="headerlink" title="9.1.1 Flink 流处理为什么需要网络流控"></a>9.1.1 Flink 流处理为什么需要网络流控</h3><p>下图是一个简单的 Flink 流任务执行图：任务首先从 Kafka 中读取数据、通过 map 算子对数据进行转换、keyBy 按照指定 key 对数据进行分区（key 相同的数据经过 keyBy 后分到同一个 subtask 实例中），keyBy 后对数据进行 map 转换，然后使用 Sink 将数据输出到外部存储。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-152946.jpg" alt="简单的Flink流任务执行图.png" align='center' style="zoom: 67%;" /></p><p>众所周知，在大数据处理中，无论是批处理还是流处理，单点处理的性能总是有限的，我们的单个 Job 一般会运行在多个节点上，通过多个节点共同配合来提升整个系统的处理性能。图中，任务被切分成 4 个可独立执行的 subtask 分别是 A0、A1、B0、B1，在数据处理过程中就会存在 shuffle。例如，subtask A0 处理完的数据经过 keyBy 后被发送到 subtask B0、B1 所在节点去处理。那么问题来了，subtask A0 应该以多快的速度向 subtask B0、B1 发送数据呢？把上述问题抽象化，如下图所示，将 subtask A0 当作 Producer，subtask B0 当做 Consumer，上游 Producer 向下游 Consumer 发送数据，在发送端和接收端有相应的 Send Buffer 和 Receive Buffer，但是上游 Producer 生产数据的速率比下游 Consumer 消费数据的速率大，Producer 生产数据的速率为 2MB/s， Consumer 消费数据速率为 1MB/s，Receive Buffer 容量只有 5MB，所以过了 5 秒后，接收端的 Receive Buffer 满了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004946.png" alt="网络流控存在的问题.png" style="zoom:13%;" /></p><p>下游消费速率慢，且接收区的 Receive Buffer 有限，如果上游一直有源源不断的数据，那么将会面临着以下两种情况：</p><ul><li>下游消费者的缓冲区放不下数据，导致下游消费者会丢弃新到达的数据</li><li>为了不丢弃数据，所以下游消费者的 Receive Buffer 持续扩张，最后耗尽消费者的内存，导致 OOM 程序挂掉</li></ul><p>常识告诉我们，这两种情况在生产环境下都是不能接受的，第一种会丢数据、第二种会把应用程序挂掉。所以，该问题的解决方案不应该是下游 Receive Buffer 一直累积数据，而是上游 Producer 发现下游 Consumer 消费比较慢的时候，应该在 Producer 端做出限流的策略，防止在下游 Consumer 端无限制地堆积数据。那上游 Producer 端该如何做限流呢？可以采用如下图所示的静态限流策略：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-005000.png" alt="网络流控-静态限速.png" style="zoom:13%;" /></p><p>静态限速的思想就是，提前已知下游 Consumer 端的消费速率，然后在上游 Producer 端使用类似令牌桶的思想，限制 Producer 端生产数据的速率，从而控制上游 Producer 端向下游 Consumer 端发送数据的速率。但是静态限速会存在问题：</p><ul><li>通常无法事先预估下游 Consumer 端能承受的最大速率</li><li>就算通过某种方式预估出下游 Consumer 端能承受的最大速率，在运行过程中也可能会因为网络抖动、 CPU 共享竞争、内存紧张、IO阻塞等原因造成下游 Consumer 的吞吐量降低，但是上游 Producer 的吞吐量正常，然后又会出现之前所说的下游接收区的 Receive Buffer 有限，上游一直有源源不断的数据发送到下游的问题，还是会造成下游要么丢数据，要么为了不丢数据 buffer 不断扩充导致下游 OOM 的问题</li></ul><p>综上所述，我们发现了，上游 Producer 端必须有一个限流的策略，且静态限流是不可靠的，于是就需要一个动态限流的策略。可以采用如下图所示的动态反馈策略：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-005009.png" alt="网络流控-动态限速.png" style="zoom:13%;" /></p><p>下游 Consumer 端会频繁地向上游 Producer 端进行动态反馈，告诉 Producer 下游 Consumer 的负载能力，从而使 Producer 端可以动态调整向下游 Consumer 发送数据的速率，以实现 Producer 端的动态限流。当 Consumer 端处理较慢时，Consumer 将负载反馈到 Producer 端，Producer 端会根据反馈适当降低 Producer 自身从上游或者 Source 端读数据的速率来降低向下游 Consumer 发送数据的速率。当 Consumer 处理负载能力提升后，又及时向 Producer 端反馈，Producer 会通过提升自身从上游或 Source 端读数据的速率来提升向下游发送数据的速率，通过动态反馈的策略来动态调整系统整体的吞吐量。</p><p>读到这里，应该知道 Flink 为什么需要网络流控机制了，并且知道 Flink 的网络流控机制必须是一个动态反馈的策略。但是还有以下几个问题：</p><ul><li>Flink 中数据具体是怎么从上游  Producer 端发送到下游 Consumer 端的？</li><li>Flink 的动态限流具体是怎么实现的？下游的负载能力和压力是如何传递给上游的？</li></ul><p>带着这两个问题，学习下面的 Flink 网络流控与反压机制。</p><h3 id="9-1-2-Flink-1-5-之前网络流控机制介绍"><a href="#9-1-2-Flink-1-5-之前网络流控机制介绍" class="headerlink" title="9.1.2 Flink 1.5 之前网络流控机制介绍"></a>9.1.2 Flink 1.5 之前网络流控机制介绍</h3><p>在 Flink 1.5 之前，Flink 没有使用任何复杂的机制来解决反压问题，因为根本不需要那样的方案！Flink 利用自身作为纯数据流引擎的优势来优雅地响应反压问题。下面我们会深入分析 Flink 是如何在 Task 之间传输数据的，以及数据流如何实现自然降速的。</p><p>如下图所示，Job 分为 Task A、B、C，Task A 是 Source Task、Task B 处理转换数据、Task C 是 Sink Task。Task A 从外部 Source 端读取到数据后将数据序列化放到 Send Buffer 中，再由 Task A 的 Send Buffer 发送到 Task B 的 Receive Buffer，Task B 的算子从 Task B 的 Receive Buffer 中将数据反序列后进行处理，将处理后数据序列化放到 Task B 的 Send Buffer 中，再由 Task B 的 Send Buffer 发送到 Task C 的 Receive Buffer，Task C 再从 Task C 的 Receive Buffer 中将数据反序列后输出到外部 Sink 端，这就是所有数据的传输和处理流程。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-005021.png" alt="简单的3个Task数据传输示意图.png" style="zoom:12%;" /></p><p>Flink 中，动态反馈策略原理比较简单，假如 Task C 由于各种原因吞吐量急剧降低，那么肯定会造成 Task C 的 Receive Buffer 中堆积大量数据，此时 Task B 还在给 Task C 发送数据，但是毕竟内存是有限的，持续一段时间后 Task C 的 Receive Buffer 满了，此时 Task B 发现 Task C 的 Receive Buffer 满了后，就不会再往 Task C 发送数据了，Task B 处理完的数据就开始往 Task B 的 Send Buffer 积压，一段时间后 Task B 的 Send Buffer 也满了，Task B 的处理就会被阻塞，这时 Task A 还在往 Task B 的 Receive Buffer 发送数据。同样的道理，Task B 的 Receive Buffer 很快满了，导致 Task A 不再往 Task B 发送数据，Task A 的 Send Buffer 也会被用完，Task A 是 Source Task 没有上游，所以 Task A 直接降低从外部 Source 端读取数据的速率甚至完全停止读取数据。通过以上原理，Flink 将下游的压力传递给上游。如果下游 Task C 的负载能力恢复后，如何将负载提升的信息反馈给上游呢？实际上 Task B 会一直向 Task C 发送探测信号，检测 Task C 的 Receive Buffer 是否有足够的空间，当 Task C 的负载能力恢复后，Task C 会优先消费 Task C Receive Buffer 中的数据，Task C Receive Buffer 中有足够的空间时，Task B 会从 Send Buffer 继续发送数据到 Task C 的 Receive Buffer，Task B 的 Send Buffer 有足够空间后，Task B 又开始正常处理数据，很快 Task B 的 Receive Buffer 中也会有足够空间，同理，Task A 会从 Send Buffer 继续发送数据到 Task B 的 Receive Buffer，Task A 的 Receive Buffer 有足够空间后，Task A 就可以从外部的 Source 端开始正常读取数据了。通过以上原理，Flink 将下游负载过低的消息传递给上游。所以说 Flink 利用自身纯数据流引擎的优势优雅地响应反压问题，并没有任何复杂的机制来解决反压。上述流程，就是 Flink 动态限流（反压机制）的简单描述，可以看到 Flink 的反压是从下游往上游传播的，一直往上传播到 Source Task 后，Source Task 最终会降低或提升从外部 Source 端读取数据的速率。</p><p>如下图所示，对于一个 Flink 任务，动态反馈要考虑如下两种情况：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-153007.jpg" alt="简单的3个Task反压图示.png" style="zoom:12%;" /></p><p>1.跨 Task，动态反馈具体如何从下游 Task 的 Receive Buffer 反馈给上游 Task 的 Send Buffer</p><ul><li>当下游 Task C 的 Receive Buffer 满了，如何告诉上游 Task B 应该降低数据发送速率</li><li>当下游 Task C 的 Receive Buffer 空了，如何告诉上游 Task B 应该提升数据发送速率</li></ul><blockquote><p>注：这里又分了两种情况，Task B 和 Task C 可能在同一个 TaskManager 上运行，也有可能不在同一个 TaskManager 上运行</p><ol><li>Task B 和 Task C 在同一个 TaskManager 运行指的是：一个 TaskManager 包含了多个 Slot，Task B 和 Task C 都运行在这个 TaskManager 上。此时 Task B 给 Task C 发送数据实际上是同一个 JVM 内的数据发送，所以<strong>不存在网络通信</strong></li><li>Task B 和 Task C 不在同一个 TaskManager 运行指的是：Task B 和 Task C 运行在不同的 TaskManager 中。此时 Task B 给 Task C 发送数据是跨节点的，所以<strong>会存在网络通信</strong></li></ol></blockquote><p>2.Task 内，动态反馈如何从内部的 Send Buffer 反馈给内部的 Receive Buffer</p><ul><li>当 Task B 的 Send Buffer 满了，如何告诉 Task B 内部的 Receive Buffer，自身的 Send Buffer 已经满了？要让 Task B 的 Receive Buffer 感受到压力，才能把下游的压力传递到 Task A</li><li>当 Task B 的 Send Buffer 空了，如何告诉 Task B 内部的 Receive Buffer 下游 Send Buffer 空了，并把下游负载很低的消息传递给 Task A</li></ul><p>到目前为止，动态反馈的具体细节抽象成了三个问题：</p><ul><li>跨 Task 且 Task 不在同一个 TaskManager 内，动态反馈具体如何从下游 Task 的 Receive Buffer 反馈给上游 Task 的 Send Buffer</li><li>跨 Task 且 Task 在同一个 TaskManager 内，动态反馈具体如何从下游 Task 的 Receive Buffer 反馈给上游 Task 的 Send Buffer</li><li>Task 内，动态反馈具体如何从 Task 内部的 Send Buffer 反馈给内部的 Receive Buffer</li></ul><h4 id="TaskManager-之间网络传输相关组件"><a href="#TaskManager-之间网络传输相关组件" class="headerlink" title="TaskManager 之间网络传输相关组件"></a>TaskManager 之间网络传输相关组件</h4><p>TaskManager 之间数据传输流向如下图所示，可以看到 Source Task 给 Task B 发送数据，Source Task 做为 Producer，Task B 做为 Consumer，Producer 端产生的数据最后通过网络发送给 Consumer 端。Producer 端 Operator 实例对一条条的数据进行处理，处理完的数据首先缓存到 ResultPartition 内的 ResultSubPartition 中。ResultSubPartition 中一个 Buffer 写满或者超时后，就会触发将 ResultSubPartition 中的数据拷贝到 Producer 端 Netty 的 Buffer 中，之后又把数据拷贝到 Socket 的 Send Buffer 中，这里有一个从用户态拷贝到内核态的过程，最后通过 Socket 发送网络请求，把 Send Buffer 中的数据发送到 Consumer 端的 Receive Buffer。数据到达 Consumer 端后，再依次从 Socket 的 Receive Buffer 拷贝到 Netty 的 Buffer，再拷贝到 Consumer Operator InputGate 内的 InputChannel 中，最后 Consumer Operator 就可以读到数据进行处理了。这就是两个 TaskManager 之间的数据传输过程，我们可以看到发送方和接收方各有三层的 Buffer。当 Task B 往下游发送数据时，整个流程与 Source Task 给 Task B 发送数据的流程类似。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-005036.png" alt="TaskManager 之间数据传输流向.png" style="zoom:12%;" /></p><p>根据上述流程，下表中对 Flink 通信相关的一些术语进行介绍：</p><table><thead><tr><th style="text-align:left">概念/术语</th><th>解释</th></tr></thead><tbody><tr><td style="text-align:left">ResultPartition</td><td>生产者生产的数据首先写入到 ResultPartition 中，一个 Operator 实例对应一个ResultPartition。</td></tr><tr><td style="text-align:left">ResultSubpartition</td><td>一个 ResultPartition 是由多个 ResultSubpartition 组成。当 Producer Operator 实例生产的数据要发送给下游 Consumer Operator n 个实例时，那么该 Producer Operator 实例对应的 ResultPartition 中就包含 n 个 ResultSubpartition。</td></tr><tr><td style="text-align:left">InputGate</td><td>消费者消费的数据来自于 InputGate 中，一个 Operator 实例对应一个InputGate。网络中传输的数据会写入到 Task 的 InputGate。</td></tr><tr><td style="text-align:left">InputChannel</td><td>一个 InputGate 是由多个 InputChannel 组成。当 Consumer Operator 实例读取的数据来自于上游 Producer Operator n 个实例时，那么该 Consumer Operator 实例对应的 InputGate 中就包含 n 个 InputChannel。</td></tr><tr><td style="text-align:left">RecordReader</td><td>用于将记录从Buffer中读出。</td></tr><tr><td style="text-align:left">RecordWriter</td><td>用于将记录写入Buffer。</td></tr><tr><td style="text-align:left">LocalBufferPool</td><td>为 ResultPartition 或 InputGate 分配内存，每一个 ResultPartition 或 InputGate分别对应一个 LocalBufferPool。</td></tr><tr><td style="text-align:left">NetworkBufferPool</td><td>为 LocalBufferPool 分配内存，NetworkBufferPool 是 Task 之间共享的，每个 TaskManager 只会实例化一个。</td></tr></tbody></table><p>InputGate 和 ResultPartition 的内存是如何申请的呢？如下图所示，了解一下 Flink 网络传输相关的内存管理。在 TaskManager 初始化时，Flink 会在 NetworkBufferPool 中生成一定数量的内存块 MemorySegment，内存块的总数量就代表了网络传输中所有可用的内存。 NetworkBufferPool 是 Task 之间共享的，每个 TaskManager 只会实例化一个。Task 线程启动时，会为 Task 的 InputChannel 和 ResultSubPartition 分别创建一个 LocalBufferPool。InputGate 或 ResultPartition 需要写入数据时，会向相对应的 LocalBufferPool 申请内存（图中①），当 LocalBufferPool 没有足够的内存且还没到达 LocalBufferPool 设置的上限时，就会向 NetworkBufferPool 申请内存（图中②），并将内存分配给相应的 InputChannel 或 ResultSubPartition （图③④）。虽然可以申请，但是必须明白内存申请肯定是有限制的，不可能无限制的申请，我们在启动任务时可以指定该任务最多可能申请多大的内存空间用于 NetworkBufferPool。当 InputChannel 的内存块被 Operator 读取消费掉或 ResultSubPartition 的内存块已经被写入到了 Netty 中，那么 InputChannel 和 ResultSubPartition 中的内存块就可以还给 LocalBufferPool 了（图中⑤），如果 LocalBufferPool 中有较多空闲的内存块，就会还给 NetworkBufferPool （图中⑥）。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-005044.png" alt="Flink 网络传输相关的内存管理.png" style="zoom:12%;" /></p><p>了解了 Flink 网络传输相关的内存管理，我们来分析 3 种动态反馈的具体细节。</p><h4 id="跨-Task-且-Task-不在同一个-TaskManager-内时，反压如何向上游传播"><a href="#跨-Task-且-Task-不在同一个-TaskManager-内时，反压如何向上游传播" class="headerlink" title="跨 Task 且 Task 不在同一个 TaskManager 内时，反压如何向上游传播"></a>跨 Task 且 Task 不在同一个 TaskManager 内时，反压如何向上游传播</h4><h4 id="跨-Task-且-Task-在同一个-TaskManager-内，反压如何向上游传播"><a href="#跨-Task-且-Task-在同一个-TaskManager-内，反压如何向上游传播" class="headerlink" title="跨 Task 且 Task 在同一个 TaskManager 内，反压如何向上游传播"></a>跨 Task 且 Task 在同一个 TaskManager 内，反压如何向上游传播</h4><h4 id="Task-内部，反压如何向上游传播"><a href="#Task-内部，反压如何向上游传播" class="headerlink" title="Task 内部，反压如何向上游传播"></a>Task 内部，反压如何向上游传播</h4><h3 id="9-1-3-基于-Credit-的反压机制"><a href="#9-1-3-基于-Credit-的反压机制" class="headerlink" title="9.1.3 基于 Credit 的反压机制"></a>9.1.3 基于 Credit 的反压机制</h3><h4 id="Flink-1-5-之前反压机制存在的问题"><a href="#Flink-1-5-之前反压机制存在的问题" class="headerlink" title="Flink 1.5 之前反压机制存在的问题"></a>Flink 1.5 之前反压机制存在的问题</h4><h4 id="基于-Credit-的反压机制原理"><a href="#基于-Credit-的反压机制原理" class="headerlink" title="基于 Credit 的反压机制原理"></a>基于 Credit 的反压机制原理</h4><h3 id="9-1-4-Flink-如何定位产生反压的位置？"><a href="#9-1-4-Flink-如何定位产生反压的位置？" class="headerlink" title="9.1.4 Flink 如何定位产生反压的位置？"></a>9.1.4 Flink 如何定位产生反压的位置？</h3><h4 id="Flink-反压监控原理介绍"><a href="#Flink-反压监控原理介绍" class="headerlink" title="Flink 反压监控原理介绍"></a>Flink 反压监控原理介绍</h4><h4 id="利用-Flink-Web-UI-定位产生反压的位置"><a href="#利用-Flink-Web-UI-定位产生反压的位置" class="headerlink" title="利用 Flink Web UI 定位产生反压的位置"></a>利用 Flink Web UI 定位产生反压的位置</h4><h4 id="利用-Flink-Metrics-定位产生反压的位置"><a href="#利用-Flink-Metrics-定位产生反压的位置" class="headerlink" title="利用 Flink Metrics 定位产生反压的位置"></a>利用 Flink Metrics 定位产生反压的位置</h4><h3 id="9-1-5-定位到反压来源后，该如何处理？"><a href="#9-1-5-定位到反压来源后，该如何处理？" class="headerlink" title="9.1.5 定位到反压来源后，该如何处理？"></a>9.1.5 定位到反压来源后，该如何处理？</h3><h4 id="系统资源"><a href="#系统资源" class="headerlink" title="系统资源"></a>系统资源</h4><h4 id="垃圾收集（GC）"><a href="#垃圾收集（GC）" class="headerlink" title="垃圾收集（GC）"></a>垃圾收集（GC）</h4><h4 id="CPU-线程瓶颈"><a href="#CPU-线程瓶颈" class="headerlink" title="CPU/线程瓶颈"></a>CPU/线程瓶颈</h4><h4 id="线程竞争"><a href="#线程竞争" class="headerlink" title="线程竞争"></a>线程竞争</h4><h4 id="负载不平衡"><a href="#负载不平衡" class="headerlink" title="负载不平衡"></a>负载不平衡</h4><h4 id="外部依赖"><a href="#外部依赖" class="headerlink" title="外部依赖"></a>外部依赖</h4><h3 id="9-1-6-小结与反思"><a href="#9-1-6-小结与反思" class="headerlink" title="9.1.6 小结与反思"></a>9.1.6 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/f66iAMz">https://t.zsxq.com/f66iAMz</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第九章-——-Flink-性能调优&quot;&gt;&lt;a href=&quot;#第九章-——-Flink-性能调优&quot; class=&quot;headerlink&quot; title=&quot;第九章 —— Flink 性能调优&quot;&gt;&lt;/a&gt;第九章 —— Flink 性能调优&lt;/h1&gt;&lt;p&gt;通过第八章的监控图表信息，我们可以发现问题，在发现问题后，需要去分析为什么会发生这些问题以及我们该如何去解决这些问题。本章将会介绍很多 Flink 生产环境遇到的问题，比如作业出现反压、作业并行度配置不合理、作业数据倾斜等，除了引出这种常见问题之外，笔者还将和你一起去分析这种问题造成的原因以及如何去优化作业。比如合理的配置并行度、让作业算子尽可能的 chain 在一起已达到最优等。希望通过本章的内容，你可以将这些解决方法运用在你的公司，帮助公司解决类似的问题。&lt;/p&gt;
&lt;h2 id=&quot;9-1-如何处理-Flink-Job-BackPressure-（反压）问题&quot;&gt;&lt;a href=&quot;#9-1-如何处理-Flink-Job-BackPressure-（反压）问题&quot; class=&quot;headerlink&quot; title=&quot;9.1 如何处理 Flink Job BackPressure （反压）问题?&quot;&gt;&lt;/a&gt;9.1 如何处理 Flink Job BackPressure （反压）问题?&lt;/h2&gt;&lt;p&gt;反压（BackPressure）机制被广泛应用到实时流处理系统中，流处理系统需要能优雅地处理反压问题。反压通常产生于这样的场景：短时间的负载高峰导致系统接收数据的速率远高于它处理数据的速率。许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或遇到大促、秒杀活动导致流量陡增。反压如果不能得到正确的处理，可能会导致资源耗尽甚至系统崩溃。反压机制是指系统能够自己检测到被阻塞的 Operator，然后自适应地降低源头或上游数据的发送速率，从而维持整个系统的稳定。Flink 任务一般运行在多个节点上，数据从上游算子发送到下游算子需要网络传输，若系统在反压时想要降低数据源头或上游算子数据的发送速率，那么肯定也需要网络传输。所以下面先来了解一下 Flink 的网络流控（Flink 对网络数据流量的控制）机制。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何搭建一套 Flink 监控系统?</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/06/flink-in-action-8.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/06/flink-in-action-8.2/</id>
    <published>2021-08-05T16:00:00.000Z</published>
    <updated>2022-01-16T12:23:45.546Z</updated>
    
    <content type="html"><![CDATA[<h2 id="8-2-搭建一套-Flink-监控系统"><a href="#8-2-搭建一套-Flink-监控系统" class="headerlink" title="8.2 搭建一套 Flink 监控系统"></a>8.2 搭建一套 Flink 监控系统</h2><p>8.1 节中讲解了 JobManager、TaskManager 和 Flink Job 的监控，以及需要关注的监控指标有哪些。本节带大家讲解一下如何搭建一套完整的 Flink 监控系统，如果你所在的公司没有专门的监控平台，那么可以根据本节的内容来为公司搭建一套属于自己公司的 Flink 监控系统。</p><a id="more"></a><h3 id="8-2-1-利用-API-获取监控数据"><a href="#8-2-1-利用-API-获取监控数据" class="headerlink" title="8.2.1 利用 API 获取监控数据"></a>8.2.1 利用 API 获取监控数据</h3><p>熟悉 Flink 的朋友都知道 Flink 的 UI 上面已经详细地展示了很多监控指标的数据，并且这些指标还是比较重要的，所以如果不想搭建额外的监控系统，那么直接利用 Flink 自身的 UI 就可以获取到很多重要的监控信息。这里要讲的是这些监控信息其实也是通过 Flink 自身的 Rest API 来获取数据的，所以其实要搭建一个粗糙的监控平台，也是可以直接利用现有的接口定时去获取数据，然后将这些指标的数据存储在某种时序数据库中，最后用些可视化图表做个展示，这样一个完整的监控系统就做出来了。</p><p>这里通过 Chrome 浏览器的控制台来查看一下有哪些 REST API 是用来提供监控数据的。</p><p>1.在 Chrome 浏览器中打开 <code>http://localhost:8081/overview</code> 页面，可以获取到整个 Flink 集群的资源信息：TaskManager 个数（TaskManagers）、Slot 总个数（Total Task Slots）、可用 Slot 个数（Available Task Slots）、Job 运行个数（Running Jobs）、Job 运行状态（Finished 0 Canceled 0 Failed 0）等，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-03-161007.png" alt=""></p><p>2.通过 <code>http://localhost:8081/taskmanagers</code> 页面查看 TaskManager 列表，可以知道该集群下所有 TaskManager 的信息（数据端口号（Data Port）、上一次心跳时间（Last Heartbeat）、总共的 Slot 个数（All Slots）、空闲的 Slot 个数（Free Slots）、以及 CPU 和内存的分配使用情况，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-03-161422.png" alt=""></p><p>3.通过 <code>http://localhost:8081/taskmanagers/tm_id</code> 页面查看 TaskManager 的具体情况（这里的 tm_id 是个随机的 UUID 值）。在这个页面上，除了上一条的监控信息可以查看，还可以查看该 TaskManager 的 JVM（堆和非堆）、Direct 内存、网络、GC 次数和时间，如下图所示。内存和 GC 这些信息非常重要，很多时候 TaskManager 频繁重启的原因就是 JVM 内存设置得不合理，导致频繁的 GC，最后使得 OOM 崩溃，不得不重启。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-03-162532.png" alt=""></p><p>另外如果你在 <code>/taskmanagers/tm_id</code> 接口后面加个 <code>/log</code> 就可以查看该 TaskManager 的日志，注意，在 Flink 中的日志和平常自己写的应用中的日志是不一样的。在 Flink 中，日志是以 TaskManager 为概念打印出来的，而不是以单个 Job 打印出来的，如果你的 Job 在多个 TaskManager 上运行，那么日志就会在多个 TaskManager 中打印出来。如果一个 TaskManager 中运行了多个 Job，那么它里面的日志就会很混乱，查看日志时会发现它为什么既有这个 Job 打出来的日志，又有那个 Job 打出来的日志，如果你之前有这个疑问，那么相信你看完这里，就不会有疑问了。</p><p>对于这种设计是否真的好，不同的人有不同的看法，在 Flink 的 Issue 中就有人提出了该问题，Issue 中的描述是希望日志可以是 Job 与 Job 之间的隔离，这样日志更方便采集和查看，对于排查问题也会更快。对此国内有公司也对这一部分做了改进，不知道正在看本书的你是否有什么好的想法可以解决 Flink 的这一痛点。</p><p>4.通过 <code>http://localhost:8081/#/job-manager/config</code> 页面可以看到可 JobManager 的配置信息，另外通过 <code>http://localhost:8081/jobmanager/log</code> 页面可以查看 JobManager 的日志详情。</p><p>5.通过 <code>http://localhost:8081/jobs/job_id</code> 页面可以查看 Job 的监控数据，如下图所示，由于指标（包括了 Job 的 Task 数据、Operator 数据、Exception 数据、Checkpoint 数据等）过多，大家可以自己在本地测试查看。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-03-164158.png" alt=""></p><p>上面列举了几个 REST API（不是全部），主要是为了告诉大家，其实这些接口我们都知道，那么我们也可以利用这些接口去获取对应的监控数据，然后绘制出更酷炫的图表，用更直观的页面将这些数据展示出来，这样就能更好地控制。</p><p>除了利用 Flink UI 提供的接口去定时获取到监控数据，其实 Flink 还提供了很多的 reporter 去上报监控数据，比如 JMXReporter、PrometheusReporter、PrometheusPushGatewayReporter、InfluxDBReporter、StatsDReporter 等，这样就可以根据需求去定制获取到 Flink 的监控数据，下面教大家使用几个常用的 reporter。</p><p>相关 Rest API 可以查看官网链接：<a href="https://ci.apache.org/projects/flink/flink-docs-stable/monitoring/metrics.html#rest-api-integration">rest-api-integration</a></p><h3 id="8-2-2-Metrics-类型简介"><a href="#8-2-2-Metrics-类型简介" class="headerlink" title="8.2.2 Metrics 类型简介"></a>8.2.2 Metrics 类型简介</h3><p>可以在继承自 RichFunction 的函数中通过 <code>getRuntimeContext().getMetricGroup()</code> 获取 Metric 信息，常见的 Metrics 的类型有 Counter、Gauge、Histogram、Meter。</p><h4 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h4><h4 id="Gauge"><a href="#Gauge" class="headerlink" title="Gauge"></a>Gauge</h4><h4 id="Histogram"><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h4><h4 id="Meter"><a href="#Meter" class="headerlink" title="Meter"></a>Meter</h4><h3 id="8-2-3-利用-JMXReporter-获取监控数据"><a href="#8-2-3-利用-JMXReporter-获取监控数据" class="headerlink" title="8.2.3 利用 JMXReporter 获取监控数据"></a>8.2.3 利用 JMXReporter 获取监控数据</h3><h3 id="8-2-4-利用-PrometheusReporter-获取监控数据"><a href="#8-2-4-利用-PrometheusReporter-获取监控数据" class="headerlink" title="8.2.4 利用 PrometheusReporter 获取监控数据"></a>8.2.4 利用 PrometheusReporter 获取监控数据</h3><h3 id="8-2-5-利用-PrometheusPushGatewayReporter-获取监控数据"><a href="#8-2-5-利用-PrometheusPushGatewayReporter-获取监控数据" class="headerlink" title="8.2.5 利用 PrometheusPushGatewayReporter 获取监控数据"></a>8.2.5 利用 PrometheusPushGatewayReporter 获取监控数据</h3><h3 id="8-2-6-利用-InfluxDBReporter-获取监控数据"><a href="#8-2-6-利用-InfluxDBReporter-获取监控数据" class="headerlink" title="8.2.6 利用 InfluxDBReporter 获取监控数据"></a>8.2.6 利用 InfluxDBReporter 获取监控数据</h3><h3 id="8-2-7-安装-InfluxDB-和-Grafana"><a href="#8-2-7-安装-InfluxDB-和-Grafana" class="headerlink" title="8.2.7 安装 InfluxDB 和 Grafana"></a>8.2.7 安装 InfluxDB 和 Grafana</h3><h4 id="安装-InfluxDB"><a href="#安装-InfluxDB" class="headerlink" title="安装 InfluxDB"></a>安装 InfluxDB</h4><h4 id="安装-Grafana"><a href="#安装-Grafana" class="headerlink" title="安装 Grafana"></a>安装 Grafana</h4><h3 id="8-2-8-配置-Grafana-展示监控数据"><a href="#8-2-8-配置-Grafana-展示监控数据" class="headerlink" title="8.2.8 配置 Grafana 展示监控数据"></a>8.2.8 配置 Grafana 展示监控数据</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/f66iAMz">https://t.zsxq.com/f66iAMz</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="8-2-9-小结与反思"><a href="#8-2-9-小结与反思" class="headerlink" title="8.2.9 小结与反思"></a>8.2.9 小结与反思</h3><p>本节讲了如何利用 API 去获取监控数据，对 Metrics 的类型进行介绍，然后还介绍了怎么利用 Reporter 去将 Metrics 数据进行上报，并通过 InfluxDB + Grafana 搭建了一套 Flink 的监控系统。另外你还可以根据公司的需要使用其他的存储方案来存储监控数据，Grafana 也支持不同的数据源，你们公司的监控系统架构是怎么样的，是否可以直接接入这套监控系统？</p><p>作业部署上线后的监控尤其重要，虽说 Flink UI 自身提供了不少的监控信息，但是个人觉得还是比较弱，还是得去搭建一套完整的监控系统去监控 Flink 中的 JobManager、TaskManager 和作业。本章中讲解了 Flink UI 上获取监控数据的方式，还讲解了如何利用 Flink 自带的 Metrics Reporter 去采集各种监控数据，从而利用时序数据库存储这些监控数据，最后用 Grafana 这种可视化比较好的去展示这些监控数据，从而达到作业真正的监控运维效果。</p><p>整套监控系统也希望你可以运用在你们公司，当然你不一定非得选用相同的存储时序数据库，这样可以为你们节省不少作业出问题后的排查时间。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;8-2-搭建一套-Flink-监控系统&quot;&gt;&lt;a href=&quot;#8-2-搭建一套-Flink-监控系统&quot; class=&quot;headerlink&quot; title=&quot;8.2 搭建一套 Flink 监控系统&quot;&gt;&lt;/a&gt;8.2 搭建一套 Flink 监控系统&lt;/h2&gt;&lt;p&gt;8.1 节中讲解了 JobManager、TaskManager 和 Flink Job 的监控，以及需要关注的监控指标有哪些。本节带大家讲解一下如何搭建一套完整的 Flink 监控系统，如果你所在的公司没有专门的监控平台，那么可以根据本节的内容来为公司搭建一套属于自己公司的 Flink 监控系统。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何实时监控 Flink 及其作业？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/05/flink-in-action-8.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/05/flink-in-action-8.1/</id>
    <published>2021-08-04T16:00:00.000Z</published>
    <updated>2022-01-16T12:20:27.508Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第八章-——-Flink-监控"><a href="#第八章-——-Flink-监控" class="headerlink" title="第八章 —— Flink 监控"></a>第八章 —— Flink 监控</h1><p>Flink 相关的组件和作业的稳定性通常是比较关键的，所以得需要对它们进行监控，如果有异常，则需要及时告警通知。本章先会教会教会大家如何利用现有 Flink UI 上面的信息去发现和排查问题，会指明一些比较重要和我们非常关心的指标，通过这些指标我们能够立马定位到问题的根本原因。接着笔者会教大家如何去利用现有的 Metrics Reporter 去构建一个 Flink 的监控系统，它可以收集到所有作业的监控指标，并会存储这些监控指标数据，最后还会有一个监控大盘做数据可视化，通过这个大盘可以方便排查问题。</p><h2 id="8-1-实时监控-Flink-及其作业"><a href="#8-1-实时监控-Flink-及其作业" class="headerlink" title="8.1 实时监控 Flink 及其作业"></a>8.1 实时监控 Flink 及其作业</h2><a id="more"></a><p>当将 Flink JobManager、TaskManager 都运行起来了，并且也部署了不少 Flink Job，那么它到底是否还在运行、运行的状态如何、资源 TaskManager 和 Slot 的个数是否足够、Job 内部是否出现异常、计算速度是否跟得上数据生产的速度 等这些问题其实对我们来说是比较关注的，所以就很迫切的需要一个监控系统帮我们把整个 Flink 集群的运行状态给展示出来。通过监控系统我们能够很好的知道 Flink 内部的整个运行状态，然后才能够根据项目生产环境遇到的问题 ‘对症下药’。下面分别来讲下 JobManager、TaskManager、Flink Job 的监控以及最关心的一些监控指标。</p><h3 id="8-1-1-监控-JobManager"><a href="#8-1-1-监控-JobManager" class="headerlink" title="8.1.1 监控 JobManager"></a>8.1.1 监控 JobManager</h3><p>我们知道 JobManager 是 Flink 集群的中控节点，类似于 Apache Storm 的 Nimbus 以及 Apache Spark 的 Driver 的角色。它负责作业的调度、作业 Jar 包的管理、Checkpoint 的协调和发起、与 TaskManager 之间的心跳检查等工作。如果 JobManager 出现问题的话，就会导致作业 UI 信息查看不了，TaskManager 和所有运行的作业都会受到一定的影响，所以这也是为啥在 7.1 节中强调 JobManager 的高可用问题。</p><p>在 Flink 自带的 UI 上 JobManager 那个 Tab 展示的其实并没有显示其对应的 Metrics，那么对于 JobManager 来说常见比较关心的监控指标有哪些呢？</p><h4 id="基础指标"><a href="#基础指标" class="headerlink" title="基础指标"></a>基础指标</h4><p>因为 Flink JobManager 其实也是一个 Java 的应用程序，那么它自然也会有 Java 应用程序的指标，比如内存、CPU、GC、类加载、线程信息等。</p><ul><li>内存：内存又分堆内存和非堆内存，在 Flink 中还有 Direct 内存，每种内存又有初始值、使用值、最大值等指标，因为在 JobManager 中的工作其实相当于 TaskManager 来说比较少，也不存储事件数据，所以通常 JobManager 占用的内存不会很多，在 Flink JobManager 中自带的内存 Metrics 指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_Memory_Direct_Count</span><br><span class="line">jobmanager_Status_JVM_Memory_Direct_MemoryUsed</span><br><span class="line">jobmanager_Status_JVM_Memory_Direct_TotalCapacity</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Committed</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Max</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Used</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_Count</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_MemoryUsed</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_TotalCapacity</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Committed</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Max</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Used</span><br></pre></td></tr></table></figure><ul><li>CPU：JobManager 分配的 CPU 使用情况，如果使用类似 K8S 等资源调度系统，则需要对每个容器进行设置资源，比如 CPU 限制不能超过多少，在 Flink JobManager 中自带的 CPU 指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_CPU_Load</span><br><span class="line">jobmanager_Status_JVM_CPU_Time</span><br></pre></td></tr></table></figure><ul><li>GC：GC 信息对于 Java 应用来说是避免不了的，每种 GC 都有时间和次数的指标可以供参考，提供的指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_MarkSweep_Count</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_MarkSweep_Time</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_Scavenge_Count</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_Scavenge_Time</span><br></pre></td></tr></table></figure><h4 id="Checkpoint-指标"><a href="#Checkpoint-指标" class="headerlink" title="Checkpoint 指标"></a>Checkpoint 指标</h4><p>因为 JobManager 负责了作业的 Checkpoint 的协调和发起功能，所以 Checkpoint 相关的指标就有表示 Checkpoint 执行的时间、Checkpoint 的时间长短、完成的 Checkpoint 的次数、Checkpoint 失败的次数、Checkpoint 正在执行 Checkpoint 的个数等，其对应的指标如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_job_lastCheckpointAlignmentBuffered</span><br><span class="line">jobmanager_job_lastCheckpointDuration</span><br><span class="line">jobmanager_job_lastCheckpointExternalPath</span><br><span class="line">jobmanager_job_lastCheckpointRestoreTimestamp</span><br><span class="line">jobmanager_job_lastCheckpointSize</span><br><span class="line">jobmanager_job_numberOfCompletedCheckpoints</span><br><span class="line">jobmanager_job_numberOfFailedCheckpoints</span><br><span class="line">jobmanager_job_numberOfInProgressCheckpoints</span><br><span class="line">jobmanager_job_totalNumberOfCheckpoints</span><br></pre></td></tr></table></figure><h4 id="重要的指标"><a href="#重要的指标" class="headerlink" title="重要的指标"></a>重要的指标</h4><p>另外还有比较重要的指标就是 Flink UI 上也提供的，类似于 Slot 总共个数、Slot 可使用的个数、TaskManager 的个数（通过查看该值可以知道是否有 TaskManager 发生异常重启）、正在运行的作业数量、作业运行的时间和完成的时间、作业的重启次数，对应的指标如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_job_uptime</span><br><span class="line">jobmanager_numRegisteredTaskManagers</span><br><span class="line">jobmanager_numRunningJobs</span><br><span class="line">jobmanager_taskSlotsAvailable</span><br><span class="line">jobmanager_taskSlotsTotal</span><br><span class="line">jobmanager_job_downtime</span><br><span class="line">jobmanager_job_fullRestarts</span><br><span class="line">jobmanager_job_restartingTime</span><br></pre></td></tr></table></figure><h3 id="8-1-2-监控-TaskManager"><a href="#8-1-2-监控-TaskManager" class="headerlink" title="8.1.2 监控 TaskManager"></a>8.1.2 监控 TaskManager</h3><p>….</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">taskmanager_Status_JVM_CPU_Load</span><br><span class="line">taskmanager_Status_JVM_CPU_Time</span><br><span class="line">taskmanager_Status_JVM_ClassLoader_ClassesLoaded</span><br><span class="line">taskmanager_Status_JVM_ClassLoader_ClassesUnloaded</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Old_Generation_Count</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Old_Generation_Time</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Young_Generation_Count</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Young_Generation_Time</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_Count</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_MemoryUsed</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_TotalCapacity</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Committed</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Max</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Used</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_Count</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_MemoryUsed</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_TotalCapacity</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Committed</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Max</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Used</span><br><span class="line">taskmanager_Status_JVM_Threads_Count</span><br><span class="line">taskmanager_Status_Network_AvailableMemorySegments</span><br><span class="line">taskmanager_Status_Network_TotalMemorySegments</span><br><span class="line">taskmanager_Status_Shuffle_Netty_AvailableMemorySegments</span><br><span class="line">taskmanager_Status_Shuffle_Netty_TotalMemorySegments</span><br></pre></td></tr></table></figure><h3 id="8-1-3-监控-Flink-作业"><a href="#8-1-3-监控-Flink-作业" class="headerlink" title="8.1.3 监控 Flink 作业"></a>8.1.3 监控 Flink 作业</h3><p>…</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">taskmanager_job_task_Shuffle_Netty_Input_Buffers_outPoolUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Input_Buffers_outputQueueLength</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inPoolUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputExclusiveBuffersUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputFloatingBuffersUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputQueueLength</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInLocal</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInLocalPerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInRemote</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInRemotePerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInLocal</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInLocalPerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInRemote</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInRemotePerSecond</span><br><span class="line">taskmanager_job_task_buffers_inPoolUsage</span><br><span class="line">taskmanager_job_task_buffers_inputExclusiveBuffersUsage</span><br><span class="line">taskmanager_job_task_buffers_inputFloatingBuffersUsage</span><br><span class="line">taskmanager_job_task_buffers_inputQueueLength</span><br><span class="line">taskmanager_job_task_buffers_outPoolUsage</span><br><span class="line">taskmanager_job_task_buffers_outputQueueLength</span><br><span class="line">taskmanager_job_task_checkpointAlignmentTime</span><br><span class="line">taskmanager_job_task_currentInputWatermark</span><br><span class="line">taskmanager_job_task_numBuffersInLocal</span><br><span class="line">taskmanager_job_task_numBuffersInLocalPerSecond</span><br><span class="line">taskmanager_job_task_numBuffersInRemote</span><br><span class="line">taskmanager_job_task_numBuffersInRemotePerSecond</span><br><span class="line">taskmanager_job_task_numBuffersOut</span><br><span class="line">taskmanager_job_task_numBuffersOutPerSecond</span><br><span class="line">taskmanager_job_task_numBytesIn</span><br><span class="line">taskmanager_job_task_numBytesInLocal</span><br><span class="line">taskmanager_job_task_numBytesInLocalPerSecond</span><br><span class="line">taskmanager_job_task_numBytesInPerSecond</span><br><span class="line">taskmanager_job_task_numBytesInRemote</span><br><span class="line">taskmanager_job_task_numBytesInRemotePerSecond</span><br><span class="line">taskmanager_job_task_numBytesOut</span><br><span class="line">taskmanager_job_task_numBytesOutPerSecond</span><br><span class="line">taskmanager_job_task_numRecordsIn</span><br><span class="line">taskmanager_job_task_numRecordsInPerSecond</span><br><span class="line">taskmanager_job_task_numRecordsOut</span><br><span class="line">taskmanager_job_task_numRecordsOutPerSecond</span><br><span class="line">taskmanager_job_task_operator_currentInputWatermark</span><br><span class="line">taskmanager_job_task_operator_currentOutputWatermark</span><br><span class="line">taskmanager_job_task_operator_numLateRecordsDropped</span><br><span class="line">taskmanager_job_task_operator_numRecordsIn</span><br><span class="line">taskmanager_job_task_operator_numRecordsInPerSecond</span><br><span class="line">taskmanager_job_task_operator_numRecordsOut</span><br><span class="line">taskmanager_job_task_operator_numRecordsOutPerSecond</span><br></pre></td></tr></table></figure><h3 id="8-1-4-最关心的性能指标"><a href="#8-1-4-最关心的性能指标" class="headerlink" title="8.1.4 最关心的性能指标"></a>8.1.4 最关心的性能指标</h3><h4 id="JobManager"><a href="#JobManager" class="headerlink" title="JobManager"></a>JobManager</h4><h4 id="TaskManager"><a href="#TaskManager" class="headerlink" title="TaskManager"></a>TaskManager</h4><h4 id="Flink-Job"><a href="#Flink-Job" class="headerlink" title="Flink Job"></a>Flink Job</h4><h3 id="8-1-5-小结与反思"><a href="#8-1-5-小结与反思" class="headerlink" title="8.1.5 小结与反思"></a>8.1.5 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/f66iAMz">https://t.zsxq.com/f66iAMz</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第八章-——-Flink-监控&quot;&gt;&lt;a href=&quot;#第八章-——-Flink-监控&quot; class=&quot;headerlink&quot; title=&quot;第八章 —— Flink 监控&quot;&gt;&lt;/a&gt;第八章 —— Flink 监控&lt;/h1&gt;&lt;p&gt;Flink 相关的组件和作业的稳定性通常是比较关键的，所以得需要对它们进行监控，如果有异常，则需要及时告警通知。本章先会教会教会大家如何利用现有 Flink UI 上面的信息去发现和排查问题，会指明一些比较重要和我们非常关心的指标，通过这些指标我们能够立马定位到问题的根本原因。接着笔者会教大家如何去利用现有的 Metrics Reporter 去构建一个 Flink 的监控系统，它可以收集到所有作业的监控指标，并会存储这些监控指标数据，最后还会有一个监控大盘做数据可视化，通过这个大盘可以方便排查问题。&lt;/p&gt;
&lt;h2 id=&quot;8-1-实时监控-Flink-及其作业&quot;&gt;&lt;a href=&quot;#8-1-实时监控-Flink-及其作业&quot; class=&quot;headerlink&quot; title=&quot;8.1 实时监控 Flink 及其作业&quot;&gt;&lt;/a&gt;8.1 实时监控 Flink 及其作业&lt;/h2&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 作业如何在 Standalone、YARN、Mesos、K8S 上部署运行？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/04/flink-in-action-7.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/04/flink-in-action-7.2/</id>
    <published>2021-08-03T16:00:00.000Z</published>
    <updated>2022-01-16T12:17:22.975Z</updated>
    
    <content type="html"><![CDATA[<h2 id="7-2-Flink-作业如何在-Standalone、YARN、Mesos、K8S-上部署运行？"><a href="#7-2-Flink-作业如何在-Standalone、YARN、Mesos、K8S-上部署运行？" class="headerlink" title="7.2 Flink 作业如何在 Standalone、YARN、Mesos、K8S 上部署运行？"></a>7.2 Flink 作业如何在 Standalone、YARN、Mesos、K8S 上部署运行？</h2><p>前面章节已经有很多学习案列带大家使用 Flink，不仅有讲将 Flink 应用程序在 IDEA 中运行，也有讲将 Flink Job 编译打包上传到 Flink UI 上运行，在这 UI 背后可能是通过 Standalone、YARN、Mesos、Kubernetes 等运行启动的 Flink。那么这节就系统讲下如何部署和运行我们的 Flink Job，大家可以根据自己公司的场景进行选择使用哪种方式进行部署 Flink 作业！</p><a id="more"></a><h3 id="7-2-1-Standalone"><a href="#7-2-1-Standalone" class="headerlink" title="7.2.1 Standalone"></a>7.2.1 Standalone</h3><p>第一种方式就是 Standalone 模式，这种模式笔者在前面 2.2 节里面演示的就是这种，我们通过执行命令：<code>./bin/start-cluster.sh</code> 启动一个 Flink Standalone 集群。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zhisheng@zhisheng  /usr/local/flink-1.9.0  ./bin/start-cluster.sh</span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host zhisheng.</span><br><span class="line">Starting taskexecutor daemon on host zhisheng.</span><br></pre></td></tr></table></figure><p>默认的话是启动一个 JobManager 和一个 TaskManager，我们可以通过 <code>jps</code> 查看进程有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">65425 Jps</span><br><span class="line">51572 TaskManagerRunner</span><br><span class="line">51142 StandaloneSessionClusterEntrypoint</span><br></pre></td></tr></table></figure><p>其中上面的 TaskManagerRunner 代表的是 TaskManager 进程，StandaloneSessionClusterEntrypoint 代表的是 JobManager 进程。上面运行产生的只有一个 JobManager 和一个 TaskManager，如果是生产环境的话，这样的配置肯定是不够运行多个 Job 的，那么我们该如何在生产环境中配置 standalone 模式的集群呢？我们就需要修改 Flink 安装目录下面的 conf 文件夹里面配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flink-conf.yaml</span><br><span class="line">masters</span><br><span class="line">slaves</span><br></pre></td></tr></table></figure><p>将 slaves 中再添加一个 <code>localhost</code>，这样就可以启动两个 TaskManager 了。接着启动脚本 <code>start-cluster.sh</code>，启动日志显示如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-161333.png" alt=""></p><p>可以看见有两个 TaskManager 启动了，再看下 UI 显示的也是有两个 TaskManager，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-161431.png" alt=""></p><p>那么如果还想要添加一个 JobManager 或者 TaskManager 怎么办？总不能再次重启修改配置文件后然后再重启吧！这里你可以这样操作。</p><p><strong>增加一个 JobManager</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/jobmanager.sh ((start|start-foreground) [host] [webui-port])|stop|stop-all</span><br></pre></td></tr></table></figure><p>但是注意 Standalone 下一台机器最多只能运行一个 JobManager。</p><p><strong>增加一个 TaskManager</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/taskmanager.sh start|start-foreground|stop|stop-all</span><br></pre></td></tr></table></figure><p>比如我执行了 <code>./bin/taskmanager.sh start</code> 命令后，运行结果如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-161657.png" alt=""></p><p>Standalone 模式下可以先对 Flink Job 通过 <code>mvn clean package</code> 编译打包，得到 Jar 包后，可以在 UI 上直接上传 Jar 包，然后点击 Submit 就可以运行了。</p><h3 id="7-2-2-YARN"><a href="#7-2-2-YARN" class="headerlink" title="7.2.2 YARN"></a>7.2.2 YARN</h3><h3 id="7-2-3-Mesos"><a href="#7-2-3-Mesos" class="headerlink" title="7.2.3 Mesos"></a>7.2.3 Mesos</h3><h4 id="Session-集群"><a href="#Session-集群" class="headerlink" title="Session 集群"></a>Session 集群</h4><h4 id="Per-Job-集群"><a href="#Per-Job-集群" class="headerlink" title="Per Job 集群"></a>Per Job 集群</h4><h3 id="7-3-4-Kubernetes"><a href="#7-3-4-Kubernetes" class="headerlink" title="7.3.4 Kubernetes"></a>7.3.4 Kubernetes</h3><h3 id="7-2-5-小结与反思"><a href="#7-2-5-小结与反思" class="headerlink" title="7.2.5 小结与反思"></a>7.2.5 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/f66iAMz">https://t.zsxq.com/f66iAMz</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>本章讲解了 Flink 中所有的配置文件，每个配置文件中的配置有啥作用，并且如果在不同环境下配置 JobManager 的高可用，另外还介绍了 Flink 的部署问题，因为 Flink 本身是支持在不同的环境下部署的，比如 Standalone、K8S、YARN、Mesos 等，其中在调度平台上又有 Session 模式和 Per Job 模式，每种模式都有自己的特点，所以你可能需要根据公司的情况来做一定的选型，每种的部署也可能会有点不一样，遇到问题的化还得根据特殊情况进行特殊处理，希望你可以在公司灵活的处理这种问题。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;7-2-Flink-作业如何在-Standalone、YARN、Mesos、K8S-上部署运行？&quot;&gt;&lt;a href=&quot;#7-2-Flink-作业如何在-Standalone、YARN、Mesos、K8S-上部署运行？&quot; class=&quot;headerlink&quot; title=&quot;7.2 Flink 作业如何在 Standalone、YARN、Mesos、K8S 上部署运行？&quot;&gt;&lt;/a&gt;7.2 Flink 作业如何在 Standalone、YARN、Mesos、K8S 上部署运行？&lt;/h2&gt;&lt;p&gt;前面章节已经有很多学习案列带大家使用 Flink，不仅有讲将 Flink 应用程序在 IDEA 中运行，也有讲将 Flink Job 编译打包上传到 Flink UI 上运行，在这 UI 背后可能是通过 Standalone、YARN、Mesos、Kubernetes 等运行启动的 Flink。那么这节就系统讲下如何部署和运行我们的 Flink Job，大家可以根据自己公司的场景进行选择使用哪种方式进行部署 Flink 作业！&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 配置详解及如何配置高可用？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/03/flink-in-action-7.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/03/flink-in-action-7.1/</id>
    <published>2021-08-02T16:00:00.000Z</published>
    <updated>2022-01-16T12:14:17.703Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第七章-——-Flink-作业环境部署"><a href="#第七章-——-Flink-作业环境部署" class="headerlink" title="第七章 —— Flink 作业环境部署"></a>第七章 —— Flink 作业环境部署</h1><p>在第一章中介绍过 Flink 是可以以多种方式部署的，比如 Standalone、YARN、Mesos、K8S。本章将先对 Flink 中的所有配置文件做一个详细的讲解，接下来将讲解 JobManager 高可用部署相关的配置，最后会分别讲解如何在不同的平台上部署运行 Flink 作业。虽然在你们公司可能只会用到其中的一种，但是仍然建议你将每种方式都熟悉一下。</p><h2 id="7-1-Flink-配置详解及如何配置高可用？"><a href="#7-1-Flink-配置详解及如何配置高可用？" class="headerlink" title="7.1 Flink 配置详解及如何配置高可用？"></a>7.1 Flink 配置详解及如何配置高可用？</h2><a id="more"></a><p>在讲解如何部署 Flink 作业（在 7.2 节中会讲）之前，先来详细的看一下 Flink 中的所有配置文件以及文件中的各种配置代表的内容，这样对于后面部署和调优 Flink 作业有一定的帮助。</p><h3 id="7-1-1-Flink-配置详解"><a href="#7-1-1-Flink-配置详解" class="headerlink" title="7.1.1 Flink 配置详解"></a>7.1.1 Flink 配置详解</h3><p>先来看下 Flink 配置文件目录中最重要的配置文件 <code>flink-conf.yaml</code> 的配置。</p><h4 id="flink-conf-yaml"><a href="#flink-conf-yaml" class="headerlink" title="flink-conf.yaml"></a>flink-conf.yaml</h4><p>基础配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># jobManager 的IP地址</span><br><span class="line">jobmanager.rpc.address: localhost</span><br><span class="line"></span><br><span class="line"># JobManager 的端口号</span><br><span class="line">jobmanager.rpc.port: 6123</span><br><span class="line"></span><br><span class="line"># JobManager JVM heap 内存大小</span><br><span class="line">jobmanager.heap.size: 1024m</span><br><span class="line"></span><br><span class="line"># TaskManager JVM heap 内存大小</span><br><span class="line">taskmanager.heap.size: 1024m</span><br><span class="line"></span><br><span class="line"># 每个 TaskManager 提供的任务 slots 数量大小</span><br><span class="line">taskmanager.numberOfTaskSlots: 1</span><br><span class="line"></span><br><span class="line"># 程序默认并行计算的个数</span><br><span class="line">parallelism.default: 1</span><br><span class="line"></span><br><span class="line"># 文件系统来源</span><br><span class="line"># fs.default-scheme</span><br></pre></td></tr></table></figure><p>高可用性相关的配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 可以选择 &apos;NONE&apos; 或者 &apos;zookeeper&apos;.</span><br><span class="line"># high-availability: zookeeper</span><br><span class="line"></span><br><span class="line"># 文件系统路径，让 Flink 在高可用性设置中持久保存元数据</span><br><span class="line"># high-availability.storageDir: hdfs:///flink/ha/</span><br><span class="line"></span><br><span class="line"># zookeeper 集群中仲裁者的机器 ip 和 port 端口号</span><br><span class="line"># high-availability.zookeeper.quorum: localhost:2181</span><br><span class="line"></span><br><span class="line"># 默认是 open，如果 zookeeper security 启用了该值会更改成 creator</span><br><span class="line"># high-availability.zookeeper.client.acl: open</span><br></pre></td></tr></table></figure><p>容错和 Checkpoint 相关的配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 用于存储和检查点状态</span><br><span class="line"># state.backend: filesystem</span><br><span class="line"></span><br><span class="line"># 存储检查点的数据文件和元数据的默认目录</span><br><span class="line"># state.checkpoints.dir: hdfs://namenode-host:port/flink-checkpoints</span><br><span class="line"></span><br><span class="line"># savepoints 的默认目标目录(可选)</span><br><span class="line"># state.savepoints.dir: hdfs://namenode-host:port/flink-checkpoints</span><br><span class="line"></span><br><span class="line"># 用于启用/禁用增量 checkpoints 的标志</span><br><span class="line"># state.backend.incremental: false</span><br></pre></td></tr></table></figure><p>Web 前端相关的配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 基于 Web 的运行时监视器侦听的地址.</span><br><span class="line">#jobmanager.web.address: 0.0.0.0</span><br><span class="line"></span><br><span class="line">#  Web 的运行时监视器端口</span><br><span class="line">rest.port: 8081</span><br><span class="line"></span><br><span class="line"># 是否从基于 Web 的 jobmanager 启用作业提交</span><br><span class="line"># jobmanager.web.submit.enable: false</span><br></pre></td></tr></table></figure><p>高级配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># io.tmp.dirs: /tmp</span><br><span class="line"></span><br><span class="line"># 是否应在 TaskManager 启动时预先分配 TaskManager 管理的内存</span><br><span class="line"># taskmanager.memory.preallocate: false</span><br><span class="line"></span><br><span class="line"># 类加载解析顺序，是先检查用户代码 jar（“child-first”）还是应用程序类路径（“parent-first”）。 默认设置指示首先从用户代码 jar 加载类</span><br><span class="line"># classloader.resolve-order: child-first</span><br><span class="line"></span><br><span class="line"># 用于网络缓冲区的 JVM 内存的分数。 这决定了 TaskManager 可以同时拥有多少流数据交换通道以及通道缓冲的程度。 如果作业被拒绝或者您收到系统没有足够缓冲区的警告，请增加此值或下面的最小/最大值。 另请注意，“taskmanager.network.memory.min”和“taskmanager.network.memory.max”可能会覆盖此分数</span><br><span class="line"># taskmanager.network.memory.fraction: 0.1</span><br><span class="line"># taskmanager.network.memory.min: 67108864</span><br><span class="line"># taskmanager.network.memory.max: 1073741824</span><br></pre></td></tr></table></figure><p>Flink 集群安全配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 指示是否从 Kerberos ticket 缓存中读取</span><br><span class="line"># security.kerberos.login.use-ticket-cache: true</span><br><span class="line"></span><br><span class="line"># 包含用户凭据的 Kerberos 密钥表文件的绝对路径</span><br><span class="line"># security.kerberos.login.keytab: /path/to/kerberos/keytab</span><br><span class="line"></span><br><span class="line"># 与 keytab 关联的 Kerberos 主体名称</span><br><span class="line"># security.kerberos.login.principal: flink-user</span><br><span class="line"></span><br><span class="line"># 以逗号分隔的登录上下文列表，用于提供 Kerberos 凭据（例如，`Client，KafkaClient`使用凭证进行 ZooKeeper 身份验证和 Kafka 身份验证）</span><br><span class="line"># security.kerberos.login.contexts: Client,KafkaClient</span><br></pre></td></tr></table></figure><p>Zookeeper 安全配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 覆盖以下配置以提供自定义 ZK 服务名称</span><br><span class="line"># zookeeper.sasl.service-name: zookeeper</span><br><span class="line"></span><br><span class="line"># 该配置必须匹配 &quot;security.kerberos.login.contexts&quot; 中的列表（含有一个）</span><br><span class="line"># zookeeper.sasl.login-context-name: Client</span><br></pre></td></tr></table></figure><p>HistoryServer 相关的配置如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 你可以通过 bin/historyserver.sh (start|stop) 命令启动和关闭 HistoryServer</span><br><span class="line"></span><br><span class="line"># 将已完成的作业上传到的目录</span><br><span class="line"># jobmanager.archive.fs.dir: hdfs:///completed-jobs/</span><br><span class="line"></span><br><span class="line"># 基于 Web 的 HistoryServer 的地址</span><br><span class="line"># historyserver.web.address: 0.0.0.0</span><br><span class="line"></span><br><span class="line"># 基于 Web 的 HistoryServer 的端口号</span><br><span class="line"># historyserver.web.port: 8082</span><br><span class="line"></span><br><span class="line"># 以逗号分隔的目录列表，用于监视已完成的作业</span><br><span class="line"># historyserver.archive.fs.dir: hdfs:///completed-jobs/</span><br><span class="line"></span><br><span class="line"># 刷新受监控目录的时间间隔（以毫秒为单位）</span><br><span class="line"># historyserver.archive.fs.refresh-interval: 10000</span><br></pre></td></tr></table></figure><h4 id="masters"><a href="#masters" class="headerlink" title="masters"></a>masters</h4><p>masters 配置文件中以 host:port 构成就行，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">localhost:8081</span><br></pre></td></tr></table></figure><h4 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h4><p>slaves 文件里面是每个 worker 节点的 IP/Hostname，每一个 worker 结点之后都会运行一个 TaskManager，一个一行，如下所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">localhost</span><br></pre></td></tr></table></figure><h3 id="7-1-2-Log-的配置"><a href="#7-1-2-Log-的配置" class="headerlink" title="7.1.2 Log 的配置"></a>7.1.2 Log 的配置</h3><p>在 Flink 的日志配置文件（<code>logback.xml</code> 或 <code>log4j.properties</code>）中有配置日志存储的地方，<code>logback.xml</code> 配置日志存储的路径是：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"file"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.FileAppender"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;log.file&#125;<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">append</span>&gt;</span>false<span class="tag">&lt;/<span class="name">append</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;60&#125; %X&#123;sourceThread&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>log4j.properties</code> 和 <code>log4j-cli.properties</code> 的配置日志存储的路径是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log4j.appender.file.file=$&#123;log.file&#125;</span><br></pre></td></tr></table></figure><p>从上面两个配置可以看到日志的路径都是由 <code>log.file</code> 变量控制的，如果系统变量没有配置的话，则会使用 <code>bin／flink</code> 脚本里配置的值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log=$FLINK_LOG_DIR/flink-$FLINK_IDENT_STRING-client-$HOSTNAME.log</span><br><span class="line">log_setting=(-Dlog.file=&quot;$log&quot; -Dlog4j.configuration=file:&quot;$FLINK_CONF_DIR&quot;/log4j-cli.properties -Dlogback.configurationFile=file:&quot;$FLINK_CONF_DIR&quot;/logback.xml)</span><br></pre></td></tr></table></figure><p>从上面可以看到 log 里配置的 FLINK_LOG_DIR 变量是在 bin 目录下的 config.sh 里初始化的。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DEFAULT_FLINK_LOG_DIR=<span class="variable">$FLINK_HOME_DIR_MANGLED</span>/<span class="built_in">log</span></span><br><span class="line">KEY_ENV_LOG_DIR=<span class="string">"env.log.dir"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$&#123;FLINK_LOG_DIR&#125;</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    FLINK_LOG_DIR=$(readFromConfig <span class="variable">$&#123;KEY_ENV_LOG_DIR&#125;</span> <span class="string">"<span class="variable">$&#123;DEFAULT_FLINK_LOG_DIR&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;YAML_CONF&#125;</span>"</span>)</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p>从上面可以知道日志默认就是在 Flink 的 log 目录下，你可以通过在 <code>flink-conf.yaml</code> 配置文件中配置 <code>env.log.dir</code> 参数来更改保存日志的目录。另外通过源码可以发现，如果找不到 <code>log.file</code> 环境变量，则会去找 <code>web.log.path</code> 的配置，但是该配置在 Standalone 下是不起作用的，日志依旧是会在 <code>log</code> 目录，在 YARN 下是会起作用的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> LogFileLocation <span class="title">find</span><span class="params">(Configuration config)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> String logEnv = <span class="string">"log.file"</span>;</span><br><span class="line">    String logFilePath = System.getProperty(logEnv);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (logFilePath == <span class="keyword">null</span>) &#123;</span><br><span class="line">        LOG.warn(<span class="string">"Log file environment variable '&#123;&#125;' is not set."</span>, logEnv);</span><br><span class="line">        logFilePath = config.getString(WebOptions.LOG_PATH); <span class="comment">//该值为 web.log.path</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// not configured, cannot serve log files</span></span><br><span class="line">    <span class="keyword">if</span> (logFilePath == <span class="keyword">null</span> || logFilePath.length() &lt; <span class="number">4</span>) &#123;</span><br><span class="line">        LOG.warn(<span class="string">"JobManager log files are unavailable in the web dashboard. "</span> +</span><br><span class="line">            <span class="string">"Log file location not found in environment variable '&#123;&#125;' or configuration key '&#123;&#125;'."</span>,</span><br><span class="line">            logEnv, WebOptions.LOG_PATH);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> LogFileLocation(<span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    String outFilePath = logFilePath.substring(<span class="number">0</span>, logFilePath.length() - <span class="number">3</span>).concat(<span class="string">"out"</span>);</span><br><span class="line"></span><br><span class="line">    LOG.info(<span class="string">"Determined location of main cluster component log file: &#123;&#125;"</span>, logFilePath);</span><br><span class="line">    LOG.info(<span class="string">"Determined location of main cluster component stdout file: &#123;&#125;"</span>, outFilePath);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> LogFileLocation(resolveFileLocation(logFilePath), resolveFileLocation(outFilePath));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The log file location (may be in /log for standalone but under log directory when using YARN).</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;String&gt; LOG_PATH =</span><br><span class="line">    key(<span class="string">"web.log.path"</span>)</span><br><span class="line">        .noDefaultValue()</span><br><span class="line">        .withDeprecatedKeys(<span class="string">"jobmanager.web.log.path"</span>)</span><br><span class="line">        .withDescription(<span class="string">"Path to the log file (may be in /log for standalone but under log directory when using YARN)."</span>);</span><br></pre></td></tr></table></figure><p>另外可能会在本地 IDE 中运行作业出不来日志的情况，这时请检查是否有添加日志的依赖。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-simple<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="7-1-3-如何配置-JobManager-高可用？"><a href="#7-1-3-如何配置-JobManager-高可用？" class="headerlink" title="7.1.3 如何配置 JobManager 高可用？"></a>7.1.3 如何配置 JobManager 高可用？</h3><p>JobManager 协调每个 Flink 作业的部署，它负责调度和资源管理。默认情况下，每个 Flink 集群只有一个 JobManager 实例，这样就可能会产生单点故障，如果 JobManager 崩溃，则无法提交新作业且运行中的作业也会失败。如果保证 JobManager 的高可用，则可以避免这个问题。下面分别下如何搭建 Standalone 集群和 YARN 集群高可用的 JobManager。</p><h4 id="搭建-Standalone-集群高可用-JobManager"><a href="#搭建-Standalone-集群高可用-JobManager" class="headerlink" title="搭建 Standalone 集群高可用 JobManager"></a>搭建 Standalone 集群高可用 JobManager</h4><p>Standalone 集群的 JobManager 高可用性的概念是：任何时候只有一个主 JobManager 和多个备 JobManager，以便在主节点失败时有新的 JobManager 接管集群。这样就保证了没有单点故障，一旦备 JobManager 接管集群，作业就可以依旧正常运行。主备 JobManager 实例之间没有明确的区别，每个 JobManager 都可以充当主备节点。例如，请考虑以下三个 JobManager 实例的设置。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/lsiuRC.jpg" alt=""></p><p><strong>如何配置</strong></p><p>要启用 JobManager 高可用性功能，首先必须在配置文件 flink-conf.yaml 中将高可用性模式设置为 ZooKeeper，配置 ZooKeeper quorum，将所有 JobManager 主机及其 Web UI 端口写入配置文件。每个 ip:port 都是一个 ZooKeeper 服务器的 ip 及其端口，Flink 可以通过指定的地址和端口访问 ZooKeeper。另外就是高可用存储目录，JobManager 元数据保存在 <code>high-availability.storageDir</code> 指定的文件系统中，在 ZooKeeper 中仅保存了指向此状态的指针, 推荐这个目录是 HDFS、S3、Ceph、NFS 等，该文件系统中保存了 JobManager 恢复状态需要的所有元数据。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">high-availability: zookeeper</span><br><span class="line">high-availability.zookeeper.quorum: ip1:2181 [,...],ip2:2181</span><br><span class="line">high-availability.storageDir: hdfs:///flink/ha/</span><br></pre></td></tr></table></figure><p>Flink 利用 ZooKeeper 在所有正在运行的 JobManager 实例之间进行分布式协调。ZooKeeper 是独立于 Flink 的服务，通过 leader 选举和轻量级一致性状态存储提供高可靠的分布式协调服务。Flink 包含用于 Bootstrap ZooKeeper 安装的脚本。<br>它在我们的 Flink 安装路径下面 /conf/zoo.cfg 。</p><h4 id="搭建-YARN-集群高可用-JobManager"><a href="#搭建-YARN-集群高可用-JobManager" class="headerlink" title="搭建 YARN 集群高可用 JobManager"></a>搭建 YARN 集群高可用 JobManager</h4><h3 id="7-1-4-小结与反思"><a href="#7-1-4-小结与反思" class="headerlink" title="7.1.4 小结与反思"></a>7.1.4 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/f66iAMz">https://t.zsxq.com/f66iAMz</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第七章-——-Flink-作业环境部署&quot;&gt;&lt;a href=&quot;#第七章-——-Flink-作业环境部署&quot; class=&quot;headerlink&quot; title=&quot;第七章 —— Flink 作业环境部署&quot;&gt;&lt;/a&gt;第七章 —— Flink 作业环境部署&lt;/h1&gt;&lt;p&gt;在第一章中介绍过 Flink 是可以以多种方式部署的，比如 Standalone、YARN、Mesos、K8S。本章将先对 Flink 中的所有配置文件做一个详细的讲解，接下来将讲解 JobManager 高可用部署相关的配置，最后会分别讲解如何在不同的平台上部署运行 Flink 作业。虽然在你们公司可能只会用到其中的一种，但是仍然建议你将每种方式都熟悉一下。&lt;/p&gt;
&lt;h2 id=&quot;7-1-Flink-配置详解及如何配置高可用？&quot;&gt;&lt;a href=&quot;#7-1-Flink-配置详解及如何配置高可用？&quot; class=&quot;headerlink&quot; title=&quot;7.1 Flink 配置详解及如何配置高可用？&quot;&gt;&lt;/a&gt;7.1 Flink 配置详解及如何配置高可用？&lt;/h2&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 扩展库——Gelly</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/02/flink-in-action-6.5/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/02/flink-in-action-6.5/</id>
    <published>2021-08-01T16:00:00.000Z</published>
    <updated>2021-12-26T11:40:16.522Z</updated>
    
    <content type="html"><![CDATA[<h2 id="6-5-Flink-扩展库——Gelly"><a href="#6-5-Flink-扩展库——Gelly" class="headerlink" title="6.5 Flink 扩展库——Gelly"></a>6.5 Flink 扩展库——Gelly</h2><p>在 1.9 版本中还剩最后一个扩展库就是 Gelly，本节将带你了解一下 Gelly 的功能以及如何使用。</p><a id="more"></a><h3 id="6-5-1-Gelly-简介"><a href="#6-5-1-Gelly-简介" class="headerlink" title="6.5.1 Gelly 简介"></a>6.5.1 Gelly 简介</h3><p>Gelly 是 Flink 的图 API 库，它包含了一组旨在简化 Flink 中图形分析应用程序开发的方法和实用程序。在 Gelly 中，可以使用类似于批处理 API 提供的高级函数来转换和修改图。Gelly 提供了创建、转换和修改图的方法以及图算法库。</p><h3 id="6-5-2-使用-Gelly"><a href="#6-5-2-使用-Gelly" class="headerlink" title="6.5.2 使用 Gelly"></a>6.5.2 使用 Gelly</h3><p>因为 Gelly 是 Flink 项目中库的一部分，它本身不在 Flink 的二进制包中，所以运行 Gelly 项目（Java 应用程序）是需要将 <code>opt/flink-gelly_2.11-1.9.0.jar</code> 移动到 <code>lib</code> 目录中，如果是 Scala 应用程序则需要将 <code>opt/flink-gelly-scala_2.11-1.9.0.jar</code> 移动到 <code>lib</code> 中，接着运行下面的命令就可以运行一个 flink-gelly-examples 项目。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run examples/gelly/flink-gelly-examples_2.11-1.9.0.jar \</span><br><span class="line">    --algorithm GraphMetrics --order directed \</span><br><span class="line">    --input RMatGraph --type integer --scale 20 --simplify directed \</span><br><span class="line">    --output print</span><br></pre></td></tr></table></figure><p>接下来可以在 UI 上看到运行的结果如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-155600.png" alt=""></p><p>如果是自己创建的 Gelly Java 应用程序，则需要添加如下依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-gelly_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>如果是 Gelly Scala 应用程序，添加下面的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-gelly-scala_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="6-5-3-Gelly-API"><a href="#6-5-3-Gelly-API" class="headerlink" title="6.5.3 Gelly API"></a>6.5.3 Gelly API</h3><p>引入好依赖后，接着将介绍一下 Gelly 该如何使用。</p><h4 id="Graph-介绍"><a href="#Graph-介绍" class="headerlink" title="Graph 介绍"></a>Graph 介绍</h4><p>在 Gelly 中，一个图（Graph）由顶点的数据集（DataSet）和边的数据集（DataSet）组成。图中的顶点由 Vertex 类型来表示，一个 Vertex 由唯一的 ID 和一个值来表示。其中 Vertex 的 ID 必须是全局唯一的值，且实现了 Comparable 接口。如果节点不需要由任何值，则该值类型可以声明成 NullValue 类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建一个 Vertex&lt;Long，String&gt;</span></span><br><span class="line">Vertex&lt;Long, String&gt; v = <span class="keyword">new</span> Vertex&lt;Long, String&gt;(<span class="number">1L</span>, <span class="string">"foo"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建一个 Vertex&lt;Long，NullValue&gt;</span></span><br><span class="line">Vertex&lt;Long, NullValue&gt; v = <span class="keyword">new</span> Vertex&lt;Long, NullValue&gt;(<span class="number">1L</span>, NullValue.getInstance());</span><br></pre></td></tr></table></figure><p>Graph 中的边由 Edge 类型来表示，一个 Edge 通常由源顶点的 ID，目标顶点的 ID 以及一个可选的值来表示。其中源顶点和目标顶点的类型必须与 Vertex 的 ID 类型相同。同样的，如果边不需要由任何值，则该值类型可以声明成 NullValue 类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Edge&lt;Long, Double&gt; e = <span class="keyword">new</span> Edge&lt;Long, Double&gt;(<span class="number">1L</span>, <span class="number">2L</span>, <span class="number">0.5</span>);</span><br><span class="line"><span class="comment">//反转此 edge 的源和目标</span></span><br><span class="line">Edge&lt;Long, Double&gt; reversed = e.reverse();</span><br><span class="line">Double weight = e.getValue(); <span class="comment">// weight = 0.5</span></span><br></pre></td></tr></table></figure><p>在 Gelly 中，一个 Edge 总是从源顶点指向目标顶点。如果图中每条边都能匹配一个从目标顶点到源顶点的 Edge，那么这个图可能是个无向图。同样地，无向图可以用这个方式来表示。</p><h4 id="创建-Graph"><a href="#创建-Graph" class="headerlink" title="创建 Graph"></a>创建 Graph</h4><p>可以通过以下几种方式创建一个 Graph：</p><ul><li>从一个 Edge 数据集合和一个 Vertex 数据集合中创建图。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataSet&lt;Vertex&lt;String, Long&gt;&gt; vertices = ...</span><br><span class="line">DataSet&lt;Edge&lt;String, Double&gt;&gt; edges = ...</span><br><span class="line"></span><br><span class="line">Graph&lt;String, Long, Double&gt; graph = Graph.fromDataSet(vertices, edges, env);</span><br></pre></td></tr></table></figure><ul><li>从一个表示边的 Tuple2 数据集合中创建图。Gelly 会将每个 Tuple2 转换成一个 Edge，其中第一个元素表示源顶点的 ID，第二个元素表示目标顶点的 ID，图中的顶点和边的 value 值均被设置为 NullValue。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataSet&lt;Tuple2&lt;String, String&gt;&gt; edges = ...</span><br><span class="line"></span><br><span class="line">Graph&lt;String, NullValue, NullValue&gt; graph = Graph.fromTuple2DataSet(edges, env);</span><br></pre></td></tr></table></figure><ul><li>从一个 Tuple3 数据集和一个可选的 Tuple2 数据集中生成图。在这种情况下，Gelly 会将每个 Tuple3 转换成 Edge，其中第一个元素域是源顶点 ID，第二个域是目标顶点 ID，第三个域是边的值。同样的，每个 Tuple2 会转换成一个顶点 Vertex，其中第一个域是顶点的 ID，第二个域是顶点的 value。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataSet&lt;Tuple2&lt;String, Long&gt;&gt; vertexTuples = env.readCsvFile(<span class="string">"path/to/vertex/input"</span>).types(String.class, Long.class);</span><br><span class="line"></span><br><span class="line">DataSet&lt;Tuple3&lt;String, String, Double&gt;&gt; edgeTuples = env.readCsvFile(<span class="string">"path/to/edge/input"</span>).types(String.class, String.class, Double.class);</span><br><span class="line"></span><br><span class="line">Graph&lt;String, Long, Double&gt; graph = Graph.fromTupleDataSet(vertexTuples, edgeTuples, env);</span><br></pre></td></tr></table></figure><ul><li>从一个表示边数据的CSV文件和一个可选的表示节点的CSV文件中生成图。在这种情况下，Gelly会将表示边的CSV文件中的每一行转换成一个Edge，其中第一个域表示源顶点ID，第二个域表示目标顶点ID，第三个域表示边的值。同样的，表示节点的CSV中的每一行都被转换成一个Vertex，其中第一个域表示顶点的ID，第二个域表示顶点的值。为了通过GraphCsvReader生成图，需要指定每个域的类型，可以使用 types、edgeTypes、vertexTypes、keyType 中的方法。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建一个具有字符串 Vertex id、Long Vertex 和双边缘的图</span></span><br><span class="line">Graph&lt;String, Long, Double&gt; graph = Graph.fromCsvReader(<span class="string">"path/to/vertex/input"</span>, <span class="string">"path/to/edge/input"</span>, env)</span><br><span class="line">                    .types(String.class, Long.class, Double.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建一个既没有顶点值也没有边值的图</span></span><br><span class="line">Graph&lt;Long, NullValue, NullValue&gt; simpleGraph = Graph.fromCsvReader(<span class="string">"path/to/edge/input"</span>, env).keyType(Long.class);</span><br></pre></td></tr></table></figure><ul><li>从一个边的集合和一个可选的顶点的集合中生成图。如果在图创建的时候顶点的集合没有传入，Gelly 会依据数据的边数据集合自动地生成一个 Vertex 集合。这种情况下，创建的节点是没有值的。或者也可以像下面一样，在创建图的时候提供一个 MapFunction 方法来初始化节点的值。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Vertex&lt;Long, Long&gt;&gt; vertexList = <span class="keyword">new</span> ArrayList...</span><br><span class="line"></span><br><span class="line">List&lt;Edge&lt;Long, String&gt;&gt; edgeList = <span class="keyword">new</span> ArrayList...</span><br><span class="line"></span><br><span class="line">Graph&lt;Long, Long, String&gt; graph = Graph.fromCollection(vertexList, edgeList, env);</span><br><span class="line"></span><br><span class="line"><span class="comment">//将顶点值初始化为顶点ID</span></span><br><span class="line">Graph&lt;Long, Long, String&gt; graph = Graph.fromCollection(edgeList,</span><br><span class="line">                <span class="keyword">new</span> MapFunction&lt;Long, Long&gt;() &#123;</span><br><span class="line">                    <span class="function"><span class="keyword">public</span> Long <span class="title">map</span><span class="params">(Long value)</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> value;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, env);</span><br></pre></td></tr></table></figure><h4 id="Graph-属性"><a href="#Graph-属性" class="headerlink" title="Graph 属性"></a>Graph 属性</h4><p>Gelly 提供了下列方法来查询图的属性和指标：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DataSet&lt;Vertex&lt;K, VV&gt;&gt; getVertices()</span><br><span class="line"><span class="comment">//获取边缘数据集</span></span><br><span class="line">DataSet&lt;Edge&lt;K, EV&gt;&gt; getEdges()</span><br><span class="line"><span class="comment">//获取顶点的 id 数据集</span></span><br><span class="line"><span class="function">DataSet&lt;K&gt; <span class="title">getVertexIds</span><span class="params">()</span></span></span><br><span class="line"><span class="function">DataSet&lt;Tuple2&lt;K, K&gt;&gt; <span class="title">getEdgeIds</span><span class="params">()</span></span></span><br><span class="line"><span class="function">DataSet&lt;Tuple2&lt;K, LongValue&gt;&gt; <span class="title">inDegrees</span><span class="params">()</span></span></span><br><span class="line"><span class="function">DataSet&lt;Tuple2&lt;K, LongValue&gt;&gt; <span class="title">outDegrees</span><span class="params">()</span></span></span><br><span class="line"><span class="function">DataSet&lt;Tuple2&lt;K, LongValue&gt;&gt; <span class="title">getDegrees</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">numberOfVertices</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">numberOfEdges</span><span class="params">()</span></span></span><br><span class="line"><span class="function">DataSet&lt;Triplet&lt;K, VV, EV&gt;&gt; <span class="title">getTriplets</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure><h4 id="Graph-转换"><a href="#Graph-转换" class="headerlink" title="Graph 转换"></a>Graph 转换</h4><p>Graph 转换方式有下面几种方式：</p><ul><li>Map：Gelly 提供了专门的用于转换顶点值和边值的方法。mapVertices 和 mapEdges 会返回一个新图，图中的每个顶点和边的 ID 不会改变，但是顶点和边的值会根据用户自定义的映射方法进行修改。这些映射方法同时也可以修改顶点和边的值的类型。</li><li>Translate：Gelly 还提供了专门用于根据用户定义的函数转换顶点和边的 ID 和值的值及类型的方法（translateGraphIDs/translateVertexValues/translateEdgeValues），是Map 功能的升级版，因为 Map 操作不支持修订顶点和边的 ID。</li><li>Filter：Gelly 支持在图中的顶点上或边上执行一个用户指定的 filter 转换。filterOnEdges 会根据提供的在边上的断言在原图的基础上生成一个新的子图，注意，顶点的数据不会被修改。同样的 filterOnVertices 在原图的顶点上进行 filter 转换，不满足断言条件的源节点或目标节点会在新的子图中移除。该子图方法支持同时对顶点和边应用 filter 函数，如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-165050.jpg" alt=""></p><ul><li>Reverse：Gelly中得reverse()方法用于在原图的基础上，生成一个所有边方向与原图相反的新图。</li><li>Undirected：在前面的内容中，我们提到过，Gelly中的图通常都是有向的，而无向图可以通过对所有边添加反向的边来实现，出于这个目的，Gelly提供了getUndirected()方法，用于获取原图的无向图。</li><li>Union：Gelly的union()操作用于联合当前图和指定的输入图，并生成一个新图，在输出的新图中，相同的节点只保留一份，但是重复的边会保留。如下图所示：</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-165224.jpg" alt=""></p><ul><li>Difference：Gelly提供了difference()方法用于发现当前图与指定的输入图之间的差异。</li><li>Intersect：Gelly提供了intersect()方法用于发现两个图中共同存在的边，并将相同的边以新图的方式返回。相同的边指的是具有相同的源顶点，相同的目标顶点和相同的边值。返回的新图中，所有的节点没有任何值，如果需要节点值，可以使用joinWithVertices()方法去任何一个输入图中检索。</li></ul><h4 id="Graph-变化"><a href="#Graph-变化" class="headerlink" title="Graph 变化"></a>Graph 变化</h4><p>Gelly 内置下列方法以支持对一个图进行节点和边的增加/移除操作：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Graph&lt;K, VV, EV&gt; <span class="title">addVertex</span><span class="params">(<span class="keyword">final</span> Vertex&lt;K, VV&gt; vertex)</span></span></span><br><span class="line"><span class="function">Graph&lt;K, VV, EV&gt; <span class="title">addVertices</span><span class="params">(List&lt;Vertex&lt;K, VV&gt;&gt; verticesToAdd)</span></span></span><br><span class="line"><span class="function">Graph&lt;K, VV, EV&gt; <span class="title">addEdge</span><span class="params">(Vertex&lt;K, VV&gt; source, Vertex&lt;K, VV&gt; target, EV edgeValue)</span></span></span><br><span class="line"><span class="function">Graph&lt;K, VV, EV&gt; <span class="title">addEdges</span><span class="params">(List&lt;Edge&lt;K, EV&gt;&gt; newEdges)</span></span></span><br><span class="line"><span class="function">Graph&lt;K, VV, EV&gt; <span class="title">removeVertex</span><span class="params">(Vertex&lt;K, VV&gt; vertex)</span></span></span><br><span class="line"><span class="function">Graph&lt;K, VV, EV&gt; <span class="title">removeVertices</span><span class="params">(List&lt;Vertex&lt;K, VV&gt;&gt; verticesToBeRemoved)</span></span></span><br><span class="line"><span class="function">Graph&lt;K, VV, EV&gt; <span class="title">removeEdge</span><span class="params">(Edge&lt;K, EV&gt; edge)</span></span></span><br><span class="line"><span class="function">Graph&lt;K, VV, EV&gt; <span class="title">removeEdges</span><span class="params">(List&lt;Edge&lt;K, EV&gt;&gt; edgesToBeRemoved)</span></span></span><br></pre></td></tr></table></figure><h4 id="Neighborhood-Methods"><a href="#Neighborhood-Methods" class="headerlink" title="Neighborhood Methods"></a>Neighborhood Methods</h4><h4 id="Graph-验证"><a href="#Graph-验证" class="headerlink" title="Graph 验证"></a>Graph 验证</h4><h3 id="6-5-4-小结与反思"><a href="#6-5-4-小结与反思" class="headerlink" title="6.5.4 小结与反思"></a>6.5.4 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/nMR7ufq">https://t.zsxq.com/nMR7ufq</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>本章所讲的内容属于 Flink 的扩展库，包含了 CEP 复杂事件处理、State Processor API、Machine Learning 和 Gelly，各种都有讲解一些样例，但是没有过多深入的讲，但还是希望你可以在书本外自己去扩充这些内容的知识点。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;6-5-Flink-扩展库——Gelly&quot;&gt;&lt;a href=&quot;#6-5-Flink-扩展库——Gelly&quot; class=&quot;headerlink&quot; title=&quot;6.5 Flink 扩展库——Gelly&quot;&gt;&lt;/a&gt;6.5 Flink 扩展库——Gelly&lt;/h2&gt;&lt;p&gt;在 1.9 版本中还剩最后一个扩展库就是 Gelly，本节将带你了解一下 Gelly 的功能以及如何使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
</feed>
