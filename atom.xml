<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhisheng的博客</title>
  
  <subtitle>坑要一个个填，路要一步步走！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.54tianzhisheng.cn/"/>
  <updated>2022-05-11T16:06:12.752Z</updated>
  <id>http://www.54tianzhisheng.cn/</id>
  
  <author>
    <name>zhisheng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink Table Store ——从计算到存储提升流批统一端到端用户体验</title>
    <link href="http://www.54tianzhisheng.cn/2022/05/12/flink-table-store/"/>
    <id>http://www.54tianzhisheng.cn/2022/05/12/flink-table-store/</id>
    <published>2022-05-11T16:00:00.000Z</published>
    <updated>2022-05-11T16:06:12.752Z</updated>
    
    <content type="html"><![CDATA[<p>该项目用于在 Flink 中为流处理和批处理构建动态表，支持超大流量的数据提取和及时的数据查询。</p><a id="more"></a><p>注意：该项目仍处于 beta 状态，正在快速发展，不建议直接在生产环境中使用它。</p><h3 id="Flink-Table-Store-介绍"><a href="#Flink-Table-Store-介绍" class="headerlink" title="Flink Table Store 介绍"></a>Flink Table Store 介绍</h3><p>在过去的几年里，得益于 Flink 社区众多的贡献者和用户，Apache Flink 已经成为最好的分布式计算引擎之一，尤其是在大规模有状态流处理方面。然而，当人们试图从他们的数据中实时获取洞察力时，仍然面临着一些挑战。在这些挑战中，一个突出的问题是缺乏满足所有计算模式的存储。</p><p>到目前为止，我们通常会部署一些存储系统来与 Flink 一起用于不同目的是很常见的。典型的设置是用于流处理的消息队列、用于批处理和即席查询的可查询文件系统/对象存储，以及用于查找的 K-V 存储。由于其复杂性和异构性，这种架构在数据质量和系统维护方面提出了挑战。这正在成为影响 Apache Flink 带来的流批统一端到端用户体验的一大问题。</p><p>Flink Table Store 的目标就是解决上述问题，这是该项目的重要一步。它将 Flink 的能力从计算扩展到存储领域。 因此，我们可以为用户提供更好的端到端体验。</p><p>Flink Table Store 旨在提供统一的存储抽象，让用户不必自己构建混合存储。具体来说，Flink Table Store 提供以下核心能力：</p><ul><li><p>支持超大数据集的存储，并允许以批处理和流方式读取和写入</p></li><li><p>支持毫秒级别延迟的流式查询</p></li><li><p>支持秒级别延迟的 Batch/OLAP 查询</p></li><li><p>默认支持流读增量快照，所以用户不需要自己解决组合不同存储的问题</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2022-05-11-151450.jpg" alt=""></p><p>在这个版本中，架构如上图所示：</p><ul><li><p>用户可以使用 Flink 将数据写入到 Table Store 中，既可以通过流式将数据库中捕获的变更日志写入，也可以通过从数据仓库等其他存储中批量加载数据后再写入</p></li><li><p>用户可以使用 Flink 以不同的方式查询 Table Store，包括流式查询和 Batch/OLAP 查询。 还值得注意的是，用户也可以使用其他引擎（例如 Apache Hive）从 Table Store 中查询</p></li><li><p>在底层，Table Store 使用混合存储架构，使用 Lake Store 存储历史数据，使用 Queue 系统（目前支持 Apache Kafka 集成）存储增量数据。 它为混合流式读取提供增量快照</p></li><li><p>Table Store 的 Lake Store 将数据作为列文件存储在文件系统/对象存储上，并使用 LSM 结构来支持大量的数据更新和高性能查询</p></li></ul><p>非常感谢以下系统的启发：Apache Iceberg 和 RocksDB。</p><h3 id="后续进展"><a href="#后续进展" class="headerlink" title="后续进展"></a>后续进展</h3><p>社区目前正在努力强化核心逻辑，稳定存储格式等，以使 Flink Table Store 可以投入生产。</p><p>在即将发布的 0.2.0 版本中，可以期待（至少）以下功能：</p><ul><li><p>生态：支持 Apache Hive Engine 的 Flink Table Store Reader</p></li><li><p>核心：支持自适应 Bucket 数量</p></li><li><p>核心：支持仅 append 的数据，Table Store 不仅仅局限于更新场景</p></li><li><p>核心：完善的 schema 变化</p></li><li><p>改进基于预览版得到的反馈</p></li></ul><p>从中期来看，你还可以期待：</p><ul><li><p>生态系统：支持 Trino、PrestoDB 和 Apache Spark 的 Flink Table Store Reader</p></li><li><p>Flink Table Store Service 会加速更新，提升查询性能</p></li></ul><h3 id="尝鲜"><a href="#尝鲜" class="headerlink" title="尝鲜"></a>尝鲜</h3><p>可以通过 <a href="https://nightlies.apache.org/flink/flink-table-store-docs-release-0.1/docs/try-table-store/quick-start/">https://nightlies.apache.org/flink/flink-table-store-docs-release-0.1/docs/try-table-store/quick-start/</a> 来尝试一下。</p><p>下载链接：<a href="https://flink.apache.org/downloads.html">https://flink.apache.org/downloads.html</a></p><blockquote><p>翻译原文链接：<a href="https://flink.apache.org/news/2022/05/11/release-table-store-0.1.0.html">https://flink.apache.org/news/2022/05/11/release-table-store-0.1.0.html</a></p><p>原文作者：李劲松 &amp; 秦江杰</p></blockquote><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;该项目用于在 Flink 中为流处理和批处理构建动态表，支持超大流量的数据提取和及时的数据查询。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink Iceberg Source 并行度推断源码解析</title>
    <link href="http://www.54tianzhisheng.cn/2022/05/02/flink-iceberg-source-parallelism/"/>
    <id>http://www.54tianzhisheng.cn/2022/05/02/flink-iceberg-source-parallelism/</id>
    <published>2022-05-01T16:00:00.000Z</published>
    <updated>2022-05-07T13:50:31.173Z</updated>
    
    <content type="html"><![CDATA[<h3 id="批读-Iceberg"><a href="#批读-Iceberg" class="headerlink" title="批读 Iceberg"></a>批读 Iceberg</h3><p>Iceberg 提供了两个配置：</p><a id="more"></a><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;Boolean&gt; TABLE_EXEC_ICEBERG_INFER_SOURCE_PARALLELISM =</span><br><span class="line">  ConfigOptions.key(<span class="string">"table.exec.iceberg.infer-source-parallelism"</span>)</span><br><span class="line">      .booleanType()</span><br><span class="line">      .defaultValue(<span class="keyword">true</span>)</span><br><span class="line">      .withDescription(<span class="string">"If is false, parallelism of source are set by config.\n"</span> +</span><br><span class="line">          <span class="string">"If is true, source parallelism is inferred according to splits number.\n"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;Integer&gt; TABLE_EXEC_ICEBERG_INFER_SOURCE_PARALLELISM_MAX =</span><br><span class="line">  ConfigOptions.key(<span class="string">"table.exec.iceberg.infer-source-parallelism.max"</span>)</span><br><span class="line">      .intType()</span><br><span class="line">      .defaultValue(<span class="number">100</span>)</span><br><span class="line">      .withDescription(<span class="string">"Sets max infer parallelism for source operator."</span>);</span><br></pre></td></tr></table></figure><ul><li>table.exec.iceberg.infer-source-parallelism：默认是 true，意味着 source 的并行度是根据推断来配置的，如果配置的 false 的话，那么并行度的配置是以配置的为准。</li><li>table.exec.iceberg.infer-source-parallelism.max： 默认是 100，source 算子的最大并行度。</li></ul><p>这两个参数只在 FileSource 的 inferParallelism 方法中调用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">inferParallelism</span><span class="params">(FlinkInputFormat format, ScanContext context)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 读取 table.exec.resource.default-parallelism 配置，默认值为 -1  </span></span><br><span class="line">  <span class="keyword">int</span> parallelism = readableConfig.get(ExecutionConfigOptions.TABLE_EXEC_RESOURCE_DEFAULT_PARALLELISM);</span><br><span class="line">  <span class="comment">// 读取 table.exec.iceberg.infer-source-parallelism 配置，默认是 true  </span></span><br><span class="line">  <span class="keyword">if</span> (readableConfig.get(FlinkConfigOptions.TABLE_EXEC_ICEBERG_INFER_SOURCE_PARALLELISM)) &#123;</span><br><span class="line">    <span class="comment">// 读取 table.exec.iceberg.infer-source-parallelism.max 配置，默认是 100</span></span><br><span class="line">    <span class="keyword">int</span> maxInferParallelism = readableConfig.get(FlinkConfigOptions</span><br><span class="line">        .TABLE_EXEC_ICEBERG_INFER_SOURCE_PARALLELISM_MAX);</span><br><span class="line">    Preconditions.checkState(</span><br><span class="line">        maxInferParallelism &gt;= <span class="number">1</span>,</span><br><span class="line">        FlinkConfigOptions.TABLE_EXEC_ICEBERG_INFER_SOURCE_PARALLELISM_MAX.key() + <span class="string">" cannot be less than 1"</span>);</span><br><span class="line">    <span class="comment">//获取表的 splitNum </span></span><br><span class="line">    <span class="keyword">int</span> splitNum;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      FlinkInputSplit[] splits = format.createInputSplits(<span class="number">0</span>);</span><br><span class="line">      splitNum = splits.length;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UncheckedIOException(<span class="string">"Failed to create iceberg input splits for table: "</span> + table, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    parallelism = Math.min(splitNum, maxInferParallelism);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (context.limit() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> limit = context.limit() &gt;= Integer.MAX_VALUE ? Integer.MAX_VALUE : (<span class="keyword">int</span>) context.limit();</span><br><span class="line">    parallelism = Math.min(parallelism, limit);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// parallelism must be positive.</span></span><br><span class="line">  parallelism = Math.max(<span class="number">1</span>, parallelism);</span><br><span class="line">  <span class="keyword">return</span> parallelism;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在下面代码获取到表的 splitNum</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">FlinkInputSplit[] splits = format.createInputSplits(<span class="number">0</span>);</span><br><span class="line">splitNum = splits.length;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> FlinkInputSplit[] createInputSplits(<span class="keyword">int</span> minNumSplits) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// Called in Job manager, so it is OK to load table from catalog.</span></span><br><span class="line">    <span class="comment">// 加载 catalog  </span></span><br><span class="line">    tableLoader.open();</span><br><span class="line">    <span class="keyword">final</span> ExecutorService workerPool = ThreadPools.newWorkerPool(<span class="string">"iceberg-plan-worker-pool"</span>, context.planParallelism());</span><br><span class="line">    <span class="keyword">try</span> (TableLoader loader = tableLoader) &#123;</span><br><span class="line">      <span class="comment">// 加载表  </span></span><br><span class="line">      Table table = loader.loadTable();</span><br><span class="line">      <span class="comment">// 调用 </span></span><br><span class="line">      <span class="keyword">return</span> FlinkSplitPlanner.planInputSplits(table, context, workerPool);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      workerPool.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> FlinkInputSplit[] planInputSplits(Table table, ScanContext context, ExecutorService workerPool) &#123;</span><br><span class="line">    <span class="comment">// 主要通过 planTasks 方法</span></span><br><span class="line">      <span class="keyword">try</span> (CloseableIterable&lt;CombinedScanTask&gt; tasksIterable = planTasks(table, context, workerPool)) &#123;</span><br><span class="line">      List&lt;CombinedScanTask&gt; tasks = Lists.newArrayList(tasksIterable);</span><br><span class="line">      FlinkInputSplit[] splits = <span class="keyword">new</span> FlinkInputSplit[tasks.size()];</span><br><span class="line">      <span class="keyword">boolean</span> exposeLocality = context.exposeLocality();</span><br><span class="line"></span><br><span class="line">      Tasks.range(tasks.size())</span><br><span class="line">          .stopOnFailure()</span><br><span class="line">          .executeWith(exposeLocality ? workerPool : <span class="keyword">null</span>)</span><br><span class="line">          .run(index -&gt; &#123;</span><br><span class="line">            CombinedScanTask task = tasks.get(index);</span><br><span class="line">            String[] hostnames = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">if</span> (exposeLocality) &#123;</span><br><span class="line">              hostnames = Util.blockLocations(table.io(), task);</span><br><span class="line">            &#125;</span><br><span class="line">            splits[index] = <span class="keyword">new</span> FlinkInputSplit(index, task, hostnames);</span><br><span class="line">          &#125;);</span><br><span class="line">      <span class="keyword">return</span> splits;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UncheckedIOException(<span class="string">"Failed to process tasks iterable"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>planTasks 方法中主要靠 scan.planTasks()，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CloseableIterable&lt;CombinedScanTask&gt; <span class="title">planTasks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    CloseableIterable&lt;FileScanTask&gt; fileScanTasks = planFiles();</span><br><span class="line">    CloseableIterable&lt;FileScanTask&gt; splitFiles = TableScanUtil.splitFiles(fileScanTasks, targetSplitSize());</span><br><span class="line">    <span class="keyword">return</span> TableScanUtil.planTasks(splitFiles, targetSplitSize(), splitLookback(), splitOpenFileCost());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取文件情况 </span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> CloseableIterable&lt;FileScanTask&gt; <span class="title">planFiles</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Snapshot snapshot = snapshot();</span><br><span class="line">    <span class="keyword">if</span> (snapshot != <span class="keyword">null</span>) &#123;</span><br><span class="line">      LOG.info(<span class="string">"Scanning table &#123;&#125; snapshot &#123;&#125; created at &#123;&#125; with filter &#123;&#125;"</span>, table,</span><br><span class="line">          snapshot.snapshotId(), DateTimeUtil.formatTimestampMillis(snapshot.timestampMillis()),</span><br><span class="line">          context.rowFilter());</span><br><span class="line"></span><br><span class="line">      Listeners.notifyAll(</span><br><span class="line">          <span class="keyword">new</span> ScanEvent(table.name(), snapshot.snapshotId(), context.rowFilter(), schema()));</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> planFiles(ops, snapshot,</span><br><span class="line">          context.rowFilter(), context.ignoreResiduals(), context.caseSensitive(), context.returnColumnStats());</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      LOG.info(<span class="string">"Scanning empty table &#123;&#125;"</span>, table);</span><br><span class="line">      <span class="keyword">return</span> CloseableIterable.empty();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// split  </span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CloseableIterable&lt;FileScanTask&gt; <span class="title">splitFiles</span><span class="params">(CloseableIterable&lt;FileScanTask&gt; tasks, <span class="keyword">long</span> splitSize)</span> </span>&#123;</span><br><span class="line">    Preconditions.checkArgument(splitSize &gt; <span class="number">0</span>, <span class="string">"Invalid split size (negative or 0): %s"</span>, splitSize);</span><br><span class="line"></span><br><span class="line">    Iterable&lt;FileScanTask&gt; splitTasks = FluentIterable</span><br><span class="line">        .from(tasks)</span><br><span class="line">        .transformAndConcat(input -&gt; input.split(splitSize));</span><br><span class="line">    <span class="comment">// Capture manifests which can be closed after scan planning</span></span><br><span class="line">    <span class="keyword">return</span> CloseableIterable.combine(splitTasks, tasks);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CloseableIterable&lt;CombinedScanTask&gt; <span class="title">planTasks</span><span class="params">(CloseableIterable&lt;FileScanTask&gt; splitFiles,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                              <span class="keyword">long</span> splitSize, <span class="keyword">int</span> lookback, <span class="keyword">long</span> openFileCost)</span> </span>&#123;</span><br><span class="line">    Preconditions.checkArgument(splitSize &gt; <span class="number">0</span>, <span class="string">"Invalid split size (negative or 0): %s"</span>, splitSize);</span><br><span class="line">    Preconditions.checkArgument(lookback &gt; <span class="number">0</span>, <span class="string">"Invalid split planning lookback (negative or 0): %s"</span>, lookback);</span><br><span class="line">    Preconditions.checkArgument(openFileCost &gt;= <span class="number">0</span>, <span class="string">"Invalid file open cost (negative): %s"</span>, openFileCost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check the size of delete file as well to avoid unbalanced bin-packing</span></span><br><span class="line">    Function&lt;FileScanTask, Long&gt; weightFunc = file -&gt; Math.max(</span><br><span class="line">        file.length() + file.deletes().stream().mapToLong(ContentFile::fileSizeInBytes).sum(),</span><br><span class="line">        (<span class="number">1</span> + file.deletes().size()) * openFileCost);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> CloseableIterable.transform(</span><br><span class="line">        CloseableIterable.combine(</span><br><span class="line">            <span class="keyword">new</span> BinPacking.PackingIterable&lt;&gt;(splitFiles, splitSize, lookback, weightFunc, <span class="keyword">true</span>),</span><br><span class="line">            splitFiles),</span><br><span class="line">        BaseCombinedScanTask::<span class="keyword">new</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>推断到表文件 split 的数量后，那么接下来是决定并行度大小的时候了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parallelism = Math.min(splitNum, maxInferParallelism);</span><br></pre></td></tr></table></figure><p>取配置的最大并行度和 split 数量的最小值，eg：设置的 source 最大并行度为 50，但是根据表文件划分出来的 split 数量为 40，那么 source 的并行度为 40。</p><p>如果没有配置 table.exec.iceberg.infer-source-parallelism 为 true 的话，那么就以 table.exec.resource.default-parallelism 的并行度为准（默认值是 -1）。</p><p>继续分析接下来的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (context.limit() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> limit = context.limit() &gt;= Integer.MAX_VALUE ? Integer.MAX_VALUE : (<span class="keyword">int</span>) context.limit();</span><br><span class="line">    parallelism = Math.min(parallelism, limit);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>limit 像是 SQL 查询语句里面的 limit 的值，如果配置了 limit，那么也会参与并行度配置的计算的，eg：如果 limti 为 1，那么 parallelism 取前面  parallelism 的值与 1 两者的最小值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parallelism must be positive.</span></span><br><span class="line">parallelism = Math.max(<span class="number">1</span>, parallelism);</span><br><span class="line"><span class="keyword">return</span> parallelism;</span><br></pre></td></tr></table></figure><p>最后代码保证并行度的最小值为 1。</p><p>来看下 inferParallelism 方法的调用情况，只在 FileSource 类的 build() 方法调用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DataStream&lt;RowData&gt; <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Preconditions.checkNotNull(env, <span class="string">"StreamExecutionEnvironment should not be null"</span>);</span><br><span class="line">  FlinkInputFormat format = buildFormat();</span><br><span class="line"></span><br><span class="line">  ScanContext context = contextBuilder.build();</span><br><span class="line">  TypeInformation&lt;RowData&gt; typeInfo = FlinkCompatibilityUtil.toTypeInfo(FlinkSchemaUtil.convert(context.project()));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!context.isStreaming()) &#123;</span><br><span class="line">    <span class="comment">// 只在 批 模式下生效  </span></span><br><span class="line">    <span class="keyword">int</span> parallelism = inferParallelism(format, context);</span><br><span class="line">    <span class="keyword">return</span> env.createInput(format, typeInfo).setParallelism(parallelism);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    StreamingMonitorFunction function = <span class="keyword">new</span> StreamingMonitorFunction(tableLoader, context);</span><br><span class="line"></span><br><span class="line">    String monitorFunctionName = String.format(<span class="string">"Iceberg table (%s) monitor"</span>, table);</span><br><span class="line">    String readerOperatorName = String.format(<span class="string">"Iceberg table (%s) reader"</span>, table);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> env.addSource(function, monitorFunctionName)</span><br><span class="line">        .transform(readerOperatorName, typeInfo, StreamingReaderOperator.factory(format));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看 TestFlinkScanSql 测试类的 testInferedParallelism 方法进行测试：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testInferedParallelism</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  Table table = catalog.createTable(TableIdentifier.of(<span class="string">"default"</span>, <span class="string">"t"</span>), TestFixtures.SCHEMA, TestFixtures.SPEC);</span><br><span class="line"></span><br><span class="line">  TableLoader tableLoader = TableLoader.fromHadoopTable(table.location());</span><br><span class="line">  FlinkInputFormat flinkInputFormat = FlinkSource.forRowData().tableLoader(tableLoader).table(table).buildFormat();</span><br><span class="line">  ScanContext scanContext = ScanContext.builder().build();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Empty table, infer parallelism should be at least 1</span></span><br><span class="line">  <span class="keyword">int</span> parallelism = FlinkSource.forRowData().inferParallelism(flinkInputFormat, scanContext);</span><br><span class="line">  Assert.assertEquals(<span class="string">"Should produce the expected parallelism."</span>, <span class="number">1</span>, parallelism);</span><br><span class="line"></span><br><span class="line">  GenericAppenderHelper helper = <span class="keyword">new</span> GenericAppenderHelper(table, fileFormat, TEMPORARY_FOLDER);</span><br><span class="line">  DataFile dataFile1 = helper.writeFile(TestHelpers.Row.of(<span class="string">"2020-03-20"</span>, <span class="number">0</span>),</span><br><span class="line">      RandomGenericData.generate(TestFixtures.SCHEMA, <span class="number">2</span>, <span class="number">0L</span>));</span><br><span class="line">  DataFile dataFile2 = helper.writeFile(TestHelpers.Row.of(<span class="string">"2020-03-21"</span>, <span class="number">0</span>),</span><br><span class="line">      RandomGenericData.generate(TestFixtures.SCHEMA, <span class="number">2</span>, <span class="number">0L</span>));</span><br><span class="line">  helper.appendToTable(dataFile1, dataFile2);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Make sure to generate 2 CombinedScanTasks</span></span><br><span class="line">  <span class="keyword">long</span> maxFileLen = Math.max(dataFile1.fileSizeInBytes(), dataFile2.fileSizeInBytes());</span><br><span class="line">  sql(<span class="string">"ALTER TABLE t SET ('read.split.open-file-cost'='1', 'read.split.target-size'='%s')"</span>, maxFileLen);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2 splits (max infer is the default value 100 , max &gt; splits num), the parallelism is splits num : 2</span></span><br><span class="line">  parallelism = FlinkSource.forRowData().inferParallelism(flinkInputFormat, scanContext);</span><br><span class="line">  Assert.assertEquals(<span class="string">"Should produce the expected parallelism."</span>, <span class="number">2</span>, parallelism);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2 splits and limit is 1 , max infer parallelism is default 100，</span></span><br><span class="line">  <span class="comment">// which is greater than splits num and limit, the parallelism is the limit value : 1</span></span><br><span class="line">  parallelism = FlinkSource.forRowData().inferParallelism(flinkInputFormat, ScanContext.builder().limit(<span class="number">1</span>).build());</span><br><span class="line">  Assert.assertEquals(<span class="string">"Should produce the expected parallelism."</span>, <span class="number">1</span>, parallelism);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2 splits and max infer parallelism is 1 (max &lt; splits num), the parallelism is  1</span></span><br><span class="line">  Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">  configuration.setInteger(FlinkConfigOptions.TABLE_EXEC_ICEBERG_INFER_SOURCE_PARALLELISM_MAX, <span class="number">1</span>);</span><br><span class="line">  parallelism = FlinkSource.forRowData()</span><br><span class="line">      .flinkConf(configuration)</span><br><span class="line">      .inferParallelism(flinkInputFormat, ScanContext.builder().build());</span><br><span class="line">  Assert.assertEquals(<span class="string">"Should produce the expected parallelism."</span>, <span class="number">1</span>, parallelism);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2 splits, max infer parallelism is 1, limit is 3, the parallelism is max infer parallelism : 1</span></span><br><span class="line">  parallelism = FlinkSource.forRowData()</span><br><span class="line">      .flinkConf(configuration)</span><br><span class="line">      .inferParallelism(flinkInputFormat, ScanContext.builder().limit(<span class="number">3</span>).build());</span><br><span class="line">  Assert.assertEquals(<span class="string">"Should produce the expected parallelism."</span>, <span class="number">1</span>, parallelism);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2 splits, infer parallelism is disabled, the parallelism is flink default parallelism 1</span></span><br><span class="line">  configuration.setBoolean(FlinkConfigOptions.TABLE_EXEC_ICEBERG_INFER_SOURCE_PARALLELISM, <span class="keyword">false</span>);</span><br><span class="line">  parallelism = FlinkSource.forRowData()</span><br><span class="line">      .flinkConf(configuration)</span><br><span class="line">      .inferParallelism(flinkInputFormat, ScanContext.builder().limit(<span class="number">3</span>).build());</span><br><span class="line">  Assert.assertEquals(<span class="string">"Should produce the expected parallelism."</span>, <span class="number">1</span>, parallelism);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意⚠️：该代码模块是在 Iceberg 项目的 flink module 下</p><h3 id="流读-Iceberg"><a href="#流读-Iceberg" class="headerlink" title="流读 Iceberg"></a>流读 Iceberg</h3><p>并没有针对流读配置 Source 并行度</p><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/6YjyJYR">https://t.zsxq.com/6YjyJYR</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;批读-Iceberg&quot;&gt;&lt;a href=&quot;#批读-Iceberg&quot; class=&quot;headerlink&quot; title=&quot;批读 Iceberg&quot;&gt;&lt;/a&gt;批读 Iceberg&lt;/h3&gt;&lt;p&gt;Iceberg 提供了两个配置：&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink Hive Source 并行度推断源码解析</title>
    <link href="http://www.54tianzhisheng.cn/2022/05/01/flink-hive-source-parallelism/"/>
    <id>http://www.54tianzhisheng.cn/2022/05/01/flink-hive-source-parallelism/</id>
    <published>2022-04-30T16:00:00.000Z</published>
    <updated>2022-05-07T13:50:31.165Z</updated>
    
    <content type="html"><![CDATA[<h3 id="批读-Hive"><a href="#批读-Hive" class="headerlink" title="批读 Hive"></a>批读 Hive</h3><p>HiveOptions 中有两个配置</p><a id="more"></a><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;Boolean&gt; TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM =</span><br><span class="line">        key(<span class="string">"table.exec.hive.infer-source-parallelism"</span>)</span><br><span class="line">                .defaultValue(<span class="keyword">true</span>)</span><br><span class="line">                .withDescription(</span><br><span class="line">                        <span class="string">"If is false, parallelism of source are set by config.\n"</span> +</span><br><span class="line">                        <span class="string">"If is true, source parallelism is inferred according to splits number.\n"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;Integer&gt; TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM_MAX =</span><br><span class="line">        key(<span class="string">"table.exec.hive.infer-source-parallelism.max"</span>)</span><br><span class="line">                .defaultValue(<span class="number">1000</span>)</span><br><span class="line">                .withDescription(<span class="string">"Sets max infer parallelism for source operator."</span>);</span><br></pre></td></tr></table></figure><ul><li>table.exec.hive.infer-source-parallelism：默认值是 true，表示 source 的并行度是根据数据分区数和文件数推断的，如果设置为 false 的话表示并行度是以配置的为准</li><li>table.exec.hive.infer-source-parallelism.max：默认值是 1000，表示读取 Hive 数据的 source 最大并行度</li></ul><p>这两个参数只在 HiveParallelismInference 类中使用，观察到 HiveParallelismInference 类是专门针对 Hive 并行度配置的工具类，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A utility class to calculate parallelism for Hive connector considering various factors.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HiveParallelismInference</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(HiveParallelismInference.class);</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ObjectPath tablePath;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> infer;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> inferMaxParallelism;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> parallelism;</span><br><span class="line"></span><br><span class="line">HiveParallelismInference(ObjectPath tablePath, ReadableConfig flinkConf) &#123;</span><br><span class="line"><span class="keyword">this</span>.tablePath = tablePath;</span><br><span class="line">        <span class="comment">// 获取 table.exec.hive.infer-source-parallelism 配置并赋值，</span></span><br><span class="line"><span class="keyword">this</span>.infer = flinkConf.get(HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM);</span><br><span class="line"><span class="comment">// 获取 table.exec.hive.infer-source-parallelism.max 配置并赋值</span></span><br><span class="line">        <span class="keyword">this</span>.inferMaxParallelism = flinkConf.get(HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM_MAX);</span><br><span class="line">Preconditions.checkArgument(</span><br><span class="line">inferMaxParallelism &gt;= <span class="number">1</span>,</span><br><span class="line">HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM_MAX.key() + <span class="string">" cannot be less than 1"</span>);</span><br><span class="line">        <span class="comment">// 获取 table.exec.resource.default-parallelism 配置</span></span><br><span class="line"><span class="keyword">this</span>.parallelism = flinkConf.get(ExecutionConfigOptions.TABLE_EXEC_RESOURCE_DEFAULT_PARALLELISM);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Apply limit to calculate the parallelism.</span></span><br><span class="line"><span class="comment"> * Here limit is the limit in query &lt;code&gt;SELECT * FROM xxx LIMIT [limit]&lt;/code&gt;.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">limit</span><span class="params">(Long limit)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (limit != <span class="keyword">null</span>) &#123;</span><br><span class="line">parallelism = Math.min(parallelism, (<span class="keyword">int</span>) (limit / <span class="number">1000</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// make sure that parallelism is at least 1</span></span><br><span class="line"><span class="keyword">return</span> Math.max(<span class="number">1</span>, parallelism);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//根据</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Infer parallelism by number of files and number of splits.</span></span><br><span class="line"><span class="comment"> * If &#123;<span class="doctag">@link</span> HiveOptions#TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM&#125; is not set this method does nothing.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">HiveParallelismInference <span class="title">infer</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">SupplierWithException&lt;Integer, IOException&gt; numFiles,</span></span></span><br><span class="line"><span class="function"><span class="params">SupplierWithException&lt;Integer, IOException&gt; numSplits)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//如果设置 table.exec.hive.infer-source-parallelism 为 false，则直接跳过了</span></span><br><span class="line"><span class="keyword">if</span> (!infer) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">// `createInputSplits` is costly,</span></span><br><span class="line"><span class="comment">// so we try to avoid calling it by first checking the number of files</span></span><br><span class="line"><span class="comment">// which is the lower bound of the number of splits</span></span><br><span class="line"><span class="keyword">int</span> lowerBound = logRunningTime(<span class="string">"getNumFiles"</span>, numFiles);</span><br><span class="line"><span class="keyword">if</span> (lowerBound &gt;= inferMaxParallelism) &#123;</span><br><span class="line">parallelism = inferMaxParallelism;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> splitNum = logRunningTime(<span class="string">"createInputSplits"</span>, numSplits);</span><br><span class="line">parallelism = Math.min(splitNum, inferMaxParallelism);</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> FlinkHiveException(e);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">logRunningTime</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">String operationName, SupplierWithException&lt;Integer, IOException&gt; supplier)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"><span class="keyword">long</span> startTimeMillis = System.currentTimeMillis();</span><br><span class="line"><span class="keyword">int</span> result = supplier.get();</span><br><span class="line">LOG.info(</span><br><span class="line"><span class="string">"Hive source(&#123;&#125;&#125;) &#123;&#125; use time: &#123;&#125; ms, result: &#123;&#125;"</span>,</span><br><span class="line">tablePath,</span><br><span class="line">operationName,</span><br><span class="line">System.currentTimeMillis() - startTimeMillis,</span><br><span class="line">result);</span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到注释主要是 infer 方法去做的的并行度推断，该方法有两个参数 numFiles 和 numSplits，该方法只在HiveTableSource 类中的 getDataStream 方法中调用，可以查看下图：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2022-05-07-134123.jpg" alt=""></p><p>那就来看看这两个方法的实现：</p><p>getNumFiles 方法是用来获取 Hive 表分区下面的文件数量的:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getNumFiles</span><span class="params">(List&lt;HiveTablePartition&gt; partitions, JobConf jobConf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> numFiles = <span class="number">0</span>;</span><br><span class="line">    FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">for</span> (HiveTablePartition partition : partitions) &#123;</span><br><span class="line">        StorageDescriptor sd = partition.getStorageDescriptor();</span><br><span class="line">        org.apache.hadoop.fs.Path inputPath = <span class="keyword">new</span> org.apache.hadoop.fs.Path(sd.getLocation());</span><br><span class="line">        <span class="keyword">if</span> (fs == <span class="keyword">null</span>) &#123;</span><br><span class="line">            fs = inputPath.getFileSystem(jobConf);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// it's possible a partition exists in metastore but the data has been removed</span></span><br><span class="line">        <span class="keyword">if</span> (!fs.exists(inputPath)) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        numFiles += fs.listStatus(inputPath).length;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> numFiles;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>createInputSplits 方法是用来将 Hive 表分区下的文件分割成逻辑上的 InputSplit，这里是在 Flink Hive Connector 里面定义了一个 HiveSourceSplit 类来包装 InputSplit，包含了 Hive 表分区的信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;HiveSourceSplit&gt; <span class="title">createInputSplits</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> minNumSplits,</span></span></span><br><span class="line"><span class="function"><span class="params">        List&lt;HiveTablePartition&gt; partitions,</span></span></span><br><span class="line"><span class="function"><span class="params">        JobConf jobConf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    List&lt;HiveSourceSplit&gt; hiveSplits = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">for</span> (HiveTablePartition partition : partitions) &#123;</span><br><span class="line">        StorageDescriptor sd = partition.getStorageDescriptor();</span><br><span class="line">        org.apache.hadoop.fs.Path inputPath = <span class="keyword">new</span> org.apache.hadoop.fs.Path(sd.getLocation());</span><br><span class="line">        <span class="keyword">if</span> (fs == <span class="keyword">null</span>) &#123;</span><br><span class="line">            fs = inputPath.getFileSystem(jobConf);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// it's possible a partition exists in metastore but the data has been removed</span></span><br><span class="line">        <span class="keyword">if</span> (!fs.exists(inputPath)) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        InputFormat format;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            format = (InputFormat)</span><br><span class="line">                    Class.forName(sd.getInputFormat(), <span class="keyword">true</span>, Thread.currentThread().getContextClassLoader()).newInstance();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> FlinkHiveException(<span class="string">"Unable to instantiate the hadoop input format"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        ReflectionUtils.setConf(format, jobConf);</span><br><span class="line">        jobConf.set(INPUT_DIR, sd.getLocation());</span><br><span class="line">        <span class="comment">//<span class="doctag">TODO:</span> we should consider how to calculate the splits according to minNumSplits in the future.</span></span><br><span class="line">        org.apache.hadoop.mapred.InputSplit[] splitArray = format.getSplits(jobConf, minNumSplits);</span><br><span class="line">        <span class="keyword">for</span> (org.apache.hadoop.mapred.InputSplit inputSplit : splitArray) &#123;</span><br><span class="line">            Preconditions.checkState(inputSplit <span class="keyword">instanceof</span> FileSplit,</span><br><span class="line">                    <span class="string">"Unsupported InputSplit type: "</span> + inputSplit.getClass().getName());</span><br><span class="line">            hiveSplits.add(<span class="keyword">new</span> HiveSourceSplit((FileSplit) inputSplit, partition, <span class="keyword">null</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> hiveSplits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为上面两个方法的执行可能需要一点时间，所以专门还写了一个 logRunningTime 记录其执行的时间。</p><p>如果文件数大于配置的最大并行度，那么作业的并行度直接以配置的最大并行度为准；否则取 InputSplit 个数与配置的最大并行度两者最小值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> lowerBound = logRunningTime(<span class="string">"getNumFiles"</span>, numFiles);</span><br><span class="line"><span class="keyword">if</span> (lowerBound &gt;= inferMaxParallelism) &#123;</span><br><span class="line">    parallelism = inferMaxParallelism;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> splitNum = logRunningTime(<span class="string">"createInputSplits"</span>, numSplits);</span><br><span class="line">parallelism = Math.min(splitNum, inferMaxParallelism);</span><br></pre></td></tr></table></figure><p>然后就是 limit 方法的限制并行度了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Apply limit to calculate the parallelism.</span></span><br><span class="line"><span class="comment"> * Here limit is the limit in query &lt;code&gt;SELECT * FROM xxx LIMIT [limit]&lt;/code&gt;.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">limit</span><span class="params">(Long limit)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (limit != <span class="keyword">null</span>) &#123;</span><br><span class="line">        parallelism = Math.min(parallelism, (<span class="keyword">int</span>) (limit / <span class="number">1000</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// make sure that parallelism is at least 1</span></span><br><span class="line">    <span class="keyword">return</span> Math.max(<span class="number">1</span>, parallelism);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方法的注释的意思是根据查询语句的 limit 来配置并行度，判断前面得到的并行度与 limit/1000 的大小，取两者最小值。举个例子，前面判断这个 Hive 表分区有非常多的文件，比如 10001 个，那大于默认的最大值 1000，那么返回的并行度是 1000，但是因为查询 Hive 的 SQL 只是 100 条，那么这里取值得到的最小值是 0，最后通过 Math.max(1, parallelism) 返回的 source 并行度是 1。</p><p>注意⚠️：上面的并行度配置仅仅针对于批作业查 Hive 数据，不针对流读 Hive 数据。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2022-05-07-134319.jpg" alt=""></p><h3 id="流读-Hive"><a href="#流读-Hive" class="headerlink" title="流读 Hive"></a>流读 Hive</h3><p>在 HiveTableSource 类中的 getDataStream 方法中并没有针对流读配置 Source 并行度。</p><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/E6Mj6uv">https://t.zsxq.com/E6Mj6uv</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;批读-Hive&quot;&gt;&lt;a href=&quot;#批读-Hive&quot; class=&quot;headerlink&quot; title=&quot;批读 Hive&quot;&gt;&lt;/a&gt;批读 Hive&lt;/h3&gt;&lt;p&gt;HiveOptions 中有两个配置&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>如何提高 Flink K8s 集群资源使用率？</title>
    <link href="http://www.54tianzhisheng.cn/2022/03/26/flink-k8s-pod-add-request-and-limit/"/>
    <id>http://www.54tianzhisheng.cn/2022/03/26/flink-k8s-pod-add-request-and-limit/</id>
    <published>2022-03-25T16:00:00.000Z</published>
    <updated>2022-03-30T08:38:05.716Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>在 flink on k8s 默认提交作业的命令下，我们会指定作业的 JM/TM 的 CPU 和 Memory，最后作业生成的 pod 它的 CPU/Memory 的 request/limit 都是一样的资源，但是作业真实运行时使用的资源远达不到 limit 的值，这样就会<strong>造成机器资源浪费</strong>（水位不高，但是机器又不能再申请 pod）。</p><a id="more"></a><p>比如下面命令：（指定了 TM 的资源，未指定 JM 资源）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run-application -p 1 -t kubernetes-application  -c com.zhisheng.Test \</span><br><span class="line">  -Dkubernetes.cluster-id=flink-log-alert-test1 \</span><br><span class="line">  -Dtaskmanager.memory.process.size=6g \</span><br><span class="line">  -Djobmanager.memory.process.size=2g \</span><br><span class="line">  -Dkubernetes.jobmanager.cpu=0.5 \</span><br><span class="line">  -Dkubernetes.taskmanager.cpu=1 \</span><br><span class="line">  -Dtaskmanager.numberOfTaskSlots=1 \</span><br><span class="line">  ....</span><br></pre></td></tr></table></figure><p>JM:</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2022-03-29-144153.jpg" alt=""></p><p>TM:</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2022-03-29-144217.jpg" alt=""></p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>1、分别为 JM/TM 的 内存和 CPU 添加参数设置 request 和 limit，如果行得通的话，这种方式要增加 8 个参数才能满足需求，但因 Flink 内存模型使得单独设置内存的 request/limit 变得非常复杂，只能设置 CPU 参数，而且之前的参数也将变得不可以使用。</p><p>2、分别为 JM/TM 的 内存和 CPU 添加参数 limit 因子，用户配置的内存或者 CPU 的值默认为 request 的值，limit 因子必须 &gt;= 1，这种方式需要增加四个参数，相比第一种方法这种方法较为简单，但是目前 YARN 集群用户的资源配置，大多数作业已经是有一定的资源浪费（申请的资源远大于实际使用的资源），如果使用该方式，用户作业无感迁移到 K8s 集群后，其实<strong>资源浪费问题并没有解决</strong>。</p><p>3、分别为 JM/TM 的 内存和 CPU 添加参数 request 因子，用户配置的内存或者 CPU 的值默认为 limit 的值，request 因子必须 &lt;= 1，我们可以根据生产的数据配置一个合理的值，比如为 0.5。这种方式同样需要增加四个参数，但是这种方法对比第二种带来的好处是，<strong>大多数用户作业的资源配置将会更合理，机器同等资源能运行更多的 pod，从而可以提高机器的资源水位</strong>。</p><p>代码开发</p><p>1、在 KubernetesConfigOptions 增加配置 </p><p>KubernetesConfigOptions.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// jobmanager</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;Double&gt; JOB_MANAGER_CPU_REQUEST_FACTOR =</span><br><span class="line">    key(<span class="string">"kubernetes.jobmanager.cpu.request-factor"</span>)</span><br><span class="line">    .doubleType()</span><br><span class="line">    .defaultValue(<span class="number">1.0</span>)</span><br><span class="line">    .withDescription(</span><br><span class="line">    <span class="string">"The request factor of cpu used by job manager. "</span></span><br><span class="line">    + <span class="string">"The resources request cpu will be set to cpu * request-factor."</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;Double&gt; JOB_MANAGER_MEMORY_REQUEST_FACTOR =</span><br><span class="line">    key(<span class="string">"kubernetes.jobmanager.memory.request-factor"</span>)</span><br><span class="line">    .doubleType()</span><br><span class="line">    .defaultValue(<span class="number">1.0</span>)</span><br><span class="line">    .withDescription(</span><br><span class="line">    <span class="string">"The request factor of memory used by job manager. "</span></span><br><span class="line">+ <span class="string">"The resources request memory will be set to memory * request-factor."</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// taskmanager</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;Double&gt; TASK_MANAGER_CPU_REQUEST_FACTOR =</span><br><span class="line">    key(<span class="string">"kubernetes.taskmanager.cpu.request-factor"</span>)</span><br><span class="line">        .doubleType()</span><br><span class="line">        .defaultValue(<span class="number">1.0</span>)</span><br><span class="line">        .withDescription(</span><br><span class="line">            <span class="string">"The request factor of cpu used by task manager. "</span></span><br><span class="line">                + <span class="string">"The resources request cpu will be set to cpu * request-factor."</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ConfigOption&lt;Double&gt; TASK_MANAGER_MEMORY_REQUEST_FACTOR =</span><br><span class="line">    key(<span class="string">"kubernetes.taskmanager.memory.request-factor"</span>)</span><br><span class="line">        .doubleType()</span><br><span class="line">        .defaultValue(<span class="number">1.0</span>)</span><br><span class="line">        .withDescription(</span><br><span class="line">            <span class="string">"The request factor of memory used by task manager. "</span></span><br><span class="line">                + <span class="string">"The resources request memory will be set to memory * request-factor."</span>);</span><br></pre></td></tr></table></figure><p>2、在 KubernetesJobManagerParameters 和 KubernetesTaskManagerParameters 中分别提供获取参数的方法</p><p>KubernetesJobManagerParameters.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getJobManagerCPURequestFactor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">double</span> requestFactor =</span><br><span class="line">        flinkConfig.getDouble(KubernetesConfigOptions.JOB_MANAGER_CPU_REQUEST_FACTOR);</span><br><span class="line">    checkArgument(</span><br><span class="line">        requestFactor &lt;= <span class="number">1</span>,</span><br><span class="line">        <span class="string">"%s should be less than or equal to 1."</span>,</span><br><span class="line">        KubernetesConfigOptions.JOB_MANAGER_CPU_REQUEST_FACTOR.key());</span><br><span class="line">    <span class="keyword">return</span> requestFactor;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getJobManagerMemoryRequestFactor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">double</span> requestFactor =</span><br><span class="line">        flinkConfig.getDouble(KubernetesConfigOptions.JOB_MANAGER_MEMORY_REQUEST_FACTOR);</span><br><span class="line">    checkArgument(</span><br><span class="line">        requestFactor &lt;= <span class="number">1</span>,</span><br><span class="line">        <span class="string">"%s should be less than or equal to 1."</span>,</span><br><span class="line">        KubernetesConfigOptions.JOB_MANAGER_MEMORY_REQUEST_FACTOR.key());</span><br><span class="line">    <span class="keyword">return</span> requestFactor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>KubernetesTaskManagerParameters.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getTaskManagerCPURequestFactor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">double</span> requestFactor =</span><br><span class="line">        flinkConfig.getDouble(KubernetesConfigOptions.TASK_MANAGER_CPU_REQUEST_FACTOR);</span><br><span class="line">    checkArgument(</span><br><span class="line">        requestFactor &lt;= <span class="number">1</span>,</span><br><span class="line">        <span class="string">"%s should be less than or equal to 1."</span>,</span><br><span class="line">        KubernetesConfigOptions.TASK_MANAGER_CPU_REQUEST_FACTOR.key());</span><br><span class="line">    <span class="keyword">return</span> requestFactor;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getTaskManagerMemoryRequestFactor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">double</span> requestFactor =</span><br><span class="line">        flinkConfig.getDouble(KubernetesConfigOptions.TASK_MANAGER_MEMORY_REQUEST_FACTOR);</span><br><span class="line">    checkArgument(</span><br><span class="line">        requestFactor &lt;= <span class="number">1</span>,</span><br><span class="line">        <span class="string">"%s should be less than or equal to 1."</span>,</span><br><span class="line">        KubernetesConfigOptions.TASK_MANAGER_MEMORY_REQUEST_FACTOR.key());</span><br><span class="line">    <span class="keyword">return</span> requestFactor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、KubernetesUtils.getResourceRequirements() 方法做如下改变，增加 request 因子参数</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2022-03-29-144238.jpg" alt=""></p><p>KubernetesUtils.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Get resource requirements from memory and cpu.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> mem Memory in mb.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> memoryRequestFactor Memory request factor.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> cpu cpu.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> cpuRequestFactor cpu request factor.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> externalResources external resources</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> KubernetesResource requirements.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ResourceRequirements <span class="title">getResourceRequirements</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> mem,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">double</span> memoryRequestFactor,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">double</span> cpu,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">double</span> cpuRequestFactor,</span></span></span><br><span class="line"><span class="function"><span class="params">        Map&lt;String, Long&gt; externalResources)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//todo：cpu 和 内存分别设置一个因子，默认是 0.5，用户设置的资源配置为 limit；request = limit * 因子</span></span><br><span class="line">    <span class="keyword">final</span> Quantity cpuQuantity = <span class="keyword">new</span> Quantity(String.valueOf(cpu));</span><br><span class="line">    <span class="keyword">final</span> Quantity cpuRequestQuantity = <span class="keyword">new</span> Quantity(String.valueOf(cpu * cpuRequestFactor));</span><br><span class="line">    <span class="keyword">final</span> Quantity memQuantity = <span class="keyword">new</span> Quantity(mem + Constants.RESOURCE_UNIT_MB);</span><br><span class="line">    <span class="keyword">final</span> Quantity memRequestQuantity =</span><br><span class="line">        <span class="keyword">new</span> Quantity(((<span class="keyword">int</span>) (mem * memoryRequestFactor)) + Constants.RESOURCE_UNIT_MB);</span><br><span class="line"></span><br><span class="line">    ResourceRequirementsBuilder resourceRequirementsBuilder = <span class="keyword">new</span> ResourceRequirementsBuilder()</span><br><span class="line">        .addToRequests(Constants.RESOURCE_NAME_MEMORY, memRequestQuantity)</span><br><span class="line">        .addToRequests(Constants.RESOURCE_NAME_CPU, cpuRequestQuantity)</span><br><span class="line">        .addToLimits(Constants.RESOURCE_NAME_MEMORY, memQuantity)</span><br><span class="line">        .addToLimits(Constants.RESOURCE_NAME_CPU, cpuQuantity);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add the external resources to resource requirement.</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, Long&gt; externalResource: externalResources.entrySet()) &#123;</span><br><span class="line">        <span class="keyword">final</span> Quantity resourceQuantity = <span class="keyword">new</span> Quantity(String.valueOf(externalResource.getValue()));</span><br><span class="line">        resourceRequirementsBuilder</span><br><span class="line">            .addToRequests(externalResource.getKey(), resourceQuantity)</span><br><span class="line">            .addToLimits(externalResource.getKey(), resourceQuantity);</span><br><span class="line">        LOG.info(<span class="string">"Request external resource &#123;&#125; with config key &#123;&#125;."</span>, resourceQuantity.getAmount(), externalResource.getKey());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> resourceRequirementsBuilder.build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、在 InitJobManagerDecorator 和 InitTaskManagerDecorator 调用上面方法的地方做相应的修改</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2022-03-29-144238.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2022-03-29-144323.jpg" alt=""></p><h3 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h3><p>可以在 flink-conf.yaml 中定义配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">kubernetes.jobmanager.cpu.request-factor:</span> <span class="number">0.5</span></span><br><span class="line"><span class="string">kubernetes.jobmanager.memory.request-factor:</span> <span class="number">0.8</span></span><br><span class="line"><span class="string">kubernetes.taskmanager.cpu.request-factor:</span> <span class="number">0.5</span></span><br><span class="line"><span class="string">kubernetes.taskmanager.memory.request-factor:</span> <span class="number">0.8</span></span><br></pre></td></tr></table></figure><p>当然，用户的作业提交参数中也可以使用上面的参数进行覆盖，最终效果如下：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2022-03-29-144340.jpg" alt=""></p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;在 flink on k8s 默认提交作业的命令下，我们会指定作业的 JM/TM 的 CPU 和 Memory，最后作业生成的 pod 它的 CPU/Memory 的 request/limit 都是一样的资源，但是作业真实运行时使用的资源远达不到 limit 的值，这样就会&lt;strong&gt;造成机器资源浪费&lt;/strong&gt;（水位不高，但是机器又不能再申请 pod）。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>宕机一台机器，结果一百多个 Flink 作业挂了</title>
    <link href="http://www.54tianzhisheng.cn/2021/11/11/flink-akka-framesize/"/>
    <id>http://www.54tianzhisheng.cn/2021/11/11/flink-akka-framesize/</id>
    <published>2021-11-10T16:00:00.000Z</published>
    <updated>2021-11-11T15:33:45.652Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>因宕机了一台物理机器，实时集群不少作业发生 failover，其中大部分作业都能 failover 成功，某个部门的部分作业一直在 failover，始终未成功，到 WebUI 查看作业异常日志如下：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">2021-11-09 16:01:11</span><br><span class="line">java.util.concurrent.CompletionException: java.lang.reflect.UndeclaredThrowableException</span><br><span class="line"> at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)</span><br><span class="line"> at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)</span><br><span class="line"> at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592)</span><br><span class="line"> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line"> at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line"> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)</span><br><span class="line"> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line"> at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: java.lang.reflect.UndeclaredThrowableException</span><br><span class="line"> at com.sun.proxy.$Proxy54.submitTask(Unknown Source)</span><br><span class="line"> at org.apache.flink.runtime.jobmaster.RpcTaskManagerGateway.submitTask(RpcTaskManagerGateway.java:72)</span><br><span class="line"> at org.apache.flink.runtime.executiongraph.Execution.lambda$deploy$10(Execution.java:756)</span><br><span class="line"> at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)</span><br><span class="line"> ... 7 more</span><br><span class="line">Caused by: java.io.IOException: The rpc invocation size 56424326 exceeds the maximum akka framesize.</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.createRpcInvocationMessage(AkkaInvocationHandler.java:276)</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.invokeRpc(AkkaInvocationHandler.java:205)</span><br><span class="line"> at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.invoke(AkkaInvocationHandler.java:134)</span><br><span class="line"> ... 11 more</span><br></pre></td></tr></table></figure><h3 id="解决异常过程"><a href="#解决异常过程" class="headerlink" title="解决异常过程"></a>解决异常过程</h3><p>从上面的异常日志中我们提取到关键信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.io.IOException: The rpc invocation size 56424326 exceeds the maximum akka framesize.</span><br></pre></td></tr></table></figure><p>看起来是 RPC 的消息大小超过了默认的 akka framesize 的最大值了，所以我们来了解一下这个值的默认值，从 <a href="https://nightlies.apache.org/flink/flink-docs-release-1.12/deployment/config.html#akka-framesize">官网</a> 我们可以看的到该值的默认大小为 “10485760b”，并且该参数的描述为：</p><p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gwbm72hedkj31i806imya.jpg" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Maximum size of messages which are sent between the JobManager and the TaskManagers. If Flink fails because messages exceed this limit, then you should increase it. The message size requires a size-unit specifier.</span><br></pre></td></tr></table></figure><p>翻译过来的意思就是：这个参数是 JobManager 和 TaskManagers 之间通信允许的最大消息大小，如果 Flink 作业因为通信消息大小超过了该值，你可以通过增加该值的大小来解决，该参数需要指定一个单位。</p><h3 id="分析原因"><a href="#分析原因" class="headerlink" title="分析原因"></a>分析原因</h3><p>Flink 使用 Akka 作为组件（JobManager/TaskManager/ResourceManager）之间的 RPC 框架，在 JobManager 和 TaskManagers 之间发送的消息的最大大小默认为 10485760b，如果消息超过这个限制就会失败，报错。这个可以看下抛出异常处的源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">protected RpcInvocation createRpcInvocationMessage(String methodName, Class&lt;?&gt;[] parameterTypes, Object[] args) throws IOException &#123;</span><br><span class="line">    Object rpcInvocation;</span><br><span class="line">    if (this.isLocal) &#123;</span><br><span class="line">        rpcInvocation = new LocalRpcInvocation(methodName, parameterTypes, args);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            RemoteRpcInvocation remoteRpcInvocation = new RemoteRpcInvocation(methodName, parameterTypes, args);</span><br><span class="line">            if (remoteRpcInvocation.getSize() &gt; this.maximumFramesize) &#123;</span><br><span class="line">                // 异常所在位置</span><br><span class="line">                throw new IOException(&quot;The rpc invocation size exceeds the maximum akka framesize.&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            rpcInvocation = remoteRpcInvocation;</span><br><span class="line">        &#125; catch (IOException var6) &#123;</span><br><span class="line">            LOG.warn(&quot;Could not create remote rpc invocation message. Failing rpc invocation because...&quot;, var6);</span><br><span class="line">            throw var6;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return (RpcInvocation)rpcInvocation;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至于为什么 JobManager 和 TaskManager 之间的 RPC 消息大小会如此之大，初步的解释是在 task 出现异常之后，它需要调用 updateTaskExecutionState(TaskExecutionState，taskExecutionState) 这个 RPC 接口去通知 Flink Jobmanager 去改变对应 task 的状态并且重启 task。但是呢，taskExecutionState 这个参数里面有个 error 属性，当我的 task 打出来的错误栈太多的时候，在序列化的之后超过了 rpc 接口要求的最大数据大小（也就是 maximum akka framesize），导致调用 updateTaskExecutionState 这个 rpc 接口失败，Jobmanager 无法获知这个 task 已经处于 fail 的状态，也无法重启，然后就导致了一系列连锁反应。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>任务停止，在 <code>flink-conf.yaml</code> 中加入 <code>akka.framesize</code> 参数，调大该值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">akka.framesize: &quot;62914560b&quot;</span><br></pre></td></tr></table></figure><p>然后将任务重启，可以观察 Jobmanager Configration 看看参数是否生效。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;因宕机了一台物理机器，实时集群不少作业发生 failover，其中大部分作业都能 failover 成功，某个部门的部分作业一直在 failover，始终未成功，到 WebUI 查看作业异常日志如下：&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>实时平台如何管理多个 Flink 版本？—— 为啥会出现多个版本？</title>
    <link href="http://www.54tianzhisheng.cn/2021/09/26/realtime-platform-flink-version/"/>
    <id>http://www.54tianzhisheng.cn/2021/09/26/realtime-platform-flink-version/</id>
    <published>2021-09-25T16:00:00.000Z</published>
    <updated>2021-11-14T03:12:49.099Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为啥会出现多个版本？"><a href="#为啥会出现多个版本？" class="headerlink" title="为啥会出现多个版本？"></a>为啥会出现多个版本？</h3><a id="more"></a><ul><li><p><strong>Flink 社区</strong>本身迭代速度非常快，目前阿里云有一大波的人专职做 Flink 开源，另外还拥有活跃的社区贡献者，所以功能开发较快，bug 修复速度较快，几乎每 4 个月一个大版本，每个大版本之间迭代的功能非常多，代码变动非常大，API 接口变动也大，动不动就干翻自己了。</p></li><li><p>社区迭代快就快呗，为什么<strong>公司</strong>也要要不断跟着社区鼻子走？社区迭代快意味着功能多，修复的 bug 多，相对于早期版本意味着稳定性也高些。除了国内一二线公司有特别多的专职人去负责这块，大多数中小公司最简单最快捷体验到稳定性最高、功能性最多、性能最好的 Flink 版本无非是直接使用最新的 Flink 版本。举个例子：Flink SQL 从最早期（1.9）的功能、性能到目前 1.14，差别真的大很多，优化了特别多的地方，增强了很多功能。原先使用 Flink SQL 完成一个流处理任务非常麻烦，还不如直接写几十行代码来的快，目前我情愿写 SQL 去处理一个流任务。那么自然会跟着升级到新版本。</p></li><li><p><strong>用户 A</strong> 问 Flink SQL 支持单独设置并行度吗？<strong>用户 B</strong> 问实时平台现在支持 Flink 1.13 版本的 Window TVF？这个要 Flink xxx 版本才能支持，要不你升级一下 Flink 版本到 xxx？这样就能支持了，类似的场景还有很多，对于<strong>中小公司的实时平台负责人</strong>来说，这无非最省事；对于<strong>大公司的负责实时开发的人</strong>来说，这无疑是一个噩梦，每次升级新版本都要将在老版本开发的各种功能都想尽办法移植到新版本上来，碰到 API 接口变动大的无非相当于重写了，或者将新版本的某些特别需要的功能通过打 patch 的方式打到老版本里面去。</p></li><li><p>新版本香是真的香，可是为啥有的人不用呢？问题就是，实时作业大多数是长期运行的，如果一个作业没啥错误，在生产运行的好好的，也不出啥故障，稳定性和性能也都能接受（并不是所有作业数据量都很大，会遇到性能问题），那么<strong>用户</strong>为啥要使用新版本？用户才不管你新版本功能多牛逼，性能多屌呢，老子升级还要改依赖版本、改接口代码、测试联调、性能测试（谁知道你说的性能提升是不是吹牛逼的）、稳定性测试（可能上线双跑一段时间验证），这些不需要时间呀，你叫我升级就升级，滚犊子吧，你知道我还有多少业务需求要做吗？</p></li></ul><p>那么就落下这个场地了，又要使用新版本的功能去解决问题，老作业的用户跟他各种扯皮也打动不了他升级作业的版本，那么自然就不断的出现了多个版本了。</p><p>这样，如果不对版本做好规划，那么摊子就逐渐越来越大，越来越难收拾了？</p><p>那么该如何管理公司的 Flink 版本？如果管理和兼容多个 Flink 版本的作业提交？如何兼容 Jar 包和 SQL 作业的提交</p><h3 id="怎么管理多个-Flink-版本的作业提交？"><a href="#怎么管理多个-Flink-版本的作业提交？" class="headerlink" title="怎么管理多个 Flink 版本的作业提交？"></a>怎么管理多个 Flink 版本的作业提交？</h3><p>尽请期待下篇文章</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;为啥会出现多个版本？&quot;&gt;&lt;a href=&quot;#为啥会出现多个版本？&quot; class=&quot;headerlink&quot; title=&quot;为啥会出现多个版本？&quot;&gt;&lt;/a&gt;为啥会出现多个版本？&lt;/h3&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 基于 Flink 的实时监控告警系统</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/21/flink-in-action-12.3/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/21/flink-in-action-12.3/</id>
    <published>2021-08-20T16:00:00.000Z</published>
    <updated>2022-02-20T13:15:20.296Z</updated>
    
    <content type="html"><![CDATA[<h2 id="12-3-基于-Flink-的实时监控告警系统"><a href="#12-3-基于-Flink-的实时监控告警系统" class="headerlink" title="12.3 基于 Flink 的实时监控告警系统"></a>12.3 基于 Flink 的实时监控告警系统</h2><p>在如今微服务、云原生等技术盛行的时代，当谈到说要从 0 开始构建一个监控系统，大家无非就首先想到三个词：Metrics、Tracing、Logging。</p><a id="more"></a><h3 id="12-3-1-监控系统的诉求"><a href="#12-3-1-监控系统的诉求" class="headerlink" title="12.3.1 监控系统的诉求"></a>12.3.1 监控系统的诉求</h3><p>国外一篇比较火的文章 <a href="http://peter.bourgon.org/blog/2017/02/21/metrics-tracing-and-logging.html">Metrics, Tracing, and Logging</a> 内有个图很好的总结了一个监控系统的诉求，分别是 Metrics、Logging、Tracing，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-08-132227.png" alt="监控系统的诉求"></p><p>Metrics 的特点：它自己提供了五种基本的度量类型 Gauge、Counter、Histogram、Timer、Meter。</p><p>Tracing 的特点：提供了一个请求从接收到处理完毕整个生命周期的跟踪路径，通常请求都是在分布式的系统中处理，所以也叫做分布式链路追踪。</p><p>Logging 的特点：提供项目应用运行的详细信息，例如方法的入参、运行的异常记录等。</p><p>这三者在监控系统中缺一不可，它们之间的关系是：基于 Metrics 的异常告警事件，然后通过 Tracing 定位问题可疑模块，根据模块详细的日志定位到错误根源，最后再返回来调整 Metrics 的告警规则，以便下次更早的预警，提前预防出现此类问题。</p><h3 id="12-3-2-监控系统包含的内容"><a href="#12-3-2-监控系统包含的内容" class="headerlink" title="12.3.2 监控系统包含的内容"></a>12.3.2 监控系统包含的内容</h3><p>针对提到的三个点，笔者找到国内外的开源监控系统做了对比，发现真正拥有全部功能的比较少，有的系统比较专注于 Logging、有的系统比较专注于 Tracing，而大部分其他的监控系统无非是只是监控系统的一部分，比如是作为一款数据库存储监控数据、作为一个可视化图表的系统去展示各种各样的监控数据信息。</p><p>拿 Logging 来说，开源用的最多最火的技术栈是 ELK，Tracing 这块有 Skywalking、Pinpoint 等技术，它们的对比如 <a href="https://mp.weixin.qq.com/s/_XE-gCJnDY3-yEK4xmWiMg">APM 巅峰对决：Skywalking PK Pinpoint</a> 一文介绍。而存储监控数据的时序数据库那就比较多了，常见的比如 InfluxDB、Prometheus、OpenTSDB 等，它们之间的对比介绍如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-31-%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AF%94%E8%BE%83.png" alt="常见时序数据库对比"></p><p>监控可视化图表的开源系统个人觉得最好看的就是 Grafana，在 8.2 节中搭建 Flink 监控系统的数据展示也是用的 Grafana，当然还可以利用 ECharts、BizCharts 等数据图表库做二次开发来适配公司的数据展示图表。</p><p>上面说了这么多，这里笔者根据自己的工作经验先谈谈几点自己对监控系统的心得：</p><ol><li><strong>告警是监控系统第一入口，图表展示体现监控的价值</strong>：告警是唯一可以第一时间反映运行状态，它承担着系统与人之间的沟通桥梁，通常告警消息又会携带链接跳转到图表展示，它作为第一入口并衔接上了整个监控系统。</li><li><strong>数据采集是监控的源泉</strong>：数据采集是监控系统的源泉，如果采集的数据是错误的，将导致后面的链路（告警、数据展示）全处于无效状态，所以千万千万要保证数据采集的准确性和完整性。</li><li><strong>数据存储是监控最大挑战</strong>：当机器、系统应用和监控指标等变得越多来多时，采集上来的数据是爆炸性增长的，将海量的监控数据实时存储到任何一个数据库，挑战都是不小的。</li></ol><p>说完心得再来讲解到底一个监控系统真正该包含哪些东西呢？笔者觉得首先分 6 层：数据采集层、数据传输层、数据计算层、告警、数据存储、数据展示，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-11-012408.png" alt="监控系统分层"></p><p>监控系统这六层的主要功能分别是：</p><ul><li>数据采集层：该层主要功能就是去采集各种各样的数据，比如 Metrics、Logging、Tracing 数据。</li><li>数据传输层：该层主要功能就是传输采集到的监控数据，一般使用消息队列居多，比如 Kafka、RocketMQ 等。</li><li>数据计算层：该层的主要功能是将采集到的数据进行数据清洗和计算，一般采用 Flink、Spark 等计算引擎来处理。</li><li>告警：该层其实也属于数据计算层，但是因为告警涉及的内容太多，比如告警规则、告警计算、告警通知等，所以可以单独作为一个重要点来讲。</li><li>数据存储层：该层的主要功能是存储所有的监控数据，为后面的数据可视化提供数据源。</li><li>数据展示层：该层的主要功能是将监控数据通过可视化图表来展示出来，通过图表可以知道服务器、应用的运行状态。</li></ul><h3 id="12-3-3-Metrics／Tracing／Logging-数据实时采集"><a href="#12-3-3-Metrics／Tracing／Logging-数据实时采集" class="headerlink" title="12.3.3 Metrics／Tracing／Logging 数据实时采集"></a>12.3.3 Metrics／Tracing／Logging 数据实时采集</h3><p>在 12.1 节中讲解了日志数据如何采集，那么对于 Metrics 和 Tracing 数据该怎么采集呢？</p><h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><h4 id="Tracing"><a href="#Tracing" class="headerlink" title="Tracing"></a>Tracing</h4><h3 id="12-3-4-消息队列如何撑住高峰流量"><a href="#12-3-4-消息队列如何撑住高峰流量" class="headerlink" title="12.3.4 消息队列如何撑住高峰流量"></a>12.3.4 消息队列如何撑住高峰流量</h3><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><h4 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h4><h3 id="12-3-5-指标数据实时计算"><a href="#12-3-5-指标数据实时计算" class="headerlink" title="12.3.5 指标数据实时计算"></a>12.3.5 指标数据实时计算</h3><h3 id="12-3-6-提供及时且准确的根因分析告警"><a href="#12-3-6-提供及时且准确的根因分析告警" class="headerlink" title="12.3.6 提供及时且准确的根因分析告警"></a>12.3.6 提供及时且准确的根因分析告警</h3><h4 id="告警本质"><a href="#告警本质" class="headerlink" title="告警本质"></a>告警本质</h4><h4 id="告警通知对象"><a href="#告警通知对象" class="headerlink" title="告警通知对象"></a>告警通知对象</h4><h4 id="告警通知方式"><a href="#告警通知方式" class="headerlink" title="告警通知方式"></a>告警通知方式</h4><h4 id="告警规则的设计"><a href="#告警规则的设计" class="headerlink" title="告警规则的设计"></a>告警规则的设计</h4><h4 id="根因分析告警"><a href="#根因分析告警" class="headerlink" title="根因分析告警"></a>根因分析告警</h4><h4 id="告警事件解耦"><a href="#告警事件解耦" class="headerlink" title="告警事件解耦"></a>告警事件解耦</h4><h4 id="告警工单记录告警解决过程"><a href="#告警工单记录告警解决过程" class="headerlink" title="告警工单记录告警解决过程"></a>告警工单记录告警解决过程</h4><h3 id="12-3-7-AIOps-智能运维道路探索"><a href="#12-3-7-AIOps-智能运维道路探索" class="headerlink" title="12.3.7 AIOps 智能运维道路探索"></a>12.3.7 AIOps 智能运维道路探索</h3><h3 id="12-3-8-如何保障高峰流量实时写入存储系统的稳定性"><a href="#12-3-8-如何保障高峰流量实时写入存储系统的稳定性" class="headerlink" title="12.3.8 如何保障高峰流量实时写入存储系统的稳定性"></a>12.3.8 如何保障高峰流量实时写入存储系统的稳定性</h3><h3 id="12-3-9-监控数据使用可视化图表展示"><a href="#12-3-9-监控数据使用可视化图表展示" class="headerlink" title="12.3.9 监控数据使用可视化图表展示"></a>12.3.9 监控数据使用可视化图表展示</h3><h4 id="Grafana-介绍"><a href="#Grafana-介绍" class="headerlink" title="Grafana 介绍"></a>Grafana 介绍</h4><h3 id="12-3-10-小结与反思"><a href="#12-3-10-小结与反思" class="headerlink" title="12.3.10 小结与反思"></a>12.3.10 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/IeAYbEy">https://t.zsxq.com/IeAYbEy</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="本章总结"><a href="#本章总结" class="headerlink" title="本章总结"></a>本章总结</h3><p>本章讲了三个公司常见场景案例：日志处理、去重、监控告警。在日志处理案例中讲解了日志的采集的需求，以及分析了整个日志采集案例的架构设计分层，关于日志采集工具的选型在 11.5 节中有讲过，所以该案例中就直接讲述采集工具的使用和安装，并将采集到的数据发送到 Kafka，然后使用 Flink 清洗日志数据并将异常日志告警通知到相应负责人，接着将数据写入到 ElasticSearch，最后通过 Kibana 可以展示和搜索日志数据。</p><p>在百亿数据实时去重案例中通过对比通用解决方法、使用 BloomFilter、使用 HBase 和使用 Flink KeyedState 几种方案来分析实时去重的解决方案，并在该案例中还提及到如何去优化去重的效果。</p><p>在实时监控告警案例中讲述了公司通用的监控告警需求，包括 Metrics、Logging、Tracing，然后设计出整个监控告警系统的架构分层和技术选型，其中分层包含数据采集层、数据传输层、数据计算层、数据存储层、数据展示层。关于数据采集工具、消息队列、数据存储中间件、数据展示的技术选型，笔者也分别做了对比介绍，以便大家可以根据自己公司的情况做架构选型。另外针对实时告警这块，笔者也详述了很多，包括告警规则的设计、告警通知对象、告警通知方式、告警消息收敛、告警消息根因分析等，最后还讲了对监控告警的展望，希望能够在 AIOps 做更多的探索，对于这块的内容，笔者在社区钉钉群做过视频直播，大家可以去笔者的博客查看录播的视频。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;12-3-基于-Flink-的实时监控告警系统&quot;&gt;&lt;a href=&quot;#12-3-基于-Flink-的实时监控告警系统&quot; class=&quot;headerlink&quot; title=&quot;12.3 基于 Flink 的实时监控告警系统&quot;&gt;&lt;/a&gt;12.3 基于 Flink 的实时监控告警系统&lt;/h2&gt;&lt;p&gt;在如今微服务、云原生等技术盛行的时代，当谈到说要从 0 开始构建一个监控系统，大家无非就首先想到三个词：Metrics、Tracing、Logging。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 基于 Flink 的百亿数据去重实践</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/20/flink-in-action-12.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/20/flink-in-action-12.2/</id>
    <published>2021-08-19T16:00:00.000Z</published>
    <updated>2022-02-20T13:10:49.299Z</updated>
    
    <content type="html"><![CDATA[<h2 id="12-2-基于-Flink-的百亿数据去重实践"><a href="#12-2-基于-Flink-的百亿数据去重实践" class="headerlink" title="12.2 基于 Flink 的百亿数据去重实践"></a>12.2 基于 Flink 的百亿数据去重实践</h2><p>在工作中经常会遇到去重的场景，例如基于 APP 的用户行为日志分析系统：用户的行为日志从手机 APP 端上报到 Nginx 服务端，然后通过 Logstash、Flume 或其他工具将日志从 Nginx 写入到 Kafka 中。由于用户手机客户端的网络可能出现不稳定，所以手机 APP 端上传日志的策略是：宁可重复上报，也不能漏报日志，所以导致 Kafka 中可能会出现日志重复的情况，即：同一条日志出现了 2 条或 2 条以上。通常情况下，Flink 任务的数据源都是 Kafka，若 Kafka 中数据出现了重复，在实时 ETL 或者流计算时都需要考虑基于日志主键对日志进行去重，否则会导致流计算结果偏高或结果不准确的问题，例如用户 a 在某个页面只点击了一次，但由于日志重复上报，所以用户 a 在该页面的点击日志在 Kafka 中出现了 2 次，最后统计该页面的点击数时，结果就会偏高。这里只阐述了一种可能造成 Kafka 中数据重复的情况，在生产环境中很多情况都可能造成 Kafka 中数据重复，这里不一一列举，本节主要讲述出现了数据重复后，该如何处理。</p><a id="more"></a><h3 id="12-2-1-去重的通用解决方案"><a href="#12-2-1-去重的通用解决方案" class="headerlink" title="12.2.1 去重的通用解决方案"></a>12.2.1 去重的通用解决方案</h3><p>Kafka 中数据出现重复后，各种解决方案都比较类似，一般需要一个全局 Set 集合来维护历史所有数据的主键。当处理新日志时，需要拿到当前日志的主键与历史数据的 Set 集合按照规则进行比较，若 Set 集合中已经包含了当前日志的主键，说明当前日志在之前已经被处理过了，则当前日志应该被过滤掉，否则认为当前日志不应该被过滤应该被处理，而且处理完成后需要将新日志的主键加入到 Set 集合中，Set 集合永远存放着所有已经被处理过的数据。这种去重的通用解决方案的流程图如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-11-151455.png" alt="去重的通用解决方案的流程图"></p><p>处理流程很简单，关键在于如何维护这个 Set 集合，可以简单估算一下这个 Set 集合需要占用多大空间。本小节要解决的问题是百亿数据去重，所以就按照每天 1 百亿的数据量来计算。由于每天数据量巨大，因此主键占用空间通常会比较大，如果主键占用空间小意味着表示的数据范围就比较小，就可能导致主键冲突，例如：4 个字节的 int 类型表示数据范围是为 -2147483648 ~ 2147483647，总共可以表示 42 亿个数，如果这里每天百亿的数据量选用 int 类型做为主键的话，很明显会有大量的主键发生冲突，会将不重复的数据认为是发生了重复。用户的行为日志是在手机客户端生成的，没有全局发号器，一般会选取 UUID 做为日志的主键，UUID 会生成 36 位的字符串，例如：”f106c4a1-4c6f-41c1-9d30-bbb2b271284a”。每个主键占用 36 字节，每天 1 百亿数据，36字节 <em> 100亿 ≈ 360 GB。这仅仅是一天的数据量，所以该 Set 集合要想存储空间不发生持续地爆炸式增长，必须增加一个功能，那就是给所有的主键增加 TTL（过期时间）。如果不增加 TTL，10 天数据量的主键占用空间就 3.6T，100 天数据量的主键占用空间 36T，所以在设计之初必须考虑为主键设定 TTL。如果要求按天进行去重或者认为日志发生重复上报的时间间隔不可能大于 24 小时，那么为了系统的可靠性 TTL 可以设置为 36 小时。每天数据量 1 百亿，且 Set 集合中存放着 36 小时的数据量，即 100 亿 </em> 1.5 = 150 亿，所以 Set 集合中需要维护 150 亿的数据量，且 Set 集合中每条数据都增加了 TTL，意味着 Set 集合需要为每条数据再附带保存一个时间戳，来确定该数据什么时候过期。例如 Redis 中为一个 key 设置了 TTL，如果没有为这个 key 附带时间戳，那么根本无法判断该 key 什么时候应该被清理。所以在考虑每条数据占用空间时，不仅要考虑数据本身，还需要考虑是否需要其他附带的存储。主键本身占用 36 字节加上 long 类型的时间戳 8 字节，所以每条数据至少需要占用 44 字节，150 亿 * 44 字节 = 660 GB。所以每天百亿的数据量，如果我们使用 Set 集合的方案来实现，至少需要占用 660 GB 以上的存储空间。</p><h3 id="12-2-2-使用-BloomFilter-实现去重"><a href="#12-2-2-使用-BloomFilter-实现去重" class="headerlink" title="12.2.2 使用 BloomFilter 实现去重"></a>12.2.2 使用 BloomFilter 实现去重</h3><p>有些流计算的场景对准确性要求并不是很高，例如传统的 Lambda 架构中，都会有离线去矫正实时计算的结果，所以根据业务场景，当业务要求可以接受结果有小量误差时，可以选择使用一些低成本的数据结构。BloomFilter 和 HyperLogLog 都是相对低成本的数据结构，分别有自己的应用场景，且两种数据结构都有一定误差。HyperLogLog 可以估算出 HyperLogLog 中插入了多少个不重复的元素，而不能告诉我们之前是否插入了哪些元素。BloomFilter 则恰好相反，相对而言 BloomFilter 更像是一个 Set 集合，BloomFilter 可以告诉你 BloomFilter 中<strong>肯定不包含</strong>元素 a，或者告诉你 BloomFilter 中<strong>可能包含</strong>元素 b，但 BloomFilter 不能告诉你 BloomFilter 中插入了多少个元素。接下来了解一下 BloomFilter 的实现原理。</p><h4 id="bitmap-位图"><a href="#bitmap-位图" class="headerlink" title="bitmap 位图"></a>bitmap 位图</h4><p>了解 BloomFilter，从 bitmap（位图）开始说起。现在有 1 千万个整数，数据范围在 0 到 2 千万之间。如何快速查找某个整数是否在这 1 千万个整数中呢？可以将这 1 千万个数保存在 HashMap 中，不考虑对象头及其他空间，1000 万个 int 类型数据需要占用大约 1000万 * 4 字节 ≈ 40 MB 存储空间。有没有其他方案呢？因为数据范围是 0 到 2 千万，所以可以申请一个长度为 2000 万、boolean 类型的数组，将这 2 千万个整数作为数组下标，将其对应的数组默认值设置成 false，如下图所示，数组下标为 2、666、999 的位置存储的数据为 true，表示 1 千万个数中包含了 2、666、999 等。当查询某个整数 K 是否在这 1 千万个整数中时，只需要将对应的数组值 <code>array[K]</code> 取出来，看是否等于 true。如果等于 true，说明 1 千万整数中包含这个整数 K，否则表示不包含这个整数 K。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-03-103907.jpg" alt=""></p><p>Java 的 boolean 基本类型占用一个字节（8bit）的内存空间，所以上述方案需要申请 2000 万字节。如下图所示，可以通过编程语言用二进制位来模拟布尔类型，二进制的 1 表示true、二进制的 0 表示false。通过二进制模拟布尔类型的方案，只需要申请 2000 万 bit 即可，相比 boolean 类型而言，存储空间占用仅为原来的 1/8。2000 万 bit ≈ 2.4 MB，相比存储原始数据的方案 40 MB 而言，占用的存储空间少了很多。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-03-103905.jpg" alt=""></p><p>假如这 1 千万个整数的数据范围是 0 到 100 亿，那么就需要申请 100 亿个 bit 约等于 1200 MB，比存储原始数据方案的 40MB 还要大很多。该情况下，直接使用位图使用的存储空间更多了，怎么解决呢？可以只申请 1 亿 bit 的存储空间，对 1000 万个数求hash，映射到 1 亿的二进制位上，最后大约占用 12 MB 的存储空间，但是可能存在 hash 冲突的情况。例如 3 和 100000003（一亿零三）这两个数对一亿求余都为 3，所以映射到长度为 1 亿的位图上，这两个数会占用同一个 bit，就会导致一个问题：1 千万个整数中包含了一亿零三，所以位图中下标为 3 的位置存储着二进制 1。当查询 1 千万个整数中是否包含数字 3 时，同样也是去位图中下标 3 的位置去查找，发现下标为 3 的位置存储着二进制 1，所以误以为 1 千万个整数中包含数字 3。为了减少 hash 冲突，于是诞生了 BloomFilter。</p><h4 id="BloomFilter-原理介绍"><a href="#BloomFilter-原理介绍" class="headerlink" title="BloomFilter 原理介绍"></a>BloomFilter 原理介绍</h4><p>hash 存在 hash 冲突（碰撞）的问题，两个不同的 key 通过同一个 hash 函数得到的值有可能相同。为了减少冲突，可以引入多个 hash 函数，如果通过其中的一个 hash 函数发现某元素不在集合中，那么该元素肯定不在集合中。当所有的 hash 函数告诉我们该元素在集合中时，才能确定该元素存在于集合中，这便是BloomFilter的基本思想。</p><p>如下图所示，是往 BloomFilter 中插入元素 a、b 的过程，有 3 个 hash 函数，元素 a 经过 3 个 hash 函数后对应的 2、8、10 这三个二进制位，所以将这三个二进制位置为 1，元素 b  经过 3 个 hash 函数后，对应的 5、10、14 这三个二进制位，将这三个二进制位也置为 1，其中下标为 10 的二进制位被 a、b 元素都涉及到。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-03-103858.jpg" style="zoom:20%;" /></p><p>如下图所示，是从 BloomFilter 中查找元素 c、d 的过程，同样包含了 3 个 hash 函数，元素 c 经过 3 个 hash 函数后对应的 2、6、9 这三个二进制位，其中下标 6 和 9 对应的二进制位为 0，所以会认为 BloomFilter 中不存在元素 c。元素 d 经过 3 个 hash 函数后对应的 5、8、14 这三个二进制位，这三个位对应的二进制位都为 1，所以会认为 BloomFilter 中存在元素 d，但其实 BloomFilter 中并不存在元素 d，是因为元素 a 和元素 b 也对应到了 5、8、14 这三个二进制位上，所以 BloomFilter 会有误判。但是从实现原理来看，当 BloomFilter 告诉你不包含元素 c 时，BloomFilter 中<strong>肯定不包含</strong>元素 c，当 BloomFilter 告诉你 BloomFilter 中包含元素 d 时，它只是<strong>可能包含</strong>，也有可能不包含。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-03-103906.jpg" style="zoom:20%;" /></p><h4 id="使用-BloomFilter-实现数据去重"><a href="#使用-BloomFilter-实现数据去重" class="headerlink" title="使用 BloomFilter 实现数据去重"></a>使用 BloomFilter 实现数据去重</h4><p>Redis 4.0 之后 BloomFilter 以插件的形式加入到 Redis 中，关于 api 的具体使用这里不多赘述。BloomFilter 在创建时支持设定一个预期容量和误判率，预期容量即预计插入的数据量，误判率即：当 BloomFilter 中插入的数据达到预期容量时，误判的概率，如果 BloomFilter 中插入数据较少的话，误判率会更低。</p><p>经笔者测试，申请一个预期容量为 10 亿，误判率为千分之一的 BloomFilter，BloomFilter 会申请约 143 亿个 bit，即：14G左右，相比之前 660G 的存储空间小太多了。但是在使用过程中，需要记录 BloomFilter 中插入元素的个数，当插入元素个数达到 10 亿时，为了保障误差率，可以将当前 BloomFilter 清除，重新申请一个新的 BloomFilter。</p><p>通过使用 Redis 的 BloomFilter，我们可以通过相对较小的内存实现百亿数据的去重，但是 BloomFilter 有误差，所以只能使用在那些对结果能承受一定误差的应用场景，对于广告计费等对数据精度要求非常高的场景，极力推荐大家使用精准去重的方案来实现。</p><h3 id="12-2-3-使用-HBase-维护全局-Set-实现去重"><a href="#12-2-3-使用-HBase-维护全局-Set-实现去重" class="headerlink" title="12.2.3 使用 HBase 维护全局 Set 实现去重"></a>12.2.3 使用 HBase 维护全局 Set 实现去重</h3><p>通过之前分析，我们知道要想实现百亿数据量的精准去重，需要维护 150 亿数据量的 Set 集合，每条数据占用 44 KB，总共需要 660 GB 的存储空间。注意这里说的是存储空间而不是内存空间，为什么呢？因为 660 G 的内存实在是太贵了，660G 的 Redis 云服务一个月至少要 2 万 RMB 以上，俗话说设计架构不考虑成本等于耍流氓。这里使用 Redis 确实可以解决问题，但是成本较高。HBase 基于 RowKey Get 的效率比较高，所以这里可以考虑将这个大的 Set 集合以 HBase RowKey 的形式存放到 HBase 中。HBase 表设置 TTL 为 36 小时，最近 36 小时的 150 亿条日志的主键都存放到 HBase 中，每来一条数据，先拿到主键去 HBase 中查询，如果 HBase 表中存在该主键，说明当前日志已经被处理过了，当前日志应该被过滤。如果 HBase 表中不存在该主键，说明当前日志之前没有被处理过，此时应该被处理，且处理完成后将当前主键 Put 到 HBase 表中。由于数据量比较大，所以一定要提前对 HBase 表进行预分区，将压力分散到各个 RegionServer 上。</p><h4 id="使用-HBase-RowKey-去重带来的问题"><a href="#使用-HBase-RowKey-去重带来的问题" class="headerlink" title="使用 HBase RowKey 去重带来的问题"></a>使用 HBase RowKey 去重带来的问题</h4><h3 id="12-2-4-使用-Flink-的-KeyedState-实现去重"><a href="#12-2-4-使用-Flink-的-KeyedState-实现去重" class="headerlink" title="12.2.4 使用 Flink 的 KeyedState 实现去重"></a>12.2.4 使用 Flink 的 KeyedState 实现去重</h3><p>下面就教大家如何使用 Flink 的 KeyedState 实现去重。</p><h4 id="使用-Flink-状态来维护-Set-集合的优势"><a href="#使用-Flink-状态来维护-Set-集合的优势" class="headerlink" title="使用 Flink 状态来维护 Set 集合的优势"></a>使用 Flink 状态来维护 Set 集合的优势</h4><h4 id="如何使用-KeyedState-维护-Set-集合"><a href="#如何使用-KeyedState-维护-Set-集合" class="headerlink" title="如何使用 KeyedState 维护 Set 集合"></a>如何使用 KeyedState 维护 Set 集合</h4><h4 id="优化主键来减少状态大小，且提高吞吐量"><a href="#优化主键来减少状态大小，且提高吞吐量" class="headerlink" title="优化主键来减少状态大小，且提高吞吐量"></a>优化主键来减少状态大小，且提高吞吐量</h4><h3 id="12-2-5-使用-RocksDBStateBackend-的优化方法"><a href="#12-2-5-使用-RocksDBStateBackend-的优化方法" class="headerlink" title="12.2.5 使用 RocksDBStateBackend 的优化方法"></a>12.2.5 使用 RocksDBStateBackend 的优化方法</h3><p>在使用上述方案的过程中，可能会出现吞吐量时高时低，或者吞吐量比笔者的测试性能要低一些，当出现这类问题的时候，可以尝试从以下几个方面进行优化。</p><h4 id="设置本地-RocksDB-的数据目录"><a href="#设置本地-RocksDB-的数据目录" class="headerlink" title="设置本地 RocksDB 的数据目录"></a>设置本地 RocksDB 的数据目录</h4><h4 id="Checkpoint-参数相关配置"><a href="#Checkpoint-参数相关配置" class="headerlink" title="Checkpoint 参数相关配置"></a>Checkpoint 参数相关配置</h4><h4 id="RocksDB-参数相关配置"><a href="#RocksDB-参数相关配置" class="headerlink" title="RocksDB 参数相关配置"></a>RocksDB 参数相关配置</h4><h3 id="12-2-6-小结与反思"><a href="#12-2-6-小结与反思" class="headerlink" title="12.2.6 小结与反思"></a>12.2.6 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/IeAYbEy">https://t.zsxq.com/IeAYbEy</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;12-2-基于-Flink-的百亿数据去重实践&quot;&gt;&lt;a href=&quot;#12-2-基于-Flink-的百亿数据去重实践&quot; class=&quot;headerlink&quot; title=&quot;12.2 基于 Flink 的百亿数据去重实践&quot;&gt;&lt;/a&gt;12.2 基于 Flink 的百亿数据去重实践&lt;/h2&gt;&lt;p&gt;在工作中经常会遇到去重的场景，例如基于 APP 的用户行为日志分析系统：用户的行为日志从手机 APP 端上报到 Nginx 服务端，然后通过 Logstash、Flume 或其他工具将日志从 Nginx 写入到 Kafka 中。由于用户手机客户端的网络可能出现不稳定，所以手机 APP 端上传日志的策略是：宁可重复上报，也不能漏报日志，所以导致 Kafka 中可能会出现日志重复的情况，即：同一条日志出现了 2 条或 2 条以上。通常情况下，Flink 任务的数据源都是 Kafka，若 Kafka 中数据出现了重复，在实时 ETL 或者流计算时都需要考虑基于日志主键对日志进行去重，否则会导致流计算结果偏高或结果不准确的问题，例如用户 a 在某个页面只点击了一次，但由于日志重复上报，所以用户 a 在该页面的点击日志在 Kafka 中出现了 2 次，最后统计该页面的点击数时，结果就会偏高。这里只阐述了一种可能造成 Kafka 中数据重复的情况，在生产环境中很多情况都可能造成 Kafka 中数据重复，这里不一一列举，本节主要讲述出现了数据重复后，该如何处理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 基于 Flink 实时处理海量日志</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/19/flink-in-action-12.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/19/flink-in-action-12.1/</id>
    <published>2021-08-18T16:00:00.000Z</published>
    <updated>2022-02-20T13:07:36.232Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第十二章-——-Flink-案例"><a href="#第十二章-——-Flink-案例" class="headerlink" title="第十二章 —— Flink 案例"></a>第十二章 —— Flink 案例</h1><p>本章将介绍 Flink 在多个场景下落地实现的大型案例，第一个是实时处理海量的日志，将从日志的收集、日志的传输、日志的实时清洗和异常检测、日志存储、日志展示等方面去介绍 Flink 在其中起的作用，希望整个日志处理的架构大家可以灵活的运用在自己的公司；第二个是百亿数据量的情况下如何使用 Flink 实时去重，在这个案例中将对比介绍其他几种常见的去重实现方案；第三个是 Flink 在监控告警系统中的落地实现，在这个案例中同样很详细的介绍了一个监控告警系统的全链路，每一个关节都不可或缺，并且还介绍了 Flink 在未来结合机器学习算法做一些 AIOps 的事情。三个案例都比较典型，如果你也在做类似的项目，希望对你们的技术选型有一定的帮助。</p><h2 id="12-1-基于-Flink-实时处理海量日志"><a href="#12-1-基于-Flink-实时处理海量日志" class="headerlink" title="12.1 基于 Flink 实时处理海量日志"></a>12.1 基于 Flink 实时处理海量日志</h2><p>在 11.5 节中讲解了 Flink 如何实时处理异常的日志，并且对比分析了几种常用的日志采集工具。我们也知道通常在排查线上异常故障的时候，日志是必不可缺的一部分，通过异常日志我们可以快速的定位到问题的根因。那么通常在公司对于日志处理有哪些需求呢？</p><a id="more"></a><h3 id="12-1-1-实时处理海量日志需求分析"><a href="#12-1-1-实时处理海量日志需求分析" class="headerlink" title="12.1.1 实时处理海量日志需求分析"></a>12.1.1 实时处理海量日志需求分析</h3><p>现在公司都在流行构建分布式、微服务、云原生的架构，在这类架构下，项目应用的日志都被分散到不同的机器上，日志查询就会比较困难，所以统一的日志收集几乎也是每家公司必不可少的。据笔者调研，不少公司现在是有日志统一的收集，也会去做日志的实时 ETL，利用一些主流的技术比如 ELK 去做日志的展示、搜索和分析，但是却缺少了日志的实时告警。总结来说，大部分公司对于日志这块的现状是：</p><ul><li><strong>日志分布零散</strong>：分布式应用导致日志分布在不同的机器上，人肉登录到机器上操作复杂，需要统一的日志收集工具。</li><li><strong>异常日志无告警</strong>：出错时无异常日志告警，导致错过最佳定位问题的时机，需要异常错误日志的告警。</li><li><strong>日志查看不友好</strong>：登录服务器上在终端查看日志不太方便，需要一个操作友好的页面去查看日志。</li><li><strong>无日志搜索分析</strong>：历史日志文件太多，想找某种日志找不到了，需要一个可以搜索日志的功能。</li></ul><p>在本节中，笔者将为大家讲解日志的全链路，包含了日志的实时采集、日志的 ETL、日志的实时监控告警、日志的存储、日志的可视化图表展示与搜索分析等。</p><h3 id="12-1-2-实时处理海量日志架构设计"><a href="#12-1-2-实时处理海量日志架构设计" class="headerlink" title="12.1.2 实时处理海量日志架构设计"></a>12.1.2 实时处理海量日志架构设计</h3><p>分析完我们这个案例的需求后，接下来对整个项目的架构做一个合理的设计。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-27-145059.png" alt=""></p><p>整个架构分为五层：日志接入层、日志削峰层、日志处理层、日志存储层、日志展示层。</p><ul><li>日志接入层：日志采集的话使用的是 Filebeat 组件，需要在每台机器上部署一个 Filebeat。</li><li>日志削峰层：防止日志流量高峰，使用 Kafka 消息队列做削峰。</li><li>日志处理层：Flink 作业同时消费 Kafka 数据做日志清洗、ETL、实时告警。</li><li>日志存储层：使用 ElasticSearch 做日志的存储。</li><li>日志展示层：使用 Kibana 做日志的展示与搜索查询界面。</li></ul><h3 id="12-1-3-日志实时采集"><a href="#12-1-3-日志实时采集" class="headerlink" title="12.1.3 日志实时采集"></a>12.1.3 日志实时采集</h3><p>在 11.5.1 中对比了这几种比较流行的日志采集工具（Logstash、Filebeat、Fluentd、Logagent），从功能完整性、性能、成本、使用难度等方面综合考虑后，这里演示使用的是 Filebeat。</p><h4 id="安装-Filebeat"><a href="#安装-Filebeat" class="headerlink" title="安装 Filebeat"></a>安装 Filebeat</h4><p>在服务器上下载 <a href="https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-linux-x86_64.tar.gz">Fliebeat 6.3.2</a> 安装包（请根据自己服务器和所需要的版本进行下载），下载后进行解压。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xzf filebeat-6.3.2-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure><h4 id="配置-Filebeat"><a href="#配置-Filebeat" class="headerlink" title="配置 Filebeat"></a>配置 Filebeat</h4><p>配置 Filebeat 需要编辑 Filebeat 的配置文件 <code>filebeat.yml</code>，不同安装方式配置文件的存放路径有一些不同，对于解压包安装的方式，配置文件存在解压目录下面；对于 rpm 和 deb 的方式, 配置文件路径的是 <code>/etc/filebeat/filebeat.yml</code> 下。</p><p>因为 Filebeat 是要实时采集日志的，所以得让 Filebeat 知道日志的路径是在哪里，下面在配置文件中定义一下日志文件的路径。通常建议在服务器上固定存放日志的路径，然后应用的日志都打在这个固定的路径中，这样 Filebeat 的日志路径配置只需要填写一次，其他机器上可以拷贝同样的配置就能将 Filebeat 运行起来，配置如下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- type: log</span><br><span class="line">  # 配置为 true 表示开启</span><br><span class="line">  enabled: true</span><br><span class="line">  # 日志的路径</span><br><span class="line">  paths:</span><br><span class="line">    - /var/logs/*.log</span><br></pre></td></tr></table></figure><p>上面的配置表示将对 /var/logs 目录下所有以 .log 结尾的文件进行采集，接下来配置日志输出的方式，这里使用的是 Kafka，配置如下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">output.kafka:</span><br><span class="line">  # 填写 Kafka 地址信息</span><br><span class="line">  hosts: [&quot;localhost:9092&quot;]</span><br><span class="line">  # 数据发到哪个 topic</span><br><span class="line">  topic: zhisheng-log</span><br><span class="line">  partition.round_robin:</span><br><span class="line">    reachable_only: false</span><br><span class="line">  required_acks: 1</span><br></pre></td></tr></table></figure><p>上面讲解的两个配置，笔者这里将它们写在一个新建的配置文件中 kafka.yml，然后启动 Filebeat 的时候使用该配置。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/var/logs/*.log</span></span><br><span class="line"><span class="string">output.kafka:</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">["localhost:9092"]</span></span><br><span class="line"><span class="attr">  topic:</span> <span class="string">zhisheng_log</span></span><br><span class="line">  <span class="string">partition.round_robin:</span></span><br><span class="line"><span class="attr">    reachable_only:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">  required_acks:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h4 id="启动-Filebeat"><a href="#启动-Filebeat" class="headerlink" title="启动 Filebeat"></a>启动 Filebeat</h4><p>日志路径的配置和 Kafka 的配置都写好后，则接下来通过下面命令将 Filebeat 启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/filebeat -e -c kafka.yml</span><br></pre></td></tr></table></figure><p>执行完命令后出现的日志如下则表示启动成功了，另外还可以看得到会在终端打印出 metrics 数据出来。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-26-075438.png" alt=""></p><h4 id="验证-Filebeat-是否将日志数据发到-Kafka"><a href="#验证-Filebeat-是否将日志数据发到-Kafka" class="headerlink" title="验证 Filebeat 是否将日志数据发到 Kafka"></a>验证 Filebeat 是否将日志数据发到 Kafka</h4><p>那么此时就得去查看是否真正就将这些日志数据发到 Kafka 了呢，你可以通过 Kafka 的自带命令去消费这个 Topic 看是否不断有数据发出来，命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --zookeeper 106.54.248.27:2181 --topic zhisheng_log --from-beginning</span><br></pre></td></tr></table></figure><p>如果出现数据则代表是已经有数据发到 Kafka 了，如果你不喜欢使用这种方式验证，可以自己写个 Flink Job 去读取 Kafka 该 Topic 的数据，比如写了个作业运行结果如下就代表着日志数据已经成功发送到 Kafka。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-27-150039.png" alt=""></p><h4 id="发到-Kafka-的日志结构"><a href="#发到-Kafka-的日志结构" class="headerlink" title="发到 Kafka 的日志结构"></a>发到 Kafka 的日志结构</h4><p>既然数据都已经发到 Kafka 了，通过消费 Kafka 该 Topic 的数据我们可以发现这些数据的格式否是 JSON，结构如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"@timestamp"</span>: <span class="string">"2019-10-26T08:18:18.087Z"</span>,</span><br><span class="line"><span class="attr">"@metadata"</span>: &#123;</span><br><span class="line"><span class="attr">"beat"</span>: <span class="string">"filebeat"</span>,</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"doc"</span>,</span><br><span class="line"><span class="attr">"version"</span>: <span class="string">"6.8.4"</span>,</span><br><span class="line"><span class="attr">"topic"</span>: <span class="string">"zhisheng_log"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"prospector"</span>: &#123;</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"log"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"input"</span>: &#123;</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"log"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"beat"</span>: &#123;</span><br><span class="line"><span class="attr">"name"</span>: <span class="string">"VM_0_2_centos"</span>,</span><br><span class="line"><span class="attr">"hostname"</span>: <span class="string">"VM_0_2_centos"</span>,</span><br><span class="line"><span class="attr">"version"</span>: <span class="string">"6.8.4"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"host"</span>: &#123;</span><br><span class="line"><span class="attr">"name"</span>: <span class="string">"VM_0_2_centos"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"source"</span>: <span class="string">"/var/logs/middleware/kafka.log"</span>,</span><br><span class="line"><span class="attr">"offset"</span>: <span class="number">9460</span>,</span><br><span class="line"><span class="attr">"log"</span>: &#123;</span><br><span class="line"><span class="attr">"file"</span>: &#123;</span><br><span class="line"><span class="attr">"path"</span>: <span class="string">"/var/logs/middleware/kafka.log"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"message"</span>: <span class="string">"2019-10-26 16:18:11 TRACE [Controller id=0] Leader imbalance ratio for broker 0 is 0.0 (kafka.controller.KafkaController)"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个日志结构里面包含了很多字段，比如 timestamp、metadata、host、source、message 等，但是其中某些字段我们其实根本不需要的，你可以根据公司的需求丢弃一些字段，把要丢弃的字段也配置在 kafka.yml 中，如下所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">processors:</span><br><span class="line">- drop_fields:</span><br><span class="line">    fields: [&quot;prospector&quot;,&quot;input&quot;,&quot;beat&quot;,&quot;log&quot;,&quot;offset&quot;,&quot;@metadata&quot;]</span><br></pre></td></tr></table></figure><p>然后再次启动 Filebeat ，发现上面配置的字段在新的数据中没有了（除 @metadata 之外），另外经笔者验证：不仅 @metadata 字段不能丢弃，如果 @timestamp 这个字段在 drop_fields 中配置了，也是不起作用的，它们两不允许丢弃。通常来说一行日志已经够长了，再加上这么多我们不需要的字段，就会增加数据的大小，对于生产环境的话，日志数据量非常大，那无疑会对后面所有的链路都会造成一定的影响，所以一定要在底层数据源头做好精简。另外还可以在发送 Kafka 的时候对数据进行压缩，可以在配置文件中配置一个 <code>compression: gzip</code>。精简后的日志数据结构如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"@timestamp"</span>: <span class="string">"2019-10-26T09:23:16.848Z"</span>,</span><br><span class="line"><span class="attr">"@metadata"</span>: &#123;</span><br><span class="line"><span class="attr">"beat"</span>: <span class="string">"filebeat"</span>,</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"doc"</span>,</span><br><span class="line"><span class="attr">"version"</span>: <span class="string">"6.8.4"</span>,</span><br><span class="line"><span class="attr">"topic"</span>: <span class="string">"zhisheng_log"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"host"</span>: &#123;</span><br><span class="line"><span class="attr">"name"</span>: <span class="string">"VM_0_2_centos"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"source"</span>: <span class="string">"/var/logs/middleware/kafka.log"</span>,</span><br><span class="line"><span class="attr">"message"</span>: <span class="string">"2019-10-26 17:23:11 TRACE [Controller id=0] Leader imbalance ratio for broker 0 is 0.0 (kafka.controller.KafkaController)"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="12-1-4-日志格式统一"><a href="#12-1-4-日志格式统一" class="headerlink" title="12.1.4 日志格式统一"></a>12.1.4 日志格式统一</h3><p>因为 Filebeat 是在机器上采集的日志，这些日志的种类比较多，常见的有应用程序的运行日志、作业构建编译打包的日志、中间件服务运行的日志等。通常在公司是可以给开发约定日志打印的规则，但是像中间件这类服务的日志是不固定的，如果将 Kafka 中的消息直接存储到 ElasticSearch 的话，后面如果要做区分筛选的话可能会有问题。为了避免这个问题，我们得在日志存入 ElasticSearch 之前做一个数据格式化和清洗的工作，因为 Flink 处理数据的速度比较好，而且可以做到实时，所以选择在 Flink Job 中完成该工作。</p><p>在该作业中的要将 message 解析，一般该行日志信息会包含很多信息，比如日志打印时间、日志级别、应用名、唯一性 ID（用来关联各个请求）、请求上下文。那么我们就需要一个新的日志结构对象来统一日志的格式，定义如下：</p><h3 id="12-1-5-日志实时清洗"><a href="#12-1-5-日志实时清洗" class="headerlink" title="12.1.5 日志实时清洗"></a>12.1.5 日志实时清洗</h3><h3 id="12-1-6-日志实时告警"><a href="#12-1-6-日志实时告警" class="headerlink" title="12.1.6 日志实时告警"></a>12.1.6 日志实时告警</h3><h3 id="12-1-7-日志实时存储"><a href="#12-1-7-日志实时存储" class="headerlink" title="12.1.7 日志实时存储"></a>12.1.7 日志实时存储</h3><h3 id="12-1-8-日志实时展示"><a href="#12-1-8-日志实时展示" class="headerlink" title="12.1.8 日志实时展示"></a>12.1.8 日志实时展示</h3><h3 id="12-1-9-小结与反思"><a href="#12-1-9-小结与反思" class="headerlink" title="12.1.9 小结与反思"></a>12.1.9 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/IeAYbEy">https://t.zsxq.com/IeAYbEy</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第十二章-——-Flink-案例&quot;&gt;&lt;a href=&quot;#第十二章-——-Flink-案例&quot; class=&quot;headerlink&quot; title=&quot;第十二章 —— Flink 案例&quot;&gt;&lt;/a&gt;第十二章 —— Flink 案例&lt;/h1&gt;&lt;p&gt;本章将介绍 Flink 在多个场景下落地实现的大型案例，第一个是实时处理海量的日志，将从日志的收集、日志的传输、日志的实时清洗和异常检测、日志存储、日志展示等方面去介绍 Flink 在其中起的作用，希望整个日志处理的架构大家可以灵活的运用在自己的公司；第二个是百亿数据量的情况下如何使用 Flink 实时去重，在这个案例中将对比介绍其他几种常见的去重实现方案；第三个是 Flink 在监控告警系统中的落地实现，在这个案例中同样很详细的介绍了一个监控告警系统的全链路，每一个关节都不可或缺，并且还介绍了 Flink 在未来结合机器学习算法做一些 AIOps 的事情。三个案例都比较典型，如果你也在做类似的项目，希望对你们的技术选型有一定的帮助。&lt;/p&gt;
&lt;h2 id=&quot;12-1-基于-Flink-实时处理海量日志&quot;&gt;&lt;a href=&quot;#12-1-基于-Flink-实时处理海量日志&quot; class=&quot;headerlink&quot; title=&quot;12.1 基于 Flink 实时处理海量日志&quot;&gt;&lt;/a&gt;12.1 基于 Flink 实时处理海量日志&lt;/h2&gt;&lt;p&gt;在 11.5 节中讲解了 Flink 如何实时处理异常的日志，并且对比分析了几种常用的日志采集工具。我们也知道通常在排查线上异常故障的时候，日志是必不可缺的一部分，通过异常日志我们可以快速的定位到问题的根因。那么通常在公司对于日志处理有哪些需求呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何实时将应用 Error 日志告警？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/18/flink-in-action-11.5/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/18/flink-in-action-11.5/</id>
    <published>2021-08-17T16:00:00.000Z</published>
    <updated>2022-02-07T14:13:56.910Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-5-如何实时将应用-Error-日志告警？"><a href="#11-5-如何实时将应用-Error-日志告警？" class="headerlink" title="11.5 如何实时将应用 Error 日志告警？"></a>11.5 如何实时将应用 Error 日志告警？</h2><p>大数据时代，随着公司业务不断的增长，数据量自然也会跟着不断的增长，那么业务应用和集群服务器的的规模也会逐渐扩大，几百台服务器在一般的公司已经是很常见的了。那么将应用服务部署在如此多的服务器上，对开发和运维人员来说都是一个挑战。一个优秀的系统运维平台是需要将部署在这么多服务器上的应用监控信息汇总成一个统一的数据展示平台，方便运维人员做日常的监测、提升运维效率，还可以及时反馈应用的运行状态给应用开发人员。举个例子，应用的运行日志需要按照时间排序做一个展示，并且提供日志下载和日志搜索等服务，这样如果应用出现问题开发人员首先可以根据应用日志的错误信息进行问题的排查。那么该如何实时的将应用的 Error 日志推送给应用开发人员呢，接下来我们将讲解日志的处理方案。</p><a id="more"></a><h3 id="11-5-1-日志处理方案的演进"><a href="#11-5-1-日志处理方案的演进" class="headerlink" title="11.5.1 日志处理方案的演进"></a>11.5.1 日志处理方案的演进</h3><p>日志处理的方案也是有一个演进的过程，要想弄清楚整个过程，我们先来看下日志的介绍。</p><h4 id="什么是日志？"><a href="#什么是日志？" class="headerlink" title="什么是日志？"></a>什么是日志？</h4><p>日志是带时间戳的基于时间序列的数据，它可以反映系统的运行状态，包括了一些标识信息（应用所在服务器集群名、集群机器 IP、机器设备系统信息、应用名、应用 ID、应用所属项目等）</p><h4 id="日志处理方案演进"><a href="#日志处理方案演进" class="headerlink" title="日志处理方案演进"></a>日志处理方案演进</h4><p>日志处理方案的演进过程：</p><ul><li>日志处理 v1.0: 应用日志分布在很多机器上，需要人肉手动去机器查看日志信息。</li><li>日志处理 v2.0: 利用离线计算引擎统一的将日志收集，形成一个日志搜索分析平台，提供搜索让用户根据关键字进行搜索和分析，缺点就是及时性比较差。</li><li>日志处理 v3.0: 利用 Agent 实时的采集部署在每台机器上的日志，然后统一发到日志收集平台做汇总，并提供实时日志分析和搜索的功能，这样从日志产生到搜索分析出结果只有简短的延迟（在用户容忍时间范围之内），优点是快，但是日志数据量大的情况下带来的挑战也大。</li></ul><h3 id="11-5-2-日志采集工具对比"><a href="#11-5-2-日志采集工具对比" class="headerlink" title="11.5.2 日志采集工具对比"></a>11.5.2 日志采集工具对比</h3><p>上面提到的日志采集，其实现在已经有很多开源的组件支持去采集日志，比如 Logstash、Filebeat、Fluentd、Logagent 等，这里简单做个对比。</p><h4 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h4><p>Logstash 是一个开源数据收集引擎，具有实时管道功能。Logstash 可以动态地将来自不同数据源的数据统一起来，并将数据标准化到你所选择的目的地。如下图所示，Logstash 将采集到的数据用作分析、监控、告警等。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-025214.jpg" alt=""></p><p><strong>优势</strong>：Logstash 主要的优点就是它的灵活性，它提供很多插件，详细的文档以及直白的配置格式让它可以在多种场景下应用。而且现在 ELK 整个技术栈在很多公司应用的比较多，所以基本上可以在往上找到很多相关的学习资源。</p><p><strong>劣势</strong>：Logstash 致命的问题是它的性能以及资源消耗(默认的堆大小是 1GB)。尽管它的性能在近几年已经有很大提升，与它的替代者们相比还是要慢很多的，它在大数据量的情况下会是个问题。另一个问题是它目前不支持缓存，目前的典型替代方案是将 Redis 或 Kafka 作为中心缓冲池：</p><h4 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h4><p>作为 Beats 家族的一员，Filebeat 是一个轻量级的日志传输工具，它的存在正弥补了 Logstash 的缺点，Filebeat 作为一个轻量级的日志传输工具可以将日志推送到 Kafka、Logstash、ElasticSearch、Redis。它的处理流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-030138.jpg" alt=""></p><p><strong>优势</strong>：Filebeat 只是一个二进制文件没有任何依赖。它占用资源极少，尽管它还十分年轻，正式因为它简单，所以几乎没有什么可以出错的地方，所以它的可靠性还是很高的。它也为我们提供了很多可以调节的点，例如：它以何种方式搜索新的文件，以及当文件有一段时间没有发生变化时，何时选择关闭文件句柄。</p><p><strong>劣势</strong>：Filebeat 的应用范围十分有限，所以在某些场景下我们会碰到问题。例如，如果使用 Logstash 作为下游管道，我们同样会遇到性能问题。正因为如此，Filebeat 的范围在扩大。开始时，它只能将日志发送到 Logstash 和 Elasticsearch，而现在它可以将日志发送给 Kafka 和 Redis，在 5.x 版本中，它还具备过滤的能力。</p><h4 id="Fluentd"><a href="#Fluentd" class="headerlink" title="Fluentd"></a>Fluentd</h4><p>Fluentd 创建的初衷主要是尽可能的使用 JSON 作为日志输出，所以传输工具及其下游的传输线不需要猜测子字符串里面各个字段的类型。这样它为几乎所有的语言都提供库，这也意味着可以将它插入到自定义的程序中。它的处理流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-031337.png" alt=""></p><p><strong>优势</strong>：和多数 Logstash 插件一样，Fluentd 插件是用 Ruby 语言开发的非常易于编写维护。所以它数量很多，几乎所有的源和目标存储都有插件(各个插件的成熟度也不太一样)。这也意味这可以用 Fluentd 来串联所有的东西。</p><p><strong>劣势</strong>：因为在多数应用场景下得到 Fluentd 结构化的数据，它的灵活性并不好。但是仍然可以通过正则表达式来解析非结构化的数据。尽管性能在大多数场景下都很好，但它并不是最好的，它的缓冲只存在与输出端，单线程核心以及 Ruby GIL 实现的插件意味着它大的节点下性能是受限的。</p><h4 id="Logagent"><a href="#Logagent" class="headerlink" title="Logagent"></a>Logagent</h4><p>Logagent 是 Sematext 提供的传输工具，它用来将日志传输到 Logsene(一个基于 SaaS 平台的 Elasticsearch API)，因为 Logsene 会暴露 Elasticsearch API，所以 Logagent 可以很容易将数据推送到 Elasticsearch 。</p><p><strong>优势</strong>：可以获取 /var/log 下的所有信息，解析各种格式的日志，可以掩盖敏感的数据信息。它还可以基于 IP 做 GeoIP 丰富地理位置信息。同样，它轻量又快速，可以将其置入任何日志块中。Logagent 有本地缓冲，所以在数据传输目的地不可用时不会丢失日志。</p><p><strong>劣势</strong>：没有 Logstash 灵活。</p><h3 id="11-5-3-日志结构设计"><a href="#11-5-3-日志结构设计" class="headerlink" title="11.5.3 日志结构设计"></a>11.5.3 日志结构设计</h3><p>前面介绍了日志和对比了常用日志采集工具的优势和劣势，通常在不同环境，不同机器上都会部署日志采集工具，然后采集工具会实时的将新的日志采集发送到下游，因为日志数据量毕竟大，所以建议发到 MQ 中，比如 Kafka，这样再想怎么处理这些日志就会比较灵活。假设我们忽略底层采集具体是哪种，但是规定采集好的日志结构化数据如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEvent</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String type;<span class="comment">//日志的类型(应用、容器、...)</span></span><br><span class="line">    <span class="keyword">private</span> Long timestamp;<span class="comment">//日志的时间戳</span></span><br><span class="line">    <span class="keyword">private</span> String level;<span class="comment">//日志的级别(debug/info/warn/error)</span></span><br><span class="line">    <span class="keyword">private</span> String message;<span class="comment">//日志内容</span></span><br><span class="line">    <span class="comment">//日志的标识(应用 ID、应用名、容器 ID、机器 IP、集群名、...)</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; tags = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后上面这种 LogEvent 的数据（假设采集发上来的是这种结构数据的 JSON 串，所以需要在 Flink 中做一个反序列化解析）就会往 Kafka 不断的发送数据，样例数据如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"app"</span>,</span><br><span class="line"><span class="attr">"timestamp"</span>: <span class="number">1570941591229</span>,</span><br><span class="line"><span class="attr">"level"</span>: <span class="string">"error"</span>,</span><br><span class="line"><span class="attr">"message"</span>: <span class="string">"Exception in thread \"main\" java.lang.NoClassDefFoundError: org/apache/flink/api/common/ExecutionConfig$GlobalJobParameters"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"cluster_name"</span>: <span class="string">"zhisheng"</span>,</span><br><span class="line"><span class="attr">"app_name"</span>: <span class="string">"zhisheng"</span>,</span><br><span class="line"><span class="attr">"host_ip"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line"><span class="attr">"app_id"</span>: <span class="string">"21"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么在 Flink 中如何将应用异常或者错误的日志做实时告警呢？</p><h3 id="11-5-4-异常日志实时告警项目架构"><a href="#11-5-4-异常日志实时告警项目架构" class="headerlink" title="11.5.4 异常日志实时告警项目架构"></a>11.5.4 异常日志实时告警项目架构</h3><p>整个异常日志实时告警项目的架构如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-035811.png" alt=""></p><p>应用日志散列在不同的机器，然后每台机器都有部署采集日志的 Agent（可以是上面的 Filebeat、Logstash 等），这些 Agent 会实时的将分散在不同机器、不同环境的应用日志统一的采集发到 Kafka 集群中，然后告警这边是有一个 Flink 作业去实时的消费 Kafka 数据做一个异常告警计算处理。如果还想做日志的搜索分析，可以起另外一个作业去实时的将 Kafka 的日志数据写入进 ElasticSearch，再通过 Kibana 页面做搜索和分析。</p><h3 id="11-5-5-日志数据发送到-Kafka"><a href="#11-5-5-日志数据发送到-Kafka" class="headerlink" title="11.5.5 日志数据发送到 Kafka"></a>11.5.5 日志数据发送到 Kafka</h3><p>上面已经讲了日志数据 LogEvent 的结构和样例数据，因为要在服务器部署采集工具去采集应用日志数据对于本地测试来说可能稍微复杂，所以在这里就只通过代码模拟构造数据发到 Kafka 去，然后在 Flink 作业中去实时消费 Kafka 中的数据，下面演示构造日志数据发到 Kafka 的工具类，这个工具类主要分两块，构造 LogEvent 数据和发送到 Kafka。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BuildLogEventDataUtil</span> </span>&#123;</span><br><span class="line">    <span class="comment">//Kafka broker 和 topic 信息</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String BROKER_LIST = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LOG_TOPIC = <span class="string">"zhisheng_log"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeDataToKafka</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, BROKER_LIST);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        KafkaProducer producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//模拟构造 LogEvent 对象</span></span><br><span class="line">            LogEvent logEvent = <span class="keyword">new</span> LogEvent().builder()</span><br><span class="line">                    .type(<span class="string">"app"</span>)</span><br><span class="line">                    .timestamp(System.currentTimeMillis())</span><br><span class="line">                    .level(logLevel())</span><br><span class="line">                    .message(message(i + <span class="number">1</span>))</span><br><span class="line">                    .tags(mapData())</span><br><span class="line">                    .build();</span><br><span class="line"><span class="comment">//            System.out.println(logEvent);</span></span><br><span class="line">            ProducerRecord record = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(LOG_TOPIC, <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(logEvent));</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.flush();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        writeDataToKafka();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">message</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"这是第 "</span> + i + <span class="string">" 行日志！"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">logLevel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> number = random.nextInt(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">switch</span> (number) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"debug"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"info"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"warn"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"error"</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"info"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">hostIp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> number = random.nextInt(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">switch</span> (number) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.10"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.11"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.12"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.13"</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.10"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">mapData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(<span class="string">"app_id"</span>, <span class="string">"11"</span>);</span><br><span class="line">        map.put(<span class="string">"app_name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line">        map.put(<span class="string">"cluster_name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line">        map.put(<span class="string">"host_ip"</span>, hostIp());</span><br><span class="line">        map.put(<span class="string">"class"</span>, <span class="string">"BuildLogEventDataUtil"</span>);</span><br><span class="line">        map.put(<span class="string">"method"</span>, <span class="string">"main"</span>);</span><br><span class="line">        map.put(<span class="string">"line"</span>, String.valueOf(<span class="keyword">new</span> Random().nextInt(<span class="number">100</span>)));</span><br><span class="line">        <span class="comment">//add more tag</span></span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果之前 Kafka 中没有 zhisheng_log 这个 topic，运行这个工具类之后也会自动创建这个 topic 了。</p><h3 id="11-5-6-Flink-实时处理日志数据"><a href="#11-5-6-Flink-实时处理日志数据" class="headerlink" title="11.5.6 Flink 实时处理日志数据"></a>11.5.6 Flink 实时处理日志数据</h3><h3 id="11-5-7-处理应用异常日志"><a href="#11-5-7-处理应用异常日志" class="headerlink" title="11.5.7 处理应用异常日志"></a>11.5.7 处理应用异常日志</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>本章属于 Flink 实战篇，前面章节讲了很多 Flink 相关的技术知识点，这章主要是通过技术点来教大家如何去完成一些真实的需求，比如通过 State 去实时统计网站各页面一天的 PV 和 UV、通过 ProcessFunction 去做定时器处理一些延迟的事件（宕机告警）、通过 Async IO 读取告警规则、通过广播变量动态的更新告警规则、如何实时的做到日志告警。</p><p>虽然这些需求换到你们公司去可能不一样，但是这些技术知识点是可以运用到你的项目需求中去的，这里介绍的这些需求，你要学会去分析，然后去判断这些需求到底该使用什么技术来实现会更好，这样才可以做到活学活用。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-5-如何实时将应用-Error-日志告警？&quot;&gt;&lt;a href=&quot;#11-5-如何实时将应用-Error-日志告警？&quot; class=&quot;headerlink&quot; title=&quot;11.5 如何实时将应用 Error 日志告警？&quot;&gt;&lt;/a&gt;11.5 如何实时将应用 Error 日志告警？&lt;/h2&gt;&lt;p&gt;大数据时代，随着公司业务不断的增长，数据量自然也会跟着不断的增长，那么业务应用和集群服务器的的规模也会逐渐扩大，几百台服务器在一般的公司已经是很常见的了。那么将应用服务部署在如此多的服务器上，对开发和运维人员来说都是一个挑战。一个优秀的系统运维平台是需要将部署在这么多服务器上的应用监控信息汇总成一个统一的数据展示平台，方便运维人员做日常的监测、提升运维效率，还可以及时反馈应用的运行状态给应用开发人员。举个例子，应用的运行日志需要按照时间排序做一个展示，并且提供日志下载和日志搜索等服务，这样如果应用出现问题开发人员首先可以根据应用日志的错误信息进行问题的排查。那么该如何实时的将应用的 Error 日志推送给应用开发人员呢，接下来我们将讲解日志的处理方案。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何利用广播变量动态更新告警规则？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/17/flink-in-action-11.4/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/17/flink-in-action-11.4/</id>
    <published>2021-08-16T16:00:00.000Z</published>
    <updated>2022-02-07T14:05:22.257Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-4-如何利用广播变量动态更新告警规则？"><a href="#11-4-如何利用广播变量动态更新告警规则？" class="headerlink" title="11.4 如何利用广播变量动态更新告警规则？"></a>11.4 如何利用广播变量动态更新告警规则？</h2><p>一个在生产环境运行的流作业有时候会想变更一些作业的配置或者数据流的配置，然后作业可以读取并使用新的配置，而不是通过修改配置然后重启作业来读取配置，毕竟重启一个有状态的流作业代价挺大，本节将带你熟悉 Broadcast，并通过一个案例来教会你如何去动态的更新作业的配置。</p><a id="more"></a><h3 id="11-4-1-BroadcastVariable-简介"><a href="#11-4-1-BroadcastVariable-简介" class="headerlink" title="11.4.1 BroadcastVariable 简介"></a>11.4.1 BroadcastVariable 简介</h3><p>BroadcastVariable 中文意思是广播变量，其实可以理解是一个公共的共享变量（可能是固定不变的数据集合，也可能是动态变化的数据集合），在作业中将该共享变量广播出去，然后下游的所有任务都可以获取到该共享变量，这样就可以不用将这个变量拷贝到下游的每个任务中。之所以设计这个广播变量的原因主要是因为在 Flink 中多并行度的情况下，每个算子或者不同算子运行所在的 Slot 不一致，这就导致它们不会共享同一个内存，也就不可以通过静态变量的方式去获取这些共享变量值。对于这个问题，有不少读者在问过我为啥我设置的静态变量值在本地运行是可以获取到的，在集群环境运行作业就出现空指针啊，该问题其实笔者自己也在生产环境遇到过，所以接下来好好教大家使用！</p><h3 id="11-4-2-如何使用-BroadcastVariable-？"><a href="#11-4-2-如何使用-BroadcastVariable-？" class="headerlink" title="11.4.2 如何使用 BroadcastVariable ？"></a>11.4.2 如何使用 BroadcastVariable ？</h3><p>在 3.4 节中讲过如何 broadcast 算子和 BroadcastStream 如何使用，在 4.1 节中讲解了 Broadcast State 如何使用以及需要注意的地方，注意 BroadcastVariable 只能应用在批作业中，如果要应用在流作业中则需要要使用 BroadcastStream。</p><p>在批作业中通过使用 <code>withBroadcastSet(DataSet, String)</code> 来广播一个 DataSet 数据集合，并可以给这份数据起个名字，如果要获取数据的时候，可以通过 <code>getRuntimeContext().getBroadcastVariable(String)</code> 获取广播出去的变量数据。下面演示一下广播一个 DataSet 变量和获取变量的样例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> ParameterTool params = ParameterTool.fromArgs(args);</span><br><span class="line"><span class="keyword">final</span> ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line"><span class="comment">//1. 待广播的数据</span></span><br><span class="line">DataSet&lt;Integer&gt; toBroadcast = env.fromElements(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">env.fromElements(<span class="string">"a"</span>, <span class="string">"b"</span>)</span><br><span class="line">        .map(<span class="keyword">new</span> RichMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            List&lt;Integer&gt; broadcastData;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">// 3. 获取广播的 DataSet 数据 作为一个 Collection</span></span><br><span class="line">                broadcastData = getRuntimeContext().getBroadcastVariable(<span class="string">"zhisheng"</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> String <span class="title">map</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> broadcastData.get(<span class="number">1</span>) + value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).withBroadcastSet(toBroadcast, <span class="string">"zhisheng"</span>)<span class="comment">// 2. 广播 DataSet</span></span><br><span class="line">        .print();</span><br></pre></td></tr></table></figure><p>注意广播的时候设置的名称和获取的名称要一致，然后运行的结果如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-013429.png" alt=""></p><p>流作业中通常使用 BroadcastStream 的方式将变量集合在数据流中传递，可能数据集合会做修改更新，但是修改后其实并不想重启作业去读取这些新修改的配置，因为对于一个流作业来说重启带来的代价很高（需要考虑数据堆积和如何恢复至重启前的状态等问题），那么这种情况下就可以在广播数据流处定时查询数据，这样就能够获取更改后的数据，通常在这种广播数据处获取数据只需要设置一个并行度就好，时间根据需求来判断及时性，一般 1 分钟内的数据变更延迟都是在容忍范围之内。广播流中的元素保证流所有的元素最终都会发到下游的所有并行实例，但是元素到达下游的并行实例的顺序可能不相同。因此，对广播状态的修改不能依赖于输入数据的顺序。在进行 Checkpoint 时，所有的任务都会 Checkpoint 下它们的广播状态。</p><p>另外需要注意的是：广播出去的变量存在于每个节点的内存中，所以这个数据集不能太大，因为广播出去的数据，会一致在内存中存在，除非程序执行结束。个人建议：如果数据集在几十兆或者百兆的时候，可以选择进行广播，如果数据集的大小上 G 的话，就不建议进行广播了。</p><p>上面介绍了下广播变量的在批作业的使用方式，下面通过一个案例来教大家如何在流作业中使用广播变量。</p><h3 id="11-4-3-利用广播变量动态更新告警规则数据需求分析"><a href="#11-4-3-利用广播变量动态更新告警规则数据需求分析" class="headerlink" title="11.4.3 利用广播变量动态更新告警规则数据需求分析"></a>11.4.3 利用广播变量动态更新告警规则数据需求分析</h3><p>在 11.3.3 节中有设计一张简单的告警规则表，通常告警规则是会对外提供接口进行增删改查的，那么随着业务应用上线，开发人员会对其应用服务新增或者修改告警规则（更改之前规则中的阈值），那么更改之后就需要让告警的作业能够去感知到之前的规则发生了变动，所以就需要在作业中想个什么办法去获取到更改后的数据。有两种方式可以让作业知道规则的变更： push 和 pull 模式。</p><p>push 模式则需要在更新、删除、新增接口中不仅操作数据库，还需要额外的发送更新、删除、新增规则的事件到消息队列中，然后作业消费消息队列的数据再去做更新、删除、新增规则，这种及时性有保证，但是可能会有数据不统一的风险（如果消息队列的数据丢了，但是在接口中还是将规则的数据变更存储到数据库）；pull 模式下就需要作业定时去查找一遍所有的告警规则数据，然后存在作业内存中，这个时间可以设置的比较短，比如 1 分钟，这样就能既保证数据的一致性，时间延迟也是在容忍范围之内。</p><p>对于这种动态变化的规则数据，在 Flink 中通常是使用广播流来处理的。那么接下来就演示下如何利用广播变量动态更新告警规则数据，假设我们在数据库中新增告警规则或者修改告警规则指标的阈值，然后看作业中是否会出现相应的变化。</p><h3 id="11-4-4-读取告警规则数据"><a href="#11-4-4-读取告警规则数据" class="headerlink" title="11.4.4 读取告警规则数据"></a>11.4.4 读取告警规则数据</h3><h3 id="11-4-5-监控数据连接规则数据"><a href="#11-4-5-监控数据连接规则数据" class="headerlink" title="11.4.5 监控数据连接规则数据"></a>11.4.5 监控数据连接规则数据</h3><h3 id="11-4-6-小结与反思"><a href="#11-4-6-小结与反思" class="headerlink" title="11.4.6 小结与反思"></a>11.4.6 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-4-如何利用广播变量动态更新告警规则？&quot;&gt;&lt;a href=&quot;#11-4-如何利用广播变量动态更新告警规则？&quot; class=&quot;headerlink&quot; title=&quot;11.4 如何利用广播变量动态更新告警规则？&quot;&gt;&lt;/a&gt;11.4 如何利用广播变量动态更新告警规则？&lt;/h2&gt;&lt;p&gt;一个在生产环境运行的流作业有时候会想变更一些作业的配置或者数据流的配置，然后作业可以读取并使用新的配置，而不是通过修改配置然后重启作业来读取配置，毕竟重启一个有状态的流作业代价挺大，本节将带你熟悉 Broadcast，并通过一个案例来教会你如何去动态的更新作业的配置。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何利用 Async I/O 读取告警规则？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/16/flink-in-action-11.3/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/16/flink-in-action-11.3/</id>
    <published>2021-08-15T16:00:00.000Z</published>
    <updated>2022-02-07T14:03:38.105Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-3-如何利用-Async-I-O-读取告警规则？"><a href="#11-3-如何利用-Async-I-O-读取告警规则？" class="headerlink" title="11.3 如何利用 Async I/O 读取告警规则？"></a>11.3 如何利用 Async I/O 读取告警规则？</h2><p>Async 中文是异步的意思，在流计算中，使用异步 I/O 能够提升作业整体的计算能力，本节中不仅会讲解异步 I/O 的 API 原理，还会通过一个实战需求（读取告警规则）来讲解异步 I/O 的使用。</p><a id="more"></a><h3 id="11-3-1-为什么需要-Async-I-O？"><a href="#11-3-1-为什么需要-Async-I-O？" class="headerlink" title="11.3.1 为什么需要 Async I/O？"></a>11.3.1 为什么需要 Async I/O？</h3><p>在大多数情况下，IO 操作都是一个耗时的过程，尤其在流计算中，如果在具体的算子里面还有和第三方外部系统（比如数据库、Redis、HBase 等存储系统）做交互，比如在一个 MapFunction 中每来一条数据就要去查找 MySQL 中某张表的数据，然后跟查询出来的数据做关联（同步交互）。查询请求到数据库，再到数据库响应返回数据的整个流程的时间对于流作业来说是比较长的。那么该 Map 算子处理数据的速度就会降下来，在大数据量的情况下很可能会导致整个流作业出现反压问题（在 9.1 节中讲过），那么整个作业的消费延迟就会增加，影响作业整体吞吐量和实时性，从而导致最终该作业处于不可用的状态。</p><p>这种同步（Sync）的与数据库做交互操作，会因耗时太久导致整个作业延迟，如果换成异步的话，就可以同时处理很多请求并同时可以接收响应，这样的话，等待数据库响应的时间就会与其他发送请求和接收响应的时间重叠，相同的等待时间内会处理多个请求，从而比同步的访问要提高不少流处理的吞吐量。虽然也可以通过增大该算子的并行度去执行查数据库，但是这种解决办法需要消耗更多的资源（并行度增加意味着消费的 slot 个数也会增加），这种方法和使用异步处理的方法对比一下，还是使用异步的查询数据库这种方法值得使用。同步操作（Sync I/O）和异步操作（Async I/O）的处理流程如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-12-121929.png" alt=""></p><p>左侧表示的是在流处理中同步的数据库请求，右侧是异步的数据库请求。假设左侧是数据流中 A 数据来了发送一个查询数据库的请求看是否之前存在 A，然后等待查询结果返回，只有等 A 整个查询请求响应后才会继续开始 B 数据的查询请求，依此继续；而右侧是连续的去数据库查询是否存在 A、B、C、D，后面哪个请求先响应就先处理哪个，不需要和左侧的一样要等待上一个请求全部完成才可以开始下一个请求，所以异步的话吞吐量自然就高起来了。但是得注意的是：使用异步这种方法前提是要数据库客户端支持异步的请求，否则可能需要借助线程池来实现异步请求，但是现在主流的数据库通常都支持异步的操作，所以不用太担心。</p><h3 id="11-3-2-Async-I-O-API"><a href="#11-3-2-Async-I-O-API" class="headerlink" title="11.3.2 Async I/O API"></a>11.3.2 Async I/O API</h3><p>Flink 的 Async I/O API 允许用户在数据流处理中使用异步请求，并且还支持超时处理、处理顺序、事件时间、容错。在 Flink 中，如果要使用 Async I/O API，是非常简单的，需要通过下面三个步骤来执行对数据库的异步操作。</p><ul><li>继承 RichAsyncFunction 抽象类或者实现用来分发请求的 AsyncFunction 接口</li><li>返回异步请求的结果的 Future</li><li>在 DataStream 上使用异步操作</li></ul><p>官网也给出案例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AsyncDatabaseRequest</span> <span class="keyword">extends</span> <span class="title">RichAsyncFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据库的客户端，它可以发出带有 callback 的并发请求</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> DatabaseClient client;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        client = <span class="keyword">new</span> DatabaseClient(host, post, credentials);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">asyncInvoke</span><span class="params">(String key, <span class="keyword">final</span> ResultFuture&lt;Tuple2&lt;String, String&gt;&gt; resultFuture)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//发出异步请求，接收 future 的结果</span></span><br><span class="line">        <span class="keyword">final</span> Future&lt;String&gt; result = client.query(key);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置客户端请求完成后执行的 callback，callback 只是将结果转发给 ResultFuture</span></span><br><span class="line">        CompletableFuture.supplyAsync(<span class="keyword">new</span> Supplier&lt;String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> result.get();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).thenAccept( (String dbResult) -&gt; &#123;</span><br><span class="line">            resultFuture.complete(Collections.singleton(<span class="keyword">new</span> Tuple2&lt;&gt;(key, dbResult)));</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//原始数据</span></span><br><span class="line">DataStream&lt;String&gt; stream = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">//应用异步 I/O 转换</span></span><br><span class="line">DataStream&lt;Tuple2&lt;String, String&gt;&gt; resultStream =</span><br><span class="line">    AsyncDataStream.unorderedWait(stream, <span class="keyword">new</span> AsyncDatabaseRequest(), <span class="number">1000</span>, TimeUnit.MILLISECONDS, <span class="number">100</span>);</span><br></pre></td></tr></table></figure><p>注意：ResultFuture 在第一次调用 resultFuture.complete 时就已经完成了，后面所有 resultFuture.complete  的调用都会被忽略。</p><p>下面两个参数控制了异步操作：</p><ul><li>Timeout：timeout 定义了异步操作过了多长时间后会被丢弃，这个参数是防止了死的或者失败的请求</li><li>Capacity：这个参数定义可以同时处理多少个异步请求。虽然异步请求会带来更好的吞吐量，但是该操作仍然可能成为流作业的性能瓶颈。限制并发请求的数量可确保操作不会不断累积处理请求，一旦超过 Capacity 值，它将触发反压。</li></ul><h4 id="超时处理"><a href="#超时处理" class="headerlink" title="超时处理"></a>超时处理</h4><h4 id="结果顺序"><a href="#结果顺序" class="headerlink" title="结果顺序"></a>结果顺序</h4><h4 id="事件时间"><a href="#事件时间" class="headerlink" title="事件时间"></a>事件时间</h4><h4 id="容错性保证"><a href="#容错性保证" class="headerlink" title="容错性保证"></a>容错性保证</h4><h4 id="实践技巧"><a href="#实践技巧" class="headerlink" title="实践技巧"></a>实践技巧</h4><h4 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h4><h3 id="11-3-3-利用-Async-I-O-读取告警规则需求分析"><a href="#11-3-3-利用-Async-I-O-读取告警规则需求分析" class="headerlink" title="11.3.3 利用 Async I/O 读取告警规则需求分析"></a>11.3.3 利用 Async I/O 读取告警规则需求分析</h3><h4 id="监控数据样例"><a href="#监控数据样例" class="headerlink" title="监控数据样例"></a>监控数据样例</h4><h4 id="告警规则表设计"><a href="#告警规则表设计" class="headerlink" title="告警规则表设计"></a>告警规则表设计</h4><h4 id="告警规则实体类"><a href="#告警规则实体类" class="headerlink" title="告警规则实体类"></a>告警规则实体类</h4><h3 id="11-3-4-如何使用-Async-I-O-读取告警规则数据"><a href="#11-3-4-如何使用-Async-I-O-读取告警规则数据" class="headerlink" title="11.3.4 如何使用 Async I/O 读取告警规则数据"></a>11.3.4 如何使用 Async I/O 读取告警规则数据</h3><h3 id="11-3-5-小结与反思"><a href="#11-3-5-小结与反思" class="headerlink" title="11.3.5 小结与反思"></a>11.3.5 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-3-如何利用-Async-I-O-读取告警规则？&quot;&gt;&lt;a href=&quot;#11-3-如何利用-Async-I-O-读取告警规则？&quot; class=&quot;headerlink&quot; title=&quot;11.3 如何利用 Async I/O 读取告警规则？&quot;&gt;&lt;/a&gt;11.3 如何利用 Async I/O 读取告警规则？&lt;/h2&gt;&lt;p&gt;Async 中文是异步的意思，在流计算中，使用异步 I/O 能够提升作业整体的计算能力，本节中不仅会讲解异步 I/O 的 API 原理，还会通过一个实战需求（读取告警规则）来讲解异步 I/O 的使用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何使用 Flink ProcessFunction 处理宕机告警?</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/15/flink-in-action-11.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/15/flink-in-action-11.2/</id>
    <published>2021-08-14T16:00:00.000Z</published>
    <updated>2022-02-07T14:01:37.985Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-2-如何使用-Flink-ProcessFunction-处理宕机告警"><a href="#11-2-如何使用-Flink-ProcessFunction-处理宕机告警" class="headerlink" title="11.2 如何使用 Flink ProcessFunction 处理宕机告警?"></a>11.2 如何使用 Flink ProcessFunction 处理宕机告警?</h2><p>在 3.3 节中讲解了 Process 算子的概念，本节中将更详细的讲解 Flink ProcessFunction，然后教大家如何使用 ProcessFunction 来解决公司中常见的问题 —— 宕机，这个宕机不仅仅包括机器宕机，还包含应用宕机，通常出现宕机带来的影响是会很大的，所以能及时收到告警会减少损失。</p><a id="more"></a><h3 id="11-2-1-ProcessFunction-简介"><a href="#11-2-1-ProcessFunction-简介" class="headerlink" title="11.2.1 ProcessFunction 简介"></a>11.2.1 ProcessFunction 简介</h3><p>在 1.2.5 节中讲了 Flink 的 API 分层，其中可以看见 Flink 的底层 API 就是 ProcessFunction，它是一个低阶的流处理操作，它可以访问流处理程序的基础构建模块：Event、State、Timer。ProcessFunction 可以被认为是一种提供了对 KeyedState 和定时器访问的 FlatMapFunction。每当数据源中接收到一个事件，就会调用来此函数来处理。对于容错的状态，ProcessFunction 可以通过 RuntimeContext 访问 KeyedState。</p><p>定时器可以对处理时间和事件时间的变化做一些处理。每次调用 processElement() 都可以获得一个 Context 对象，通过该对象可以访问元素的事件时间戳以及 TimerService。TimerService 可以为尚未发生的事件时间/处理时间实例注册回调。当定时器到达某个时刻时，会调用 onTimer() 方法。在调用期间，所有状态再次限定为定时器创建的 key，允许定时器操作 KeyedState。如果要访问 KeyedState 和定时器，那必须在 KeyedStream 上使用 KeyedProcessFunction，比如在 keyBy 算子之后使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(...).process(<span class="keyword">new</span> KeyedProcessFunction&lt;&gt;()&#123;</span><br><span class="line">    </span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>KeyedProcessFunction 是 ProcessFunction 函数的一个扩展，它可以在 onTimer 和 processElement 方法中获取到分区的 Key 值，这对于数据传递是很有帮助的，因为经常有这样的需求，经过 keyBy 算子之后可能还需要这个 key 字段，那么在这里直接构建成一个新的对象（新增一个 key 字段），然后下游的算子直接使用这个新对象中的 key 就好了，而不在需要重复的拼一个唯一的 key。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(String value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    System.out.println(ctx.getCurrentKey());</span><br><span class="line">    out.collect(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">long</span> timestamp, OnTimerContext ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    System.out.println(ctx.getCurrentKey());</span><br><span class="line">    <span class="keyword">super</span>.onTimer(timestamp, ctx, out);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="11-2-2-CoProcessFunction-简介"><a href="#11-2-2-CoProcessFunction-简介" class="headerlink" title="11.2.2 CoProcessFunction 简介"></a>11.2.2 CoProcessFunction 简介</h3><p>如果要在两个输入流上进行操作，可以使用 CoProcessFunction，这个函数可以传入两个不同的数据流输入，并为来自两个不同数据源的事件分别调用 processElement1() 和  processElement2() 方法。可以按照下面的步骤来实现一个典型的 Join 操作：</p><ul><li>为一个数据源的数据建立一个状态对象</li><li>从数据源处有新数据流过来的时候更新这个状态对象</li><li>在另一个数据源接收到元素时，关联状态对象并对其产生出连接的结果</li></ul><p>比如，将监控的 metric 数据和告警规则数据进行一个连接，在流数据的状态中存储了告警规则数据，当有监控数据过来时，根据监控数据的 metric 名称和一些 tag 去找对应告警规则计算表达式，然后通过规则的表达式对数据进行加工处理，判断是否要告警，如果是要告警则会关联构造成一个新的对象，新对象中不仅有初始的监控 metric 数据，还有含有对应的告警规则数据以及通知策略数据，组装成这样一条数据后，下游就可以根据这个数据进行通知，通知还会在状态中存储这个告警状态，表示它在什么时间告过警了，下次有新数据过来的时候，判断新数据是否是恢复的，如果属于恢复则把该状态清除。</p><h3 id="11-2-3-Timer-简介"><a href="#11-2-3-Timer-简介" class="headerlink" title="11.2.3 Timer 简介"></a>11.2.3 Timer 简介</h3><p>Timer 提供了一种定时触发器的功能，通过 TimerService 接口注册 timer。TimerService 在内部维护两种类型的定时器（处理时间和事件时间定时器）并排队执行。处理时间定时器的触发依赖于 ProcessingTimeService，它负责管理所有基于处理时间的触发器，内部使用 ScheduledThreadPoolExecutor 调度定时任务；事件时间定时器的触发依赖于系统当前的 Watermark。需要注意的一点就是：<strong>Timer 只能在 KeyedStream 中使用</strong>。</p><p>TimerService 会删除每个 Key 和时间戳重复的定时器，即每个 Key 在同一个时间戳上最多有一个定时器。如果为同一时间戳注册了多个定时器，则只会调用一次 onTimer（） 方法。Flink 会同步调用 onTimer() 和  processElement() 方法，因此不必担心状态的并发修改问题。TimerService 不仅提供了注册和删除 Timer 的功能，还可以通过它来获取当前的系统时间和 Watermark 的值。TimerService 类中的方法如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-12-070737.png" alt=""></p><h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><p>定时器具有容错能力，并且会与应用程序的状态一起进行 Checkpoint，如果发生故障重启会从 Checkpoint／Savepoint 中恢复定时器的状态。如果有处理时间定时器原本是要在恢复起来的那个时间之前触发的，那么在恢复的那一刻会立即触发该定时器。定时器始终是异步的进行 Checkpoint（除 RocksDB 状态后端存储、增量的 Checkpoint、基于堆的定时器外）。因为定时器实际上也是一种特殊状态的状态，在 Checkpoint 时会写入快照中，所以如果有大量的定时器，则无非会增加一次 Checkpoint 所需要的时间，必要的话得根据实际情况合并定时器。</p><h4 id="合并定时器"><a href="#合并定时器" class="headerlink" title="合并定时器"></a>合并定时器</h4><p>由于 Flink 仅为每个 Key 和时间戳维护一个定时器，因此可以通过降低定时器的频率来进行合并以减少定时器的数量。对于频率为 1 秒的定时器（基于事件时间或处理时间），可以将目标时间向下舍入为整秒数，则定时器最多提前 1 秒触发，但不会迟于我们的要求，精确到毫秒。因此，每个键每秒最多有一个定时器。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> coalescedTime = ((ctx.timestamp() + timeout) / <span class="number">1000</span>) * <span class="number">1000</span>;</span><br><span class="line">ctx.timerService().registerProcessingTimeTimer(coalescedTime);</span><br></pre></td></tr></table></figure><p>由于事件时间计时器仅在 Watermark 到达时才触发，因此可以将当前 Watermark 与下一个 Watermark 的定时器一起调度和合并：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> coalescedTime = ctx.timerService().currentWatermark() + <span class="number">1</span>;</span><br><span class="line">ctx.timerService().registerEventTimeTimer(coalescedTime);</span><br></pre></td></tr></table></figure><p>定时器也可以类似下面这样移除：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//删除处理时间定时器</span></span><br><span class="line"><span class="keyword">long</span> timestampOfTimerToStop = ...</span><br><span class="line">ctx.timerService().deleteProcessingTimeTimer(timestampOfTimerToStop);</span><br><span class="line"></span><br><span class="line"><span class="comment">//删除事件时间定时器</span></span><br><span class="line"><span class="keyword">long</span> timestampOfTimerToStop = ...</span><br><span class="line">ctx.timerService().deleteEventTimeTimer(timestampOfTimerToStop);</span><br></pre></td></tr></table></figure><p>如果没有该时间戳的定时器，则删除定时器无效。</p><h3 id="11-2-4-如果利用-ProcessFunction-处理宕机告警？"><a href="#11-2-4-如果利用-ProcessFunction-处理宕机告警？" class="headerlink" title="11.2.4 如果利用 ProcessFunction 处理宕机告警？"></a>11.2.4 如果利用 ProcessFunction 处理宕机告警？</h3><h4 id="宕机告警需求分析"><a href="#宕机告警需求分析" class="headerlink" title="宕机告警需求分析"></a>宕机告警需求分析</h4><h4 id="宕机告警代码实现"><a href="#宕机告警代码实现" class="headerlink" title="宕机告警代码实现"></a>宕机告警代码实现</h4><h3 id="11-2-5-小结与反思"><a href="#11-2-5-小结与反思" class="headerlink" title="11.2.5 小结与反思"></a>11.2.5 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-2-如何使用-Flink-ProcessFunction-处理宕机告警&quot;&gt;&lt;a href=&quot;#11-2-如何使用-Flink-ProcessFunction-处理宕机告警&quot; class=&quot;headerlink&quot; title=&quot;11.2 如何使用 Flink ProcessFunction 处理宕机告警?&quot;&gt;&lt;/a&gt;11.2 如何使用 Flink ProcessFunction 处理宕机告警?&lt;/h2&gt;&lt;p&gt;在 3.3 节中讲解了 Process 算子的概念，本节中将更详细的讲解 Flink ProcessFunction，然后教大家如何使用 ProcessFunction 来解决公司中常见的问题 —— 宕机，这个宕机不仅仅包括机器宕机，还包含应用宕机，通常出现宕机带来的影响是会很大的，所以能及时收到告警会减少损失。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何统计网站各页面一天内的 PV 和 UV？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/14/flink-in-action-11.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/14/flink-in-action-11.1/</id>
    <published>2021-08-13T16:00:00.000Z</published>
    <updated>2022-02-07T13:59:31.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第十一章-——-Flink-实战"><a href="#第十一章-——-Flink-实战" class="headerlink" title="第十一章 —— Flink 实战"></a>第十一章 —— Flink 实战</h1><p>本章主要是 Flink 实战，介绍了一些常见的需求，比如实时统计网站页面的 PV/UV、宕机告警、动态更新配置、应用 Error 日志实时告警等，然后分别去分析这些需求的实现方式，明白该使用 Flink 中的哪些知识点才能够很好的完成这种需求，并提供完整的案例代码供大家参考。在实现完成这些需求之后，笔者还将会更深一步的去讲解下这些知识点背后的实现方式，希望可以加深你对这些知识点的印象，以便后面你可以灵活的处理类似的需求。</p><h2 id="11-1-如何统计网站各页面一天内的-PV-和-UV？"><a href="#11-1-如何统计网站各页面一天内的-PV-和-UV？" class="headerlink" title="11.1 如何统计网站各页面一天内的 PV 和 UV？"></a>11.1 如何统计网站各页面一天内的 PV 和 UV？</h2><p>大数据开发最常统计的需求可能就是 PV、UV。PV 全拼 PageView，即页面访问量，用户每次对网站的访问均被记录，按照访问量进行累计，假如用户对同一页面访问了 5 次，那该页面的 PV 就应该加 5。UV 全拼为 UniqueVisitor，即独立访问用户数，访问该页面的一台电脑客户端为一个访客，假如用户对同一页面访问了 5 次，那么该页面的 UV 只应该加 1，因为 UV 计算的是去重后的用户数而不是访问次数。当然如果是按天统计，那么当天 0 点到 24 点相同的客户端只被计算一次，如果过了今天 24 点，第二天该用户又访问了该页面，那么第二天该页面的 UV 应该加 1。 概念明白了那如何使用 Flink 来统计网站各页面的 PV 和 UV 呢？通过本节来详细描述。</p><a id="more"></a><h3 id="11-1-1-统计网站各页面一天内的-PV"><a href="#11-1-1-统计网站各页面一天内的-PV" class="headerlink" title="11.1.1 统计网站各页面一天内的 PV"></a>11.1.1 统计网站各页面一天内的 PV</h3><p>在 9.5.2 节端对端如何保证 Exactly Once 中的幂等性写入如何保证端对端 Exactly Once 部分已经用案例讲述了如何通过 Flink 的状态来计算 APP 的 PV，并能够保证 Exactly Once。如果在工作中需要计算网站各页面一天内的 PV，只需要将案例中的 APP 替换成各页面的 id 或者各页面的 url 进行统计即可，按照各页面 id 和日期组合做为 key 进行 keyBy，相同页面、相同日期的数据发送到相同的实例中进行 PV 值的累加，每个 key 对应一个 ValueState，将 PV 值维护在 ValueState 即可。如果一些页面属于爆款页面，例如首页或者活动页面访问特别频繁就可能出现某些 subtask 上的数据量特别大，导致各个 subtask 之前出现数据倾斜的问题，关于数据倾斜的解决方案请参考 9.6 节。</p><h3 id="11-1-2-统计网站各页面一天内-UV-的三种方案"><a href="#11-1-2-统计网站各页面一天内-UV-的三种方案" class="headerlink" title="11.1.2 统计网站各页面一天内 UV 的三种方案"></a>11.1.2 统计网站各页面一天内 UV 的三种方案</h3><p>PV 统计相对来说比较简单，每来一条用户的访问日志只需要从日志中提取出相应的页面 id 和日期，将其对应的 PV 值加一即可。相对而言统计 UV 就有难度了，同一个用户一天内多次访问同一个页面，只能计数一次。所以每来一条日志，日志中对应页面的 UV 值是否需要加一呢？存在两种情况：如果该用户今天第一次访问该页面，那么 UV 应该加一。如果该用户今天不是第一次访问该页面，表示 UV 中已经记录了该用户，UV 要基于用户去重，所以此时 UV 值不应该加一。难点就在于如何判断该用户今天是不是第一次访问该页面呢？</p><p>把问题简单化，先不考虑日期，现在统计网站各页面的累积 UV，可以为每个页面维护一个 Set 集合，假如网站有 10 个页面，那么就维护 10 个 Set 集合，集合中存放着所有访问过该页面用户的 user_id。每来一条用户的访问日志，我们都需要从日志中解析出相应的页面 id 和用户 user_id，去该页面 id 对应的 Set 中查找该 user_id 之前有没有访问过该页面，如果 Set 中包含该 user_id 表示该用户之前访问过该页面，所以该页面的 UV 值不应该加一，如果 Set 中不包含该 user_id 表示该用户之前没有访问过该页面，所以该页面的 UV 值应该加一，并且将该 user_id 插入到该页面对应的 Set 中，表示该用户访问过该页面了。要按天去统计各页面 UV，只需要将日期和页面 id 看做一个整体 key，每个 key 对应一个 Set，其他流程与上述类似。具体的程序流程图如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-11-151250.png" alt=""></p><h4 id="使用-Redis-的-set-来维护用户集合"><a href="#使用-Redis-的-set-来维护用户集合" class="headerlink" title="使用 Redis 的 set 来维护用户集合"></a>使用 Redis 的 set 来维护用户集合</h4><p>每个 key 都需要维护一个 Set，这个 Set 存放在哪里呢？这里每条日志都需要访问一次 Set，对 Set 访问比较频繁，对存储介质的延迟要求比较高，所以可以使用 Redis 的 set 数据结构，Redis 的 set 数据结构也会对数据进行去重。可以将页面 id 和日期拼接做为 Redis 的 key，通过 Redis 的 sadd 命令将 user_id 放到 key 对应的 set 中即可。Redis 的 set 中存放着今天访问过该页面所有用户的 user_id。</p><p>在真实的工作中，Flink 任务可能不需要维护一个 UV 值，Flink 任务承担的角色是实时计算，而查询 UV 可能是一个 Java Web 项目。Web 项目只需要去 Redis 查询相应 key 对应的 set 中元素的个数即可，Redis 的 set 数据结构有 scard 命令可以查询 set 中元素个数，这里的元素个数就是我们所要统计的网站各页面每天的 UV 值。所以使用 Redis set 数据结构的方案 Flink 任务的代码很简单，只需要从日志中解析出相应的日期、页面id 和 user_id，将日期和页面 id 组合做为 Redis 的 key，最后将 user_id 通过 sadd 命令添加到 set 中，Flink 任务的工作就结束了，之后 Web 项目就能从 Redis 中查询到实时增加的 UV 了。下面来看详细的代码实现。</p><p>用户访问网站页面的日志实体类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserVisitWebEvent</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 日志的唯一 id</span></span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">    <span class="comment">// 日期，如：20191025</span></span><br><span class="line">    <span class="keyword">private</span> String date;</span><br><span class="line">    <span class="comment">// 页面 id</span></span><br><span class="line">    <span class="keyword">private</span> Integer pageId;</span><br><span class="line">    <span class="comment">// 用户的唯一标识，用户 id</span></span><br><span class="line">    <span class="keyword">private</span> String userId;</span><br><span class="line">    <span class="comment">// 页面的 url</span></span><br><span class="line">    <span class="keyword">private</span> String url;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成测试数据的核心代码如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">String yyyyMMdd = <span class="keyword">new</span> DateTime(System.currentTimeMillis()).toString(<span class="string">"yyyyMMdd"</span>);</span><br><span class="line"><span class="keyword">int</span> pageId = random.nextInt(<span class="number">10</span>);    <span class="comment">// 随机生成页面 id</span></span><br><span class="line"><span class="keyword">int</span> userId = random.nextInt(<span class="number">100</span>);   <span class="comment">// 随机生成用户 id</span></span><br><span class="line"></span><br><span class="line">UserVisitWebEvent userVisitWebEvent = UserVisitWebEvent.builder()</span><br><span class="line">        .id(UUID.randomUUID().toString())   <span class="comment">// 日志的唯一 id</span></span><br><span class="line">        .date(yyyyMMdd)                     <span class="comment">// 日期</span></span><br><span class="line">        .pageId(pageId)                     <span class="comment">// 页面 id</span></span><br><span class="line">        .userId(Integer.toString(userId))   <span class="comment">// 用户 id</span></span><br><span class="line">        .url(<span class="string">"url/"</span> + pageId)               <span class="comment">// 页面的 url</span></span><br><span class="line">        .build();</span><br><span class="line"><span class="comment">// 对象序列化为 JSON 发送到 Kafka</span></span><br><span class="line">ProducerRecord record = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(topic,</span><br><span class="line">        <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(userVisitWebEvent));</span><br><span class="line">producer.send(record);</span><br></pre></td></tr></table></figure><p>统计 UV 的核心代码如下，对 Redis Connector 不熟悉的请参阅 3.11 节如何使用 Flink Connectors —— Redis：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisSetUvExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//  省略了 env初始化及 Checkpoint 相关配置</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, UvExampleUtil.broker_list);</span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"app-uv-stat"</span>);</span><br><span class="line"></span><br><span class="line">        FlinkKafkaConsumerBase&lt;String&gt; kafkaConsumer = <span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">                UvExampleUtil.topic, <span class="keyword">new</span> SimpleStringSchema(), props)</span><br><span class="line">                .setStartFromLatest();</span><br><span class="line"></span><br><span class="line">        FlinkJedisPoolConfig conf = <span class="keyword">new</span> FlinkJedisPoolConfig</span><br><span class="line">                .Builder().setHost(<span class="string">"192.168.30.244"</span>).build();</span><br><span class="line"></span><br><span class="line">        env.addSource(kafkaConsumer)</span><br><span class="line">                .map(string -&gt; &#123;</span><br><span class="line">                    <span class="comment">// 反序列化 JSON</span></span><br><span class="line">                    UserVisitWebEvent userVisitWebEvent = GsonUtil.fromJson(</span><br><span class="line">                            string, UserVisitWebEvent.class);</span><br><span class="line">                    <span class="comment">// 生成 Redis key，格式为 日期_pageId，如: 20191026_0</span></span><br><span class="line">                    String redisKey = userVisitWebEvent.getDate() + <span class="string">"_"</span></span><br><span class="line">                            + userVisitWebEvent.getPageId();</span><br><span class="line">                    <span class="keyword">return</span> Tuple2.of(redisKey, userVisitWebEvent.getUserId());</span><br><span class="line">                &#125;)</span><br><span class="line">                .returns(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;String, String&gt;&gt;()&#123;&#125;)</span><br><span class="line">                .addSink(<span class="keyword">new</span> RedisSink&lt;&gt;(conf, <span class="keyword">new</span> RedisSaddSinkMapper()));</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">"Redis Set UV Stat"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 数据与 Redis key 的映射关系</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisSaddSinkMapper</span> </span></span><br><span class="line"><span class="class">            <span class="keyword">implements</span> <span class="title">RedisMapper</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt;&gt; </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> RedisCommandDescription <span class="title">getCommandDescription</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">//  这里必须是 sadd 操作</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RedisCommandDescription(RedisCommand.SADD);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getKeyFromData</span><span class="params">(Tuple2&lt;String, String&gt; data)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> data.f0;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getValueFromData</span><span class="params">(Tuple2&lt;String, String&gt; data)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> data.f1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Redis 中统计结果如下图所示，左侧展示的 Redis key，20191026_1 表示 2019年10月26日浏览过 pageId 为 1 的页面对应的 key，右侧展示 key 对应的 set 集合，表示 userId 为 [0,6,27,30,66,67,79,88] 的用户在 2019年10月26日浏览过 pageId 为 1 的页面。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-31-174242.jpg" style="zoom:50%;" /></p><p>要想获取 20191026_1 对应的 UV 值，可通过 scard 命令获取 set 中 user_id 的数量，具体操作如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span> scard 20191026_1</span><br><span class="line">8</span><br></pre></td></tr></table></figure><p>通过上述代码即可通过 Redis 的 set 数据结构来统计网站各页面的 UV。</p><h4 id="使用-Flink-的-KeyedState-来维护用户集合"><a href="#使用-Flink-的-KeyedState-来维护用户集合" class="headerlink" title="使用 Flink 的 KeyedState 来维护用户集合"></a>使用 Flink 的 KeyedState 来维护用户集合</h4><h4 id="使用-Redis-的-HyperLogLog-来统计-UV"><a href="#使用-Redis-的-HyperLogLog-来统计-UV" class="headerlink" title="使用 Redis 的 HyperLogLog 来统计 UV"></a>使用 Redis 的 HyperLogLog 来统计 UV</h4><h3 id="11-1-3-小结与反思"><a href="#11-1-3-小结与反思" class="headerlink" title="11.1.3 小结与反思"></a>11.1.3 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第十一章-——-Flink-实战&quot;&gt;&lt;a href=&quot;#第十一章-——-Flink-实战&quot; class=&quot;headerlink&quot; title=&quot;第十一章 —— Flink 实战&quot;&gt;&lt;/a&gt;第十一章 —— Flink 实战&lt;/h1&gt;&lt;p&gt;本章主要是 Flink 实战，介绍了一些常见的需求，比如实时统计网站页面的 PV/UV、宕机告警、动态更新配置、应用 Error 日志实时告警等，然后分别去分析这些需求的实现方式，明白该使用 Flink 中的哪些知识点才能够很好的完成这种需求，并提供完整的案例代码供大家参考。在实现完成这些需求之后，笔者还将会更深一步的去讲解下这些知识点背后的实现方式，希望可以加深你对这些知识点的印象，以便后面你可以灵活的处理类似的需求。&lt;/p&gt;
&lt;h2 id=&quot;11-1-如何统计网站各页面一天内的-PV-和-UV？&quot;&gt;&lt;a href=&quot;#11-1-如何统计网站各页面一天内的-PV-和-UV？&quot; class=&quot;headerlink&quot; title=&quot;11.1 如何统计网站各页面一天内的 PV 和 UV？&quot;&gt;&lt;/a&gt;11.1 如何统计网站各页面一天内的 PV 和 UV？&lt;/h2&gt;&lt;p&gt;大数据开发最常统计的需求可能就是 PV、UV。PV 全拼 PageView，即页面访问量，用户每次对网站的访问均被记录，按照访问量进行累计，假如用户对同一页面访问了 5 次，那该页面的 PV 就应该加 5。UV 全拼为 UniqueVisitor，即独立访问用户数，访问该页面的一台电脑客户端为一个访客，假如用户对同一页面访问了 5 次，那么该页面的 UV 只应该加 1，因为 UV 计算的是去重后的用户数而不是访问次数。当然如果是按天统计，那么当天 0 点到 24 点相同的客户端只被计算一次，如果过了今天 24 点，第二天该用户又访问了该页面，那么第二天该页面的 UV 应该加 1。 概念明白了那如何使用 Flink 来统计网站各页面的 PV 和 UV 呢？通过本节来详细描述。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何设置 Flink Job RestartStrategy（重启策略）？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/13/flink-in-action-10.2/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/13/flink-in-action-10.2/</id>
    <published>2021-08-12T16:00:00.000Z</published>
    <updated>2022-01-23T12:10:45.524Z</updated>
    
    <content type="html"><![CDATA[<h2 id="10-2-如何使用-Flink-ParameterTool-读取配置？"><a href="#10-2-如何使用-Flink-ParameterTool-读取配置？" class="headerlink" title="10.2 如何使用 Flink ParameterTool 读取配置？"></a>10.2 如何使用 Flink ParameterTool 读取配置？</h2><p>在使用 Flink 中不知道你有没有觉得配置的管理很不方便，比如像算子的并行度配置、Kafka 数据源的配置（broker 地址、topic 名、group.id）、Checkpoint 是否开启、状态后端存储路径、数据库地址、用户名和密码等，反正各种各样的配置都杂乱在一起，当然你可能说我就在代码里面写死不就好了，但是你有没有想过你的作业是否可以不修改任何配置就直接在各种环境（开发、测试、预发、生产）运行呢？可能每个环境的这些配置对应的值都是不一样的，如果你是直接在代码里面写死的配置，那这下子就比较痛苦了，每次换个环境去运行测试你的作业，你都要重新去修改代码中的配置，然后编译打包，提交运行，这样你就要花费很多时间在这些重复的劳动力上了。有没有什么办法可以解决这种问题呢？</p><a id="more"></a><h3 id="10-2-1-Flink-Job-配置"><a href="#10-2-1-Flink-Job-配置" class="headerlink" title="10.2.1 Flink Job 配置"></a>10.2.1 Flink Job 配置</h3><p>在 Flink 中其实是有几种方法来管理配置，下面分别来讲解一下。</p><h4 id="使用-Configuration"><a href="#使用-Configuration" class="headerlink" title="使用 Configuration"></a>使用 Configuration</h4><p>Flink 提供了 withParameters 方法，它可以传递 Configuration 中的参数给，要使用它，需要实现那些 Rich 函数，比如实现 RichMapFunction，而不是 MapFunction，因为 Rich 函数中有 open 方法，然后可以重写 open 方法通过 Configuration 获取到传入的参数值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// Configuration 类来存储参数</span></span><br><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">configuration.setString(<span class="string">"name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line"></span><br><span class="line">env.fromElements(WORDS)</span><br><span class="line">        .flatMap(<span class="keyword">new</span> RichFlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            String name;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">//读取配置</span></span><br><span class="line">                name = parameters.getString(<span class="string">"name"</span>, <span class="string">""</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                String[] splits = value.toLowerCase().split(<span class="string">"\\W+"</span>);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> (String split : splits) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (split.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        out.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(split + name, <span class="number">1</span>));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).withParameters(configuration)    <span class="comment">//将参数传递给函数</span></span><br><span class="line">        .print();</span><br></pre></td></tr></table></figure><p>但是要注意这个 withParameters 只在批程序中支持，流程序中是没有该方法的，并且这个 withParameters 要在每个算子后面使用才行，并不是一次使用就所有都可以获取到，如果所有算子都要该配置，那么就重复设置多次就会比较繁琐。</p><h3 id="10-2-2-ParameterTool-管理配置"><a href="#10-2-2-ParameterTool-管理配置" class="headerlink" title="10.2.2 ParameterTool 管理配置"></a>10.2.2 ParameterTool 管理配置</h3><p>上面通过 Configuration 的局限性很大，其实在 Flink 中还可以通过使用 ParameterTool 类读取配置，它可以读取环境变量、运行参数、配置文件，下面分别讲下每种如何使用。</p><h4 id="读取运行参数"><a href="#读取运行参数" class="headerlink" title="读取运行参数"></a>读取运行参数</h4><p>我们知道 Flink UI 上是支持为每个 Job 单独传入 arguments（参数）的，它的格式要求是如下这种。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--brokers 127.0.0.1:9200</span><br><span class="line">--username admin</span><br><span class="line">--password 123456</span><br></pre></td></tr></table></figure><p>或者这种</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-brokers 127.0.0.1:9200</span><br><span class="line">-username admin</span><br><span class="line">-password 123456</span><br></pre></td></tr></table></figure><p>然后在 Flink 程序中你可以直接使用 <code>ParameterTool.fromArgs(args)</code> 获取到所有的参数，然后如果你要获取某个参数对应的值的话，可以通过 <code>parameterTool.get(&quot;username&quot;)</code> 方法。那么在这个地方其实你就可以将配置放在一个第三方的接口，然后这个参数值中传入一个接口，拿到该接口后就能够通过请求去获取更多你想要的配置。</p><h4 id="读取系统属性"><a href="#读取系统属性" class="headerlink" title="读取系统属性"></a>读取系统属性</h4><p>ParameterTool 还支持通过 <code>ParameterTool.fromSystemProperties()</code> 方法读取系统属性。</p><h4 id="读取配置文件"><a href="#读取配置文件" class="headerlink" title="读取配置文件"></a>读取配置文件</h4><p>除了上面两种外，ParameterTool 还支持 <code>ParameterTool.fromPropertiesFile(&quot;/application.properties&quot;)</code> 读取 properties 配置文件。你可以将所有要配置的地方（比如并行度和一些 Kafka、MySQL 等配置）都写成可配置的，然后其对应的 key 和 value 值都写在配置文件中，最后通过 ParameterTool 去读取配置文件获取对应的值。</p><h4 id="ParameterTool-获取值"><a href="#ParameterTool-获取值" class="headerlink" title="ParameterTool 获取值"></a>ParameterTool 获取值</h4><p>ParameterTool 类提供了很多便捷方法去获取值，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-09-134119.png" alt=""></p><p>你可以在应用程序的 main() 方法中直接使用这些方法返回的值，例如：你可以按如下方法来设置一个算子的并行度：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ParameterTool parameters = ParameterTool.fromArgs(args);</span><br><span class="line"><span class="keyword">int</span> parallelism = parameters.get(<span class="string">"mapParallelism"</span>, <span class="number">2</span>);</span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts = data.flatMap(<span class="keyword">new</span> Tokenizer()).setParallelism(parallelism);</span><br></pre></td></tr></table></figure><p>因为 ParameterTool 是可序列化的，所以你可以将它当作参数进行传递给自定义的函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ParameterTool parameters = ParameterTool.fromArgs(args);</span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts = dara.flatMap(<span class="keyword">new</span> Tokenizer(parameters));</span><br></pre></td></tr></table></figure><p>然后在函数内部使用 ParameterTool 来获取命令行参数，这样就意味着你在作业任何地方都可以获取到参数，而不是像 withParameters 一样需要每次都设置。</p><h4 id="注册全局参数"><a href="#注册全局参数" class="headerlink" title="注册全局参数"></a>注册全局参数</h4><p>在 ExecutionConfig 中可以将 ParameterTool 注册为全作业参数的参数，这样就可以被 JobManager 的 web 端以及用户自定义函数中以配置值的形式访问。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.getConfig().setGlobalJobParameters(ParameterTool.fromArgs(args));</span><br></pre></td></tr></table></figure><p>然后就可以在用户自定义的 Rich 函数中像如下这样获取到参数值了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">env.addSource(<span class="keyword">new</span> RichSourceFunction&lt;String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;String&gt; sourceContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ParameterTool parameterTool = (ParameterTool) getRuntimeContext().getExecutionConfig().getGlobalJobParameters();</span><br><span class="line">            sourceContext.collect(System.currentTimeMillis() + parameterTool.get(<span class="string">"os.name"</span>) + parameterTool.get(<span class="string">"user.home"</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>在笔者公司内通常是以 Job 运行的环境变量为准，比如我们是运行在 K8s 上面，那么我们会为我们的这个 Flink Job 设置很多环境变量，设置的环境变量的值就得通过 ParameterTool 类去获取，我们是会优先根据环境变量的值为准，如果环境变量的值没有就会去读取应用运行参数，如果应用运行参数也没有才会去读取之前已经写好在配置文件中的配置。大概代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ParameterTool <span class="title">createParameterTool</span><span class="params">(<span class="keyword">final</span> String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ParameterTool</span><br><span class="line">            .fromPropertiesFile(ExecutionEnv.class.getResourceAsStream(<span class="string">"/application.properties"</span>))</span><br><span class="line">            .mergeWith(ParameterTool.fromArgs(args))</span><br><span class="line">            .mergeWith(ParameterTool.fromSystemProperties())</span><br><span class="line">            .mergeWith(ParameterTool.fromMap(getenv()));<span class="comment">// mergeWith 会使用最新的配置</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取 Job 设置的环境变量</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">getenv</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry : System.getenv().entrySet()) &#123;</span><br><span class="line">        map.put(entry.getKey().toLowerCase().replace(<span class="string">'_'</span>, <span class="string">'.'</span>), entry.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> map;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样如果 Job 要更改一些配置，直接在 Job 在 K8s 上面的环境变量进行配置就好了，修改配置后然后重启 Job 就可以运行起来了，整个过程都不需要再次将作业重新编译打包的。但是这样其实也有一定的坏处，重启一个作业的代价很大，因为在重启后你又要去保证状态要恢复到之前未重启时的状态，尽管 Flink 中的 Checkpoint 和 Savepoint 已经很强大了，但是对于复杂的它来说我们多一事不如少一事，所以其实更希望能够直接动态的获取配置，如果配置做了更改，作业能够感知到。在 Flink 中有的配置是不能够动态设置的，但是比如应用业务配置却是可以做到动态的配置，这时就需要使用比较强大的广播变量，广播变量在之前 3.4 节已经介绍过了，如果忘记可以再回去查看，另外在 11.4 节中会通过一个实际案例来教你如何使用广播变量去动态的更新配置数据。</p><h3 id="10-2-3-ParameterTool-源码分析"><a href="#10-2-3-ParameterTool-源码分析" class="headerlink" title="10.2.3 ParameterTool 源码分析"></a>10.2.3 ParameterTool 源码分析</h3><h3 id="10-2-4-自定义配置参数类"><a href="#10-2-4-自定义配置参数类" class="headerlink" title="10.2.4 自定义配置参数类"></a>10.2.4 自定义配置参数类</h3><h3 id="10-2-5-小结与反思"><a href="#10-2-5-小结与反思" class="headerlink" title="10.2.5 小结与反思"></a>10.2.5 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>本章讲了两个实践相关的内容，一个是作业的重启策略，从分析真实线上故障来教大家如何去配置重启策略，以及介绍重启策略的种类，另一个是使用 ParameterTool 去管理配置。两个实践都是比较真实且有一定帮助作用的，希望你也可以应用在你的项目中去。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;10-2-如何使用-Flink-ParameterTool-读取配置？&quot;&gt;&lt;a href=&quot;#10-2-如何使用-Flink-ParameterTool-读取配置？&quot; class=&quot;headerlink&quot; title=&quot;10.2 如何使用 Flink ParameterTool 读取配置？&quot;&gt;&lt;/a&gt;10.2 如何使用 Flink ParameterTool 读取配置？&lt;/h2&gt;&lt;p&gt;在使用 Flink 中不知道你有没有觉得配置的管理很不方便，比如像算子的并行度配置、Kafka 数据源的配置（broker 地址、topic 名、group.id）、Checkpoint 是否开启、状态后端存储路径、数据库地址、用户名和密码等，反正各种各样的配置都杂乱在一起，当然你可能说我就在代码里面写死不就好了，但是你有没有想过你的作业是否可以不修改任何配置就直接在各种环境（开发、测试、预发、生产）运行呢？可能每个环境的这些配置对应的值都是不一样的，如果你是直接在代码里面写死的配置，那这下子就比较痛苦了，每次换个环境去运行测试你的作业，你都要重新去修改代码中的配置，然后编译打包，提交运行，这样你就要花费很多时间在这些重复的劳动力上了。有没有什么办法可以解决这种问题呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何设置 Flink Job RestartStrategy（重启策略）？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/12/flink-in-action-10.1/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/12/flink-in-action-10.1/</id>
    <published>2021-08-11T16:00:00.000Z</published>
    <updated>2022-01-23T12:08:58.313Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第十章-——-Flink-最佳实践"><a href="#第十章-——-Flink-最佳实践" class="headerlink" title="第十章 —— Flink 最佳实践"></a>第十章 —— Flink 最佳实践</h1><p>本章将介绍两个最佳实践，第一个是如何合理的配置重启策略，笔者通过自己的亲身经历来讲述配置重启策略的重要性，接着介绍了 Flink 中的重启策略和恢复策略的发展实现过程；第二个是如何去管理 Flink 作业的配置。两个实践大家可以参考，不一定要照搬运用在自己的公司，同时也希望你可以思考下自己是否有啥最佳实践可以分享。</p><h2 id="10-1-如何设置-Flink-Job-RestartStrategy（重启策略）？"><a href="#10-1-如何设置-Flink-Job-RestartStrategy（重启策略）？" class="headerlink" title="10.1 如何设置 Flink Job RestartStrategy（重启策略）？"></a>10.1 如何设置 Flink Job RestartStrategy（重启策略）？</h2><p>从使用 Flink 到至今，遇到的 Flink 有很多，解决的问题更多（含帮助微信好友解决问题），所以对于 Flink 可能遇到的问题及解决办法都比较清楚，那么在这章就给大家讲解下几个 Flink 中比较常遇到的问题的解决办法。</p><a id="more"></a><h3 id="10-1-1-常见错误导致-Flink-作业重启"><a href="#10-1-1-常见错误导致-Flink-作业重启" class="headerlink" title="10.1.1 常见错误导致 Flink 作业重启"></a>10.1.1 常见错误导致 Flink 作业重启</h3><p>不知道大家是否有遇到过这样的问题：整个 Job 一直在重启，并且还会伴随着一些错误（可以通过 UI 查看 Exceptions 日志），以下三张图片中的错误信息是笔者曾经生产环境遇到过的一些问题。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-04-152844.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-140519.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-26-2019-05-14_00-59-25.png" alt=""></p><p>笔者就曾因为上图中的一个异常报错，作业一直重启，在深夜线上发版的时候，同事发现这个问题，凌晨两点的时候打电话把我叫醒起来修 BUG，真是惨的教训，哈哈哈，估计这辈子都忘不掉了！</p><p>其实遇到上面这种问题比较常见的，比如有时候因为数据的问题（不合规范、为 null 等），这时在处理这些脏数据的时候可能就会遇到各种各样的异常错误，比如空指针、数组越界、数据类型转换错误等。可能你会说只要过滤掉这种脏数据就行了，或者进行异常捕获就不会导致 Job 不断重启的问题了。</p><p>确实如此，如果做好了脏数据的过滤和异常的捕获，Job 的稳定性确实有保证，但是复杂的 Job 下每个算子可能都会产生出脏数据（包含源数据可能也会为空或者不合法的数据），你不可能在每个算子里面也用一个大的 try catch 做一个异常捕获，所以脏数据和异常简直就是防不胜防，不过我们还是要尽力的保证代码的健壮性，但是也要配置好 Flink Job 的 RestartStrategy（重启策略）。</p><h3 id="10-1-2-RestartStrategy-简介"><a href="#10-1-2-RestartStrategy-简介" class="headerlink" title="10.1.2 RestartStrategy 简介"></a>10.1.2 RestartStrategy 简介</h3><p>RestartStrategy，重启策略，在遇到机器或者代码等不可预知的问题时导致 Job 或者 Task 挂掉的时候，它会根据配置的重启策略将 Job 或者受影响的 Task 拉起来重新执行，以使得作业恢复到之前正常执行状态。Flink 中的重启策略决定了是否要重启 Job 或者 Task，以及重启的次数和每次重启的时间间隔。</p><h3 id="10-1-3-为什么需要-RestartStrategy？"><a href="#10-1-3-为什么需要-RestartStrategy？" class="headerlink" title="10.1.3 为什么需要 RestartStrategy？"></a>10.1.3 为什么需要 RestartStrategy？</h3><p>重启策略会让 Job 从上一次完整的 Checkpoint 处恢复状态，保证 Job 和挂之前的状态保持一致，另外还可以让 Job 继续处理数据，不会出现 Job 挂了导致消息出现大量堆积的问题，合理的设置重启策略可以减少 Job 不可用时间和避免人工介入处理故障的运维成本，因此重启策略对于 Flink Job 的稳定性来说有着举足轻重的作用。</p><h3 id="10-1-4-如何配置-RestartStrategy？"><a href="#10-1-4-如何配置-RestartStrategy？" class="headerlink" title="10.1.4 如何配置 RestartStrategy？"></a>10.1.4 如何配置 RestartStrategy？</h3><p>既然 Flink 中的重启策略作用这么大，那么该如何配置呢？其实如果 Flink Job 没有单独设置重启重启策略的话，则会使用集群启动时加载的默认重启策略，如果 Flink Job 中单独设置了重启策略则会覆盖默认的集群重启策略。默认重启策略可以在 Flink 的配置文件 <code>flink-conf.yaml</code> 中设置，由 <code>restart-strategy</code> 参数控制，有 fixed-delay（固定延时重启策略）、failure-rate（故障率重启策略）、none（不重启策略）三种可以选择，如果选择的参数不同，对应的其他参数也不同。下面分别介绍这几种重启策略和如何配置。</p><h4 id="FixedDelayRestartStrategy（固定延时重启策略）"><a href="#FixedDelayRestartStrategy（固定延时重启策略）" class="headerlink" title="FixedDelayRestartStrategy（固定延时重启策略）"></a>FixedDelayRestartStrategy（固定延时重启策略）</h4><p>FixedDelayRestartStrategy 是固定延迟重启策略，程序按照集群配置文件中或者程序中额外设置的重启次数尝试重启作业，如果尝试次数超过了给定的最大次数，程序还没有起来，则停止作业，另外还可以配置连续两次重启之间的等待时间，在 <code>flink-conf.yaml</code> 中可以像下面这样配置。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">fixed-delay</span></span><br><span class="line"><span class="string">restart-strategy.fixed-delay.attempts:</span> <span class="number">3</span>  <span class="comment">#表示作业重启的最大次数，启用 checkpoint 的话是 Integer.MAX_VALUE，否则是 1。</span></span><br><span class="line"><span class="string">restart-strategy.fixed-delay.delay:</span> <span class="number">10</span> <span class="string">s</span>  <span class="comment">#如果设置分钟可以类似 1 min，该参数表示两次重启之间的时间间隔，当程序与外部系统有连接交互时延迟重启可能会有帮助，启用 checkpoint 的话，延迟重启的时间是 10 秒，否则使用 akka.ask.timeout 的值。</span></span><br></pre></td></tr></table></figure><p>在程序中设置固定延迟重启策略的话如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 尝试重启的次数</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 延时</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure><h4 id="FailureRateRestartStrategy（故障率重启策略）"><a href="#FailureRateRestartStrategy（故障率重启策略）" class="headerlink" title="FailureRateRestartStrategy（故障率重启策略）"></a>FailureRateRestartStrategy（故障率重启策略）</h4><p>FailureRateRestartStrategy 是故障率重启策略，在发生故障之后重启作业，如果固定时间间隔之内发生故障的次数超过设置的值后，作业就会失败停止，该重启策略也支持设置连续两次重启之间的等待时间。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">failure-rate</span></span><br><span class="line"><span class="string">restart-strategy.failure-rate.max-failures-per-interval:</span> <span class="number">3</span>  <span class="comment">#固定时间间隔内允许的最大重启次数，默认 1</span></span><br><span class="line"><span class="string">restart-strategy.failure-rate.failure-rate-interval:</span> <span class="number">5</span> <span class="string">min</span>  <span class="comment">#固定时间间隔，默认 1 分钟</span></span><br><span class="line"><span class="string">restart-strategy.failure-rate.delay:</span> <span class="number">10</span> <span class="string">s</span> <span class="comment">#连续两次重启尝试之间的延迟时间，默认是 akka.ask.timeout</span></span><br></pre></td></tr></table></figure><p>可以在应用程序中这样设置来配置故障率重启策略：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.failureRateRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 固定时间间隔允许 Job 重启的最大次数</span></span><br><span class="line">  Time.of(<span class="number">5</span>, TimeUnit.MINUTES), <span class="comment">// 固定时间间隔</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 两次重启的延迟时间</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure><h4 id="NoRestartStrategy（不重启策略）"><a href="#NoRestartStrategy（不重启策略）" class="headerlink" title="NoRestartStrategy（不重启策略）"></a>NoRestartStrategy（不重启策略）</h4><p>NoRestartStrategy 作业不重启策略，直接失败停止，在 <code>flink-conf.yaml</code> 中配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">none</span></span><br></pre></td></tr></table></figure><p>在程序中如下设置即可配置不重启：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.noRestart());</span><br></pre></td></tr></table></figure><h4 id="Fallback（备用重启策略）"><a href="#Fallback（备用重启策略）" class="headerlink" title="Fallback（备用重启策略）"></a>Fallback（备用重启策略）</h4><p>如果程序没有启用 Checkpoint，则采用不重启策略，如果开启了 Checkpoint 且没有设置重启策略，那么采用固定延时重启策略，最大重启次数为 Integer.MAX_VALUE。</p><p>在应用程序中配置好了固定延时重启策略，可以测试一下代码异常后导致 Job 失败后重启的情况，然后观察日志，可以看到 Job 重启相关的日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Try to restart or fail the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) if no longer possible.</span><br><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) switched from state FAILING to RESTARTING.</span><br><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Restarting the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0).</span><br></pre></td></tr></table></figure><p>最后重启次数达到配置的最大重启次数后 Job 还没有起来的话，则会停止 Job 并打印日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[flink-akka.actor.default-dispatcher-2] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Could not restart the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) because the restart strategy prevented it.</span><br></pre></td></tr></table></figure><p>Flink 中几种重启策略的设置如上，大家可以根据需要选择合适的重启策略，比如如果程序抛出了空指针异常，但是你配置的是一直无限重启，那么就会导致 Job 一直在重启，这样无非再浪费机器资源，这种情况下可以配置重试固定次数，每次隔多久重试的固定延时重启策略，这样在重试一定次数后 Job 就会停止，如果对 Job 的状态做了监控告警的话，那么你就会收到告警信息，这样也会提示你去查看 Job 的运行状况，能及时的去发现和修复 Job 的问题。</p><h3 id="10-1-5-RestartStrategy-源码分析"><a href="#10-1-5-RestartStrategy-源码分析" class="headerlink" title="10.1.5 RestartStrategy 源码分析"></a>10.1.5 RestartStrategy 源码分析</h3><p>再介绍重启策略应用程序代码配置的时候不知道你有没有看到设置重启策略都是使用 RestartStrategies 类，通过该类的方法就可以创建不同的重启策略，在 RestartStrategies 类中提供了五个方法用来创建四种不同的重启策略（有两个方法是创建 FixedDelay 重启策略的，只不过方法的参数不同），如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151745.png" alt=""></p><p>在每个方法内部其实调用的是 RestartStrategies 中的内部静态类，分别是 NoRestartStrategyConfiguration、FixedDelayRestartStrategyConfiguration、FailureRateRestartStrategyConfiguration、FallbackRestartStrategyConfiguration，这四个类都继承自 RestartStrategyConfiguration 抽象类，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151617.png" alt=""></p><p>上面是定义的四种重启策略的配置类，在 Flink 中是靠 RestartStrategyResolving 类中的 resolve 方法来解析 RestartStrategies.RestartStrategyConfiguration，然后根据配置使用 RestartStrategyFactory 创建 RestartStrategy。RestartStrategy 是一个接口，它有 canRestart 和 restart 两个方法，它有四个实现类： FixedDelayRestartStrategy、FailureRateRestartStrategy、ThrowingRestartStrategy、NoRestartStrategy，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151311.png" alt=""></p><h3 id="10-1-6-Failover-Strategies（故障恢复策略）"><a href="#10-1-6-Failover-Strategies（故障恢复策略）" class="headerlink" title="10.1.6 Failover Strategies（故障恢复策略）"></a>10.1.6 Failover Strategies（故障恢复策略）</h3><h4 id="重启所有的任务"><a href="#重启所有的任务" class="headerlink" title="重启所有的任务"></a>重启所有的任务</h4><h4 id="基于-Region-的局部故障重启策略"><a href="#基于-Region-的局部故障重启策略" class="headerlink" title="基于 Region 的局部故障重启策略"></a>基于 Region 的局部故障重启策略</h4><h3 id="10-1-7-小结与反思"><a href="#10-1-7-小结与反思" class="headerlink" title="10.1.7 小结与反思"></a>10.1.7 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/RBYj66M">https://t.zsxq.com/RBYj66M</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第十章-——-Flink-最佳实践&quot;&gt;&lt;a href=&quot;#第十章-——-Flink-最佳实践&quot; class=&quot;headerlink&quot; title=&quot;第十章 —— Flink 最佳实践&quot;&gt;&lt;/a&gt;第十章 —— Flink 最佳实践&lt;/h1&gt;&lt;p&gt;本章将介绍两个最佳实践，第一个是如何合理的配置重启策略，笔者通过自己的亲身经历来讲述配置重启策略的重要性，接着介绍了 Flink 中的重启策略和恢复策略的发展实现过程；第二个是如何去管理 Flink 作业的配置。两个实践大家可以参考，不一定要照搬运用在自己的公司，同时也希望你可以思考下自己是否有啥最佳实践可以分享。&lt;/p&gt;
&lt;h2 id=&quot;10-1-如何设置-Flink-Job-RestartStrategy（重启策略）？&quot;&gt;&lt;a href=&quot;#10-1-如何设置-Flink-Job-RestartStrategy（重启策略）？&quot; class=&quot;headerlink&quot; title=&quot;10.1 如何设置 Flink Job RestartStrategy（重启策略）？&quot;&gt;&lt;/a&gt;10.1 如何设置 Flink Job RestartStrategy（重启策略）？&lt;/h2&gt;&lt;p&gt;从使用 Flink 到至今，遇到的 Flink 有很多，解决的问题更多（含帮助微信好友解决问题），所以对于 Flink 可能遇到的问题及解决办法都比较清楚，那么在这章就给大家讲解下几个 Flink 中比较常遇到的问题的解决办法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何处理 Flink 中数据倾斜问题？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/11/flink-in-action-9.6/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/11/flink-in-action-9.6/</id>
    <published>2021-08-10T16:00:00.000Z</published>
    <updated>2022-01-23T12:05:28.185Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-6-如何处理-Flink-中数据倾斜问题？"><a href="#9-6-如何处理-Flink-中数据倾斜问题？" class="headerlink" title="9.6 如何处理 Flink 中数据倾斜问题？"></a>9.6 如何处理 Flink 中数据倾斜问题？</h2><p>在大数据计算场景，无论使用 MapReduce、Spark 还是 Flink 计算框架，无论是批处理还是流处理都存在数据倾斜的问题，通过本节学习产生数据倾斜的原因及如何在生产环境解决数据倾斜。</p><a id="more"></a><h3 id="9-6-1-数据倾斜简介"><a href="#9-6-1-数据倾斜简介" class="headerlink" title="9.6.1 数据倾斜简介"></a>9.6.1 数据倾斜简介</h3><p>分析一个计算各 app PV 的案例，如下图所示，圆球表示 app1 的日志，方块表示 app2 的日志，Source 端从外部系统读取用户上报的各 app 行为日志，要计算各 app 的 PV，所以按照 app 进行 keyBy，相同 app 的数据发送到同一个 Operator 实例中处理，keyBy 后对 app 的 PV 值进行累加来，最后将计算的 PV 结果输出到外部 Sink 端。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004442.jpg" alt=""></p><p>可以看到在任务运行过程中，计算 Count 的算子有两个并行度，其中一个并行度处理 app1 的数据，另一个并行度处理 app2 的数据。由于 app1 比较热门，所以 app1 的日志量远大于 app2 的日志量，造成计算 app1 PV 的并行度压力过大成为整个系统的瓶颈，而计算 app2 PV 的并行度数据量较少所以 CPU、内存以及网络资源的使用率整体都比较低，这就是产生数据倾斜的案例。</p><p>随着业务的不断发展，如果 app1 的日志量暴增，单个节点的单个并行度已经承担不了计算 app1 PV 的任务，此时如何来解决呢？对于不了解数据倾斜的同学看到 Flink 任务出现了延迟，结合之前学习的反压章节，定位整个 Flink 任务的瓶颈在于 Count 算子，所以认为 Count 算子的并行度不够，于是解决思路就是调大 Count 算子的并行度至 4 来提高 Count 算子的计算能力，调大并行度以后发现 Flink 任务的吞吐量并没有提升，而且通过反压机制定位到系统的瓶颈还在于 Count 算子，难道 Count 算子的并行度需要从 2 调大到 10 吗？No，上述情况就算把并行度调大到 100，依然不能解决任务瓶颈。为什么出现这种情况呢？要计算各 app 的 PV 数据，那么相同 app 的数据必然要发送到相同的 Operator 实例去处理，现在只有两个 app，最多只能分配到两个并行度上去执行，如果 Count 算子的并行度大于 2，意味着肯定有一些并行度分配不到数据，所以上述情况调大 Count 算子的并行度不能解决问题。那使用 Flink 如何来解决数据倾斜呢，我们先学习 Flink 中如何来判断是否发生了数据倾斜。</p><h3 id="9-6-2-判断是否存在数据倾斜"><a href="#9-6-2-判断是否存在数据倾斜" class="headerlink" title="9.6.2 判断是否存在数据倾斜"></a>9.6.2 判断是否存在数据倾斜</h3><p>这里再通过一个案例来讲述 Flink 任务如何来判断是否存在数据倾斜，如下图所示，是 Flink Web UI Job 页面展示的任务执行计划，可以看到任务经过 Operator Chain 后，总共有两个 Task，上游 Task 将数据 keyBy 后发送到下游 Task，如何判断第二个 Task 计算的数据是否存在数据呢？</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004443.jpg" alt=""></p><p>如下图所示，通过 Flink Web UI 中 Job 页面的第一个 Subtasks 选项卡，可以看到任务的两个 Task，点击 Task，可以看到 Task 相应的 Subtask 详情。例如 Subtask 的启动时间、结束时间、持续时长、接收数据量的字节数以及接收数据的个数。图中可以看到，相同 Task 的多个 Subtask 中，有的 Subtask 接收到 1.69 TB 的数据量，有的 Subtask 接收到 17.6 TB 的数据量，通过 Flink Web UI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜，接下来学习 Flink 中如何来解决数据倾斜。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004431.jpg" alt=""></p><h3 id="9-6-3-分析和解决数据倾斜问题"><a href="#9-6-3-分析和解决数据倾斜问题" class="headerlink" title="9.6.3 分析和解决数据倾斜问题"></a>9.6.3 分析和解决数据倾斜问题</h3><p>在 Flink 中，很多因素都会导致数据倾斜，例如 9.6.1 节描述的 keyBy 后的聚合操作存在数据倾斜。keyBy 之前的数据直接来自于数据源，一般不会出现数据倾斜，除非数据源中的数据发生了数据倾斜。本小节将从多个角度来解决数据倾斜。</p><h5 id="keyBy-后的聚合操作存在数据倾斜"><a href="#keyBy-后的聚合操作存在数据倾斜" class="headerlink" title="keyBy 后的聚合操作存在数据倾斜"></a>keyBy 后的聚合操作存在数据倾斜</h5><h5 id="keyBy-之前发生数据倾斜"><a href="#keyBy-之前发生数据倾斜" class="headerlink" title="keyBy 之前发生数据倾斜"></a>keyBy 之前发生数据倾斜</h5><h3 id="9-6-4-小结与反思"><a href="#9-6-4-小结与反思" class="headerlink" title="9.6.4 小结与反思"></a>9.6.4 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>在前一章中讲解了 Flink 监控系统的重要性，这章主要讲解 Flink 作业的性能调优。当作业出现各种各样的问题时，其实这时就体现了前面章节提到的监控的重要性，所以本章的内容也比较依赖于监控系统，然后才能够更好的去排查问题，然后去解决问题。</p><p>在本章中讲解的反压问题、并行度设置问题、数据倾斜问题等都是开发作业时要注意的点，本章不仅讲解了这些问题出现后的解决方案，还深入的剖析了这些问题为啥会出现，只有知其原因后，后面开发新的作业时才会去注意这些问题。本章的内容属于高阶玩家要掌握的，希望你也能够好好理解，在你们公司遇到同样问题的时候可以站出来去解决。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-6-如何处理-Flink-中数据倾斜问题？&quot;&gt;&lt;a href=&quot;#9-6-如何处理-Flink-中数据倾斜问题？&quot; class=&quot;headerlink&quot; title=&quot;9.6 如何处理 Flink 中数据倾斜问题？&quot;&gt;&lt;/a&gt;9.6 如何处理 Flink 中数据倾斜问题？&lt;/h2&gt;&lt;p&gt;在大数据计算场景，无论使用 MapReduce、Spark 还是 Flink 计算框架，无论是批处理还是流处理都存在数据倾斜的问题，通过本节学习产生数据倾斜的原因及如何在生产环境解决数据倾斜。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink 中如何保证 Exactly Once？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/11/flink-in-action-9.5/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/11/flink-in-action-9.5/</id>
    <published>2021-08-10T16:00:00.000Z</published>
    <updated>2022-01-23T12:03:10.112Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-5-Flink-中如何保证-Exactly-Once？"><a href="#9-5-Flink-中如何保证-Exactly-Once？" class="headerlink" title="9.5 Flink 中如何保证 Exactly Once？"></a>9.5 Flink 中如何保证 Exactly Once？</h2><p>在分布式场景下，我们的应用程序随时可能出现任何形式的故障，例如：机器硬件故障、程序 OOM 等。当应用程序出现故障时，Flink 为了保证数据消费的 Exactly Once，需要有相应的故障容错能力。Flink 是通过周期性 Checkpoint 的方式来实现故障容错，这里使用的是基于 Chandy-Lamport 改进的算法。本节会介绍 Flink 内部如何保证 Exactly Once 以及端对端如何保证 Exactly Once。</p><a id="more"></a><h3 id="9-5-1-Flink-内部如何保证-Exactly-Once？"><a href="#9-5-1-Flink-内部如何保证-Exactly-Once？" class="headerlink" title="9.5.1 Flink 内部如何保证 Exactly Once？"></a>9.5.1 Flink 内部如何保证 Exactly Once？</h3><p>Flink 官网的定义是 Stateful Computations over Data Streams（数据流上的有状态计算），那到底什么是状态呢？举一个无状态计算的例子，比如：我们只是进行一个字符串拼接，输入a，输出a_666,输入b，输出 b_666。无状态表示计算输出的结果跟之前的状态没关系，符合幂等性。幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生副作用。而计算 PV、UV 就属于有状态计算。实时计算 PV 时，每次都需要从某个存储介质的结果表中拿到之前的 PV 值，+1 后 set 到结果表中。有状态计算表示输出的结果跟之前的状态有关系，不符合幂等性，访问多次，PV 会增加。</p><h4 id="Flink的-Checkpoint-功能简介"><a href="#Flink的-Checkpoint-功能简介" class="headerlink" title="Flink的 Checkpoint 功能简介"></a>Flink的 Checkpoint 功能简介</h4><p>Flink Checkpoint 机制的存在就是为了解决 Flink 任务在运行过程中由于各种原因导致任务失败后，能够正常恢复任务。那 Checkpoint 具体做了哪些功能，为什么任务挂掉之后，通过 Checkpoint 机制能使得任务恢复呢？Checkpoint 是通过给程序做快照的方式使得将整个程序某些时刻的状态保存下来，当任务挂掉之后，默认从最近一次保存的完整快照处进行恢复任务。问题来了，快照是什么东西？SnapShot翻译为快照，是指将程序中某些信息存一份，后期可以用这些信息来恢复任务。对于一个 Flink 任务来讲，快照里面到底保存着什么信息呢？理论知识一般比较晦涩难懂，我们分析一个案例，用案例辅助大家理解快照里面到底存储什么信息。计算各个 app 的 PV，使用 Flink 该怎么统计呢？</p><p>可以把要统计的 app_id 做为 key，对应的 PV 值做为 value，将统计的结果放到一个 Map 集合中，这个 Map 集合可以是内存里的 HashMap 或其他 kv 数据库，例如放到Redis 的 key、value 结构中。从 Kafka 读取到一条条日志，由于要统计各 app 的 PV，所以我们需要从日志中解析出 app_id 字段，每来一条日志，只需要从 Map 集合将相应 app_id 的 PV 值拿出来，+1 后 put 到 Map 中，这样我们的 Map 中永远保存着所有 app 最新的 PV 数据。详细流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151541.jpg" alt="flink任务task图.png" style="zoom:50%;" /></p><p>图中包含三部分：第一个是 Kafka 的一个名为 test 的 Topic，我们的数据来源于这个 Topic，第二个是 Flink 的 Source Task，是 Flink 应用程序读取数据的 Task，第三个是计算 PV 的 Flink Task，用于统计各个 app 的 PV 值，并将 PV 结果输出到 Map 集合。</p><p>Flink 的 Source Task 记录了当前消费到 test Topic 所有 partition 的 offset，为了方便理解 Checkpoint 的作用，这里先用一个 partition 进行讲解，假设名为 test 的 Topic只有一个partition0。例：（0，60000）表示0号partition 目前消费到 offset 为 60000 的数据。Flink 的 PV task 记录了当前计算的各 app 的 PV 值，为了方便讲解，这里假设有两个app：app1、app2。例：（app1，50000）（app2，10000）表示 app1 当前 PV 值为50000、app2 当前 PV 值为 10000。计算过程中，每来一条数据，只需要确定相应 app_id，将相应的 PV 值 +1 后 put 到 map 中即可。</p><p>该案例中，Checkpoint 到底记录了什么信息呢？记录的其实就是第 n 次 Checkpoint 消费的 offset 信息和各app 的 PV 值信息，记录下发生 Checkpoint 当前的状态信息，并将该状态信息保存到相应的状态后端。（注：<strong>状态后端是保存状态的地方</strong>，决定状态如何保存，如何保证状态高可用，我们只需要知道，我们能从状态后端拿到 offset 信息和 PV 信息即可。状态后端必须是高可用的，否则我们的状态后端经常出现故障，会导致无法通过 Checkpoint 来恢复我们的应用程序）。下面列出了第 100 次 Checkpoint 的时候，状态后端保存的状态信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chk-100</span><br><span class="line">- offset：（0，60000）</span><br><span class="line">- PV：（app1，50000）（app2，10000）</span><br></pre></td></tr></table></figure><p>该状态信息表示第 100 次 Checkpoint 的时候， partition 0 offset 消费到了 60000，PV 统计结果为（app1，50000）（app2，10000） 。如果任务挂了，如何恢复？</p><p>假如我们设置了一分钟进行一次 Checkpoint，第 100 次 Checkpoint 成功后，过了十秒钟，offset已经消费到 （0，60100），PV 统计结果变成了（app1，50080）（app2，10020），突然任务挂了，怎么办？其实很简单，Flink 只需要从最近一次成功的 Checkpoint，也就是从第 100 次 Checkpoint 保存的 offset（0，60000）处接着消费即可，当然 PV 值也要从第 100 次 Checkpoint 里保存的 PV 值（app1，50000）（app2，10000）进行累加，不能从（app1，50080）（app2，10020）处进行累加，因为 <strong>partition 0 offset消费到 60000 时，对应的 PV 统计结果为（app1，50000）（app2，10000）</strong>。当然如果你想从offset （0，60100）PV（app1，50080）（app2，10020）这个状态恢复，也是做不到的，因为那个时刻程序突然挂了，这个状态根本没有保存下来，只有在 Checkpoint 的时候，才会把这些完整的状态保存到状态后端，供我们恢复任务。我们能做的最高效方式就是从最近一次成功的 Checkpoint 处恢复，也就是一直所说的 chk-100。以上基本就是 Checkpoint 承担的工作，为了方便理解，描述的业务场景比较简单。</p><p>补充两个问题：计算 PV 的 task 在一直运行，它怎么知道什么时候去做 Checkpoint 呢？计算 PV 的 task 怎么保证它自己计算的 PV 值（app1，50000）（app2，10000）就是offset（0，60000）那一刻的统计结果呢？Flink 在数据中加了一个叫做 barrier（栅栏） 的东西，如下图所示，用圈标注的就是 barrier。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151548.jpg" style="zoom:20%;" /></p><p>barrier 从 Source Task 处生成，一直流到 Sink Task，期间所有的 Task 只要碰到 barrier，就会触发自身进行快照。如上图所示，Checkpoint barrier n-1 处做的快照就是指 Job 从开始处理到 barrier n-1 所有的状态数据，barrier n 处做的快照就是指从 Job 开始到处理到 barrier n 所有的状态数据。对应到 PV 案例中就是，Source Task 接收到 JobManager 的编号为 chk-100 的 Checkpoint 触发请求后，发现自己恰好接收到 kafka offset（0，60000）处的数据，所以会往 offset（0，60000）数据之后 offset（0，60001）数据之前插入一个barrier，然后自己开始做快照，也就是将offset（0，60000）保存到状态后端 chk-100 中。然后，Source Task 会把 barrier 和我们要处理的数据一块往下游发送，当统计 PV 的 task 接收到 barrier 后，意味着 barrier 之前的数据已经被 PV task 处理完了，此时也会暂停处理 barrier 之后的数据，将自己内存中保存的 PV 信息（app1，50000）（app2，10000）保存到状态后端 chk-100 中。Flink 大概就是通过以上过程来保存快照的。</p><p>上述过程中，barrier 的作用就是为了把数据区分开，barrier 之前的数据是本次 Checkpoint 之前必须处理完的数据，barrier 之后的数据在本次 Checkpoint 之前不能被处理。Checkpoint 过程中有一个同步做快照的环节不能处理 barrier 之后的数据，为什么呢？如果做快照的同时，也在处理数据，那么处理的数据可能会修改快照内容，所以先暂停处理数据，把内存中快照保存好后，再处理数据。结合案例来讲就是，PV task 在对（app1，50000）（app2，10000）做快照的同时，如果 barrier 之后的数据还在处理，可能会导致状态信息还没保存到磁盘，状态已经变成了（app1，50001）（app2，10001），导致我们最后快照里保存的 PV 值变成了（app1，50001）（app2，10001），这样如果从 Checkpoint 恢复任务时，我们从 offset 60000 开始消费，PV 值从 （app1，50001）（app2，10001） 开始累加，就会造成计算的 PV 结果偏高，结果不准确，就不能保证 Exactly Once。所以，Checkpoint 同步做快照的过程中，不能处理 barrier 之后的数据。Checkpoint 将快照信息写入到磁盘后，为了保证快照信息的高可用，需要将快照上传到 HDFS，这个上传快照到 HDFS 的过程是异步进行的，这个过程也可以处理 barrier 之后的数据，处理 barrier 之后的数据不会影响到磁盘上的快照信息。</p><p>从 PV 案例再分析 Flink 是如何做 Checkpoint 并从 Checkpoint 处恢复任务的，首先 JobManager 端会向所有 SourceTask 发送 Checkpoint，Source Task 会在数据流中安插 Checkpoint barrier，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151547.jpg" alt="单并行度 PV 案例 Checkpoint 过程图示1" style="zoom:13%;" /></p><p>Source Task 安插好 barrier 后，会将 barrier 跟数据一块发送给下游，然后自身开始做快照，并将快照信息 offset (0,60000) 发送到高可用的持久化存储介质，例如 HDFS 上，发送流程如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151542.jpg" alt="单并行度 PV 案例 Checkpoint 过程图示2" style="zoom:13%;" /></p><p>下游的 PV task 接收到 barrier 后，也会做快照，并将快照信息 PV：(app1,50000) (app2,10000) 发送到 HDFS 上，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151543.jpg" style="zoom:13%;" /></p><p>假设第 100 次 Checkpoint 完成后，一段时间后任务挂了，Flink 任务会自动从状态后端恢复任务。Source Task 去读取自己需要的状态信息 offset (0,60000) ，并从 offset 为 60000 的位置接着开始消费数据，PV task 也会去读取需要的状态信息 PV：(app1,50000) (app2,10000)，并在该状态值的基础上，往上累积计算 PV 值，流程如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151544.jpg" style="zoom:13%;" /></p><h4 id="多并行度、多-Operator-情况下，Checkpoint-的过程"><a href="#多并行度、多-Operator-情况下，Checkpoint-的过程" class="headerlink" title="多并行度、多 Operator 情况下，Checkpoint 的过程"></a>多并行度、多 Operator 情况下，Checkpoint 的过程</h4><p>上一节中讲述了单并行度情况下 Checkpoint 的过程，但是生产环境中，一般都是多并行度，而且算子也会比较多，这种情况下 Checkpoint 的过程就会变得复杂。分布式状态容错面临的问题与挑战：</p><ul><li>如何确保状态拥有<strong>精确一次</strong>的容错保证？</li><li>如何在分布式场景下替多个拥有本地状态的算子产生<strong>一个全域一致的快照</strong>？</li><li>如何在<strong>不中断运算</strong>的前提下产生快照？</li></ul><p>多并行度、多 Operator 实例的情况下，如何做全域一致的快照？所有的 Operator 运行过程中接收到所有上游算子发送 barrier 后，对自身的状态进行一次快照，保存到相应状态后端，流程如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151553.jpg" style="zoom: 13%;" /></p><p>当任务从状态恢复时，每个 Operator 从状态后端读取自己相应的状态信息，数据源会从状态中保存的位置开始重新消费，后续的其他算子也会基于 Checkpoint 中保存的状态进行计算，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151556.jpg" alt="多并行度下，任务从 Checkpoint 恢复图示" style="zoom:13%;" /></p><p>整个 Checkpoint 的过程跟之前单并行度类似，图中有 4 个带状态的 Operator 实例，相应的状态后端就可以想象成 4 个格子。整个 Checkpoint 的过程可以当做 Operator 实例填自己格子的过程，Operator 实例将自身的状态写到状态后端中相应的格子，当所有的格子填满可以简单的认为一次完整的 Checkpoint 做完了。</p><p>上面只是快照的过程，Checkpoint 执行过程如下：</p><p>1、JobManager 端的 CheckPointCoordinator 向所有 Source Task 发送 CheckPointTrigger，Source Task会在数据流中安插 Checkpoint barrier</p><p>2、当 task 收到所有的 barrier 后，向自己的下游继续传递 barrier，然后自身执行快照，并将自己的状态<strong>异步写入到持久化存储</strong>中</p><ul><li>增量 CheckPoint 只是把最新的一部分数据更新写入到外部存储</li><li>为了下游尽快开始做 CheckPoint，所以会先发送 barrier 到下游，自身再同步进行快照</li></ul><p>3、当 task 对状态的快照信息完成备份后，会将备份数据的地址（state handle）通知给 JobManager 的 CheckPointCoordinator</p><p>如果 Checkpoint 的持续时长超过了 Checkpoint 设定的超时时间，CheckPointCoordinator 还没有收集完所有的 State Handle，CheckPointCoordinator就会认为本次 Checkpoint 失败，会把这次 Checkpoint 产生的所有 状态数据全部删除</p><p>4、CheckPointCoordinator 把整个 StateHandle 封装成 Completed Checkpoint Meta，写入到 HDFS，整个 Checkpoint 结束</p><h4 id="barrier-对齐"><a href="#barrier-对齐" class="headerlink" title="barrier 对齐"></a>barrier 对齐</h4><p>什么是 barrier 对齐？如图所示，当前的 Operator 实例接收上游两个流的数据，一个是字母流，一个是数字流。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151558.jpg" style="zoom:10%;" /></p><p>当 Checkpoint 时，上游字母流和数字流都会往 Operator 实例发送 Checkpoint barrier，但是由于每个算子的执行速率不同，所以不可能保证上游两个流的 barrier 同时到达 Operator 实例，那图中的 Operator 实例到底什么时候进行快照呢？接收到任意一个 barrier 就可以开始进行快照了吗，还是接收到所有的 barrier 才能开始进行快照呢？答案是：当一个 Operator 实例有多个输入流时，Operator 实例需要在做快照之前进行 barrier 对齐，等待所有输入流的 barrier 都到达。barrier 对齐的详细过程如下所示：</p><p>1、对于一个有多个输入流的 Operator 实例，当 Operator 实例从其中一个输入流接收到 Checkpoint barrier n 时，就不能处理来自该流的任何数据记录了，直到它从其他所有输入流接收到 barrier n为止，否则 <strong>Operator 实例 Checkpoint n 的快照会混入快照 n 的记录和快照 n + 1 的记录</strong>。如上图中第 1 个小图所示，数字流的 barrier 先到达了。</p><p>2、接收到 barrier n 的流暂时被搁置，从这些流接收的记录不会被处理，而是放入输入缓冲区。图 2 中，我们可以看到虽然数字流对应的 barrier 已经到达了，但是barrier之后的 1、2、3 这些数据只能放到缓冲区中，等待字母流的barrier到达。</p><p>3、一旦最后所有输入流都接收到 barrier n，Operator 实例就会把 barrier 之前所有已经处理完成的数据和 barrier n 一块发送给下游。然后 Operator 实例就可以对状态信息进行快照。如图 3 所示，Operator 实例接收到上游所有流的 barrier n，此时 Operator 实例就可以将 barrier 和 barrier 之前的数据发送到下游，然后自身状态进行快照。</p><p>4、快照做完后，Operator 实例将继续处理缓冲区的记录，然后就可以处理输入流的数据。如图 4 所示，先处理完缓冲区数据，就可以正常处理输入流的数据了。</p><p>上面的过程就是 Flink 在 Operator 实例有多个输入流的情况下，整个 barrier 对齐的过程。那什么是 barrier 不对齐呢？barrier 不对齐是指当还有其他流的 barrier 还没到达时，为了提高 Operator 实例的处理性能，Operator 实例会直接处理 barrier 之后的数据，等到所有流的 barrier 都到达后，就可以对该 Operator 做 Checkpoint 快照了。对应到图中就是，barrier 不对齐时会直接把 barrier 之后的数据 1、2、3 直接处理掉，而<strong>不是</strong>放到缓冲区中等待其他的输入流的 barrier 到达，当所有输入流的 barrier 都到达后，才开始对 Operator 实例的状态信息进行快照，这样会导致做快照之前，Operator 实例已经处理了一些 barrier n 之后的数据。Checkpoint 的目的是为了保存快照信息，如果 barrier 不对齐，那么 Operator 实例在做第 n 次 Checkpoint 之前，已经处理了一些 barrier n 之后的数据，当程序从第 n 次 Checkpoint 恢复任务时，程序会从第 n 次 Checkpoint 保存的 offset 位置开始消费数据，就会导致一些数据被处理了两次，就出现了重复消费。如果进行 barrier 对齐，就不会出现这种重复消费的问题，所以 <strong>barrier 对齐就可以实现 Exactly Once，barrier 不对齐就变成了At Least Once。</strong></p><p>再结合计算 PV 的案例来证明一下，为什么 barrier 对齐就可以实现 Exactly Once，barrier 不对齐就变成了 At Least Once。之前的案例为了简单，描述的 kafka topic 只有 1 个 partition，这里为了讲述 barrier 对齐，假设 topic 有 2 个 partittion，且计算的是我们平台的总 PV，也就是说不需要区分 app，每条一条数据，我们都需要将其 PV 值 +1 即可。如下图所示，Flink 应用程序有两个 Source Task，一个计算 PV 的 Task，这里计算 PV 的 Task 就出现了存在多个输入流的情况。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151546.jpg" style="zoom:13%;" /></p><p>假设 barrier 不对齐，那么 Checkpoint 过程是怎么样呢？如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151554.jpg" style="zoom:12%;" /></p><p>如上图左部分所示，Source Subtask 0 和 Subtask 1 已经完成了快照操作，他们的状态信息为 offset(0,10000)(1,10005) 表示 partition0 消费到 offset 为 10000 的位置，partition 1 消费到 offset 为 10005 的位置。当 Source Subtask 1 的 barrier 到达 PV task 时，计算的 PV 结果为 20002，但 PV task 还没有接收到 Source Subtask 0 发送的 barrier，所以 PV task 还不能对自身状态信息进行快照。由于设置的 barrier 不对齐，所以此时 PV task 会继续处理 Source Subtask 0 和 Source Subtask 1 传来的数据。很快，如上图右部分所示，PV task 接收到 Source Subtask 0 发来的 barrier，但是 PV task 已经处理了 Source Subtask 1 barrier 之后的三条数据，所以 PV 值目前已经为 20008了，这里的 PV=20008 实际上已经处理到 partition 1 offset 为 10008 的位置，此时 PV task 会对自身的状态信息（PV = 20008）做快照，整体的快照信息为 offset(0,10000)(1,10005)  PV=20008。</p><p>接着程序在继续运行，过了 10 秒，由于某个服务器故障，导致我们的 Operator 实例有一个挂了，所以 Flink 会从最近一次 Checkpoint 保存的状态恢复。那具体是怎么恢复的呢？Flink 同样会起三个 Operator 实例，我还称他们是 Source Subtask 0 、Source Subtask 1 和 PV task。三个 Operator 会从状态后端读取保存的状态信息。Source Subtask 0 会从 partition 0 offset 为 10000 的位置开始消费，Source Subtask 1 会从 partition 1 offset 为 10005 的位置开始消费，PV task 会基于 PV=20008 进行累加统计。然后就会发现的 PV 值 20008 实际上已经包含了 partition 1 的 offset 10005~10008 的数据，所以 partition 1 从 offset 10005 恢复任务时，partition1 的 offset 10005~10008 的数据被消费了两次，出现了重复消费的问题，所以 barrier 不对齐只能保证 At Least Once。</p><p>如果设置为 barrier 对齐，这里能保证 Exactly Once 吗？如下图所示，当 PV task 接收到 Source Subtask 1 的 barrier 后，并不会处理 Source Subtask 1 barrier 之后的数据，而是把这些数据放到 PV task 的输入缓冲区中，直到等到 Source Subtask 0 的 barrier 到达后，PV task 才会对自身状态信息进行快照，此时 PV task 会把 PV=20005 保存到快照信息中，整体的快照状态信息为 offset(0,10000)(1,10005)  PV=20005，当任务从 Checkpoint 恢复时，Source Subtask 0 会从 partition 0 offset 为 10000 的位置开始消费，Source Subtask 1 会从 partition 1 offset 为 10005 的位置开始消费，PV task 会基于 PV=20005 进行累加统计，所以 barrier 对齐能保证 Flink 内部的 Exactly Once。在 Flink 应用程序中，当 Checkpoint 语义设置 Exactly Once 或 At Least Once 时，唯一的区别就是 barrier 对不对齐。当设置为 Exactly Once 时，就会 barrier 对齐，当设置为 At Least Once 时，就会 barrier 不对齐。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151555.jpg" style="zoom:12%;" /></p><p>通过本案例，我们应该发现了 barrier 在 Flink 的 Checkpoint 中起着非常大的作用。barrier 告诉 Flink 应用程序，Checkpoint 之前哪些数据不应该被处理，barrier 对齐的过程其实就是为了防止 Flink 应用程序处理重复的数据。总结一下，满足哪些条件时，会出现 barrier 对齐？在代码中设置了 Flink 的 Checkpoint 语义是 Exactly Once，其次 Operator 实例必须有多个输入流才会出现 barrier 对齐。对齐，汉语词汇，释义为使两个以上事物配合或接触得整齐。由汉语解释可得对齐肯定需要两个以上事物，所以必须有多个输入流才可能存在对齐。barrier 对齐就是上游多个流配合使得数据对齐的过程。言外之意：如果 Operator 实例只有一个输入流，就根本不存在 barrier 对齐，自己跟自己默认永远都是对齐的，所以当我们的应用程序从 Source 到 Sink 所有算子的并行度都是 1 的话，就算设置的 At Least Once，无形中也实现了 barrier 对齐，此时 Checkpoint 设置成 Exactly Once 和 At Least Once 一点区别都没有，都可以保证 Exactly Once。看到这里你应该已经知道了哪种情况会出现重复消费了，也应该要掌握为什么 barrier 对齐就能保证 Exactly Once，为什么 barrier 不对齐就是 At Least Once。</p><p>barrier 对齐其实是要付出代价的，从 barrier 对齐的过程可以看出，PV task 明明可以更高效的处理数据，但因为 barrier 对齐，导致 Source Subtask 1 barrier 之后的数据被放到缓冲区中，暂时性地没有被处理，假如生产环境中，Source Subtask 0 的 barrier 迟迟没有到达，比 Source Subtask 1 延迟了 30 秒，那么这 30 秒期间，Source Subtask 1 barrier 之后的数据不能被处理，所以 PV task 相当于被闲置了。所以，当我们的一些业务场景对 Exactly Once 要求不高时，我们可以设置 Flink 的 Checkpoint 语义是 At Least Once 来小幅度的提高应用程序的执行效率。Flink Web UI 的 Checkpoint 选项卡中可以看到 barrier 对齐的耗时，如果发现耗时比较长，且对 Exactly Once 语义要求不高时，可以考虑使用该优化方案。</p><p>前面提到如何在不中断运算的前提下产生快照？在 Flink 的 Checkpoint 过程中，无论下游算子有没有做完快照，只要上游算子将 barrier 发送到下游且上游算子自身已经做完快照时，那么上游算子就可以处理 barrier 之后的数据了，从而使得整个系统 Checkpoint 的过程影响面尽量缩到最小，来提升系统整体的吞吐量。</p><p>在整个 Checkpoint 的过程中，还存在一个问题，假设我们设置的 10 分钟一次 Checkpoint。在第 n 次 Checkpoint 成功后，过了 9 分钟，任务突然挂了，我们需要从最近一次成功的 Checkpoint 处恢复任务，也就是从 9 分钟之前的状态恢复任务，就需要把这 9分钟的数据全部再消费一次，成本比较大。有的同学可能会想，那可以不可以设置为 100 ms就做一次 Checkpoint 呢？这样的话，当任务出现故障时，就不需要从 9 分钟前的状态进行恢复了，直接从 100 ms之前的状态恢复即可，恢复就会很快，不需要处理大量重复数据了。但是，这样做会导致应用程序频繁的访问状态后端，一般我们为了高可用，会把状态里的数据比如 offset：（0，60000）PV：（app1，50000）（app2，10000） 信息保存到 HDFS 中，如果频繁访问 HDFS，肯定会造成吞吐量下降，所以一般我们的 Checkpoint 时间间隔可以设置为分钟级别，例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，我们甚至可以设置为 5 分钟一次 Checkpoint，毕竟我们的应用程序挂的概率并不高，偶尔一次从 5 分钟前的状态恢复，我们是可以接受的。可以根据业务场景合理地调节 Checkpoint 的间隔时长，对于状态很小的 Job Checkpoint 会很快，我们可以调小时间间隔，对于状态比较大的 Job Checkpoint 会比较慢，我们可以调大 Checkpoint 时间间隔。</p><p>有的同学可能还有疑问，明明说好的 Exactly Once，但在 Checkpoint 成功后 10s 发生了故障，从最近一次成功的 Checkpoint 处恢复时，由于发生故障前的 10s Flink 也在处理数据，所以 Flink 应用程序肯定是把一些数据重复处理了呀。在面对任意故障时，不可能保证每个算子中用户定义的逻辑在每个事件中只执行一次，因为用户代码被部分执行的可能性是永远存在的。那么，当引擎声明 Exactly Once 处理语义时，它们能保证什么呢？如果不能保证用户逻辑只执行一次，那么哪些逻辑只执行一次？当引擎声明 Exactly Once 处理语义时，它们实际上是在说，它们可以保证引擎管理的状态更新只提交一次到持久的后端存储。换言之，无论以什么维度计算 PV、无论 Flink 应用程序发生多少次故障导致重启从 Checkpoint 恢复，Flink 都可以保证 PV 结果是准确的，不会因为各种任务重启而导致 PV 值计算偏高。</p><p>为了下游尽快做 Checkpoint，所以会先发送 barrier 到下游，自身再同步进行快照。这一步，如果向下发送barrier后，自己同步快照慢怎么办？下游已经同步好了，自己还没？可能会出现下游比上游快照还早的情况，但是这不影响快照结果，只是下游做快照更及时了，我只要保证下游把barrier之前的数据都处理了，并且不处理 barrier 之后的数据，然后做快照，那么下游也同样支持 Exactly Once。这个问题不要从全局思考，单独思考上游和下游的实例，你会发现上下游的状态都是准确的，既没有丢，也没有重复计算。这里需要注意，如果有一个Operator 的 Checkpoint 失败了或者因为 Checkpoint 超时也会导致失败，那么 JobManager 会认为整个 Checkpoint 失败。失败的 Checkpoint 是不能用来恢复任务的，必须所有的算子的 Checkpoint 都成功，那么这次 Checkpoint 才能认为是成功的，才能用来恢复任务。对应到 PV 案例就是，PV task 做快照速度较快，PV=20005 较早地写入到了 HDFS，但是 offset(0,10000)(1,10005) 过了几秒才写入到 HDFS，这种情况就算出现了，也不会影响计算结果，因为我们的快照信息是完全正确的。</p><p>再分享一个案例，Flink 的 Checkpoint 语义设置了 Exactly Once，程序中设置了 1 分钟 1 次 Checkpoint，5 秒向 MySQL 写一次数据，并commit。最后发现 MySQL 中数据重复了。为什么会重复呢？Flink要求端对端的 Exactly Once 都必须实现 TwoPhaseCommitSinkFunction。如果你的 Checkpoint 成功了，过了30秒突然程序挂了，由于 5 秒 commit 一次，所以在应用程序挂之前的 30 秒实际上已经写入了 6 批数据进入 MySQL。从 Checkpoint 处恢复时，之前提交的 6 批数据就会重复写入，所以出现了重复消费。Flink 的 Exactly Once 有两种情况，一个是我们本节所讲的 Flink 内部的 Exactly Once，一个是端对端的 Exactly Once。关于端对端如何保证 Exactly Once，我们在下一节中深入分析。</p><h3 id="9-5-2-端对端如何保证-Exactly-Once？"><a href="#9-5-2-端对端如何保证-Exactly-Once？" class="headerlink" title="9.5.2 端对端如何保证 Exactly Once？"></a>9.5.2 端对端如何保证 Exactly Once？</h3><p>Flink 与外部存储介质之间进行数据交互统称为端对端或 end to end 数据传输。上一节讲述了 Flink 内部如何保证 Exactly Once，这一节来分析端对端的 Exactly Once。正如上述 Flink 写 MySQL 的案例所示，在第 n 次 Checkpoint 结束后，第 n+1 次 Checkpoint 之前，如果 Flink 应用程序已经向外部的存储介质中成功写入并提交了一些数据后，Flink 应用程序由于某些原因挂了，导致任务从第 n 次 Checkpoint 处恢复。这种情况下，就会导致第 n 次 Checkpoint 结束后且任务失败之前往外部存储介质中写入的那一部分数据重复写入两次，可能会导致相同的数据在存储介质中存储了两份，从而端对端的一致性语义保证从 Exactly Once 退化为 At Least Once。这里只考虑了数据重复的情况，为什么不考虑丢数据的情况呢？在写数据时可以对异常进行捕获增加重试策略，如果重试多次还没有成功可以让 Flink 任务失败，Flink 任务就会从最近一次成功的 Checkpoint 处恢复，就不会出现丢数据的情况，所以我们本节内容主要用来解决数据重复的问题。</p><p>针对上述端对端 Exactly Once 的问题，我们可以使用以下方案来解决：</p><p>1、假如我们使用的存储介质支持按照全局主键去重，那么比较容易实现 Exactly Once，无论相同的数据往外部存储中写入了几次，外部存储都会进行去重，只保留一条数据。例如，app1 的 PV 值为 10，现在把 （key=app1，value=10） 往 Redis 中写入 10 次，只是说把 value 值覆盖了 10次，并不会导致结果错误，这种方案属于幂等性写入。</p><p>2、我们上述案例中为什么会导致重复写入数据到外部存储呢？是因为在下一次 Checkpoint 之前如果任务失败时，一些数据已经成功写入到了外部存储中，没办法删除那些数据。既然问题是这样，那可以想办法把 “向外部存储中提交数据” 与 “Checkpoint” 强关联，两次 Checkpoint 之间不允许向外部存储介质中提交数据，Checkpoint 的时候再向外部存储提交。如果提交成功，则 Checkpoint 成功，提交失败，则 Checkpoint 也失败。这样在下一次 Checkpoint 之前，如果任务失败，也没有重复数据被提交到外部存储。这里只是描述一下大概思想，好多细节这里并没有详细描述，会在下文中详细描述。基于上述思想，Flink 实现了 TwoPhaseCommitSinkFunction，它提取了两阶段提交协议的通用逻辑，使得通过 Flink 来构建端到端的Exactly Once 程序成为可能。它提供了一个抽象层，用户只需要实现少数方法就能实现端到端的 Exactly Once 语义。不过这种方案必须要求我们的输出端 (Sink 端) 必须支持事务。</p><p>下面我们通过两部分来详细介绍上述两种方案。</p><h4 id="幂等性写入如何保证端对端的-Exactly-Once"><a href="#幂等性写入如何保证端对端的-Exactly-Once" class="headerlink" title="幂等性写入如何保证端对端的 Exactly Once"></a>幂等性写入如何保证端对端的 Exactly Once</h4><p>实时 ETL 当 HBase 做为 Sink 端时，就是典型的应用场景。把日志中的主键做为 HBase 的 RowKey，就可以保证数据不重复，实现比较简单，这里不多赘述。</p><p>继续探讨实时计算各 app PV 的案例，将统计结果以普通键值对的形式保存到 Redis 中供业务方查询。到底如何实现，才能保证 Redis 中的结果是精准的呢？在之前 Strom 或 Spark Streaming 的方案中，将统计的 PV 结果保存在 Redis 中，每来一条数据，从 Redis 中获取相应 app 对应的 PV 值然后内存中进行 +1 后，再将 PV 值 put 到 Redis 中。例如：Redis 中保存 app1 的 PV 为 10，现在来了一条 app1 的日志，首先从 Redis 中获取 app1 的 PV 值=10，内存中 10+1=11，将 (app1,11) put 到 Redis 中，这里的 11 就是我们统计的 app1 的 PV 结果。可以将这种方案优化为 incr 或 incrby，直接对 Redis 中的 10 进行累加，不需要手动在内存中进行累加操作。当然 Flink 也可以用上述的这种方案来统计各 app 的 PV，但是上述方案并不能保证 Exactly Once，为什么呢？当第 n 次 Checkpoint 时，app1 的 PV 结果为 10000，第 n 次 Checkpoint 结束后运行了 10 秒，Redis 中 app1 的 PV 结果已经累加到了 10200。此时如果任务挂了，从第 n 次 Checkpoint 恢复任务时，会继续按照 Redis 中保存的 PV=10200 进行累加，但是正确的结果应该是从 PV=10000 开始累加。如果按照上面的方案统计 PV，就可能会出现统计值偏高的情况。这里也证实了一点：并不是说 Flink 程序的 Checkpoint 语义设置为 Exactly Once，就能保证我们的统计结果或者各种输出结果都能满足 Exactly Once。为了编写真正满足 Exactly Once 的代码，我们需要对 Flink 的 Checkpoint 原理做一些了解，编写对 Exactly Once 友好的代码。</p><p>那如何编写代码才能使得最后在 Redis 中保存的 PV 结果满足 Exactly Once 呢？上一节中，讲述了 Flink 内部状态可以保证 Exactly Once，这里可以将统计的 PV 结果保存在 Flink 内部的状态里，每次基于状态进行累加操作，并将累加到的结果 put 到 Redis 中，这样当任务从 Checkpoint 处恢复时，并不是基于 Redis 中实时统计的 PV 值进行累加，而是基于 Checkpoint 中保存的 PV 值进行累加，Checkpoint 中会保存每次 Checkpoint 时对应的 PV 快照信息，例如：第 n 次 Checkpoint 会把当时 pv=10000 保存到快照信息里，同时状态后端还保存着一份实时的状态信息用于实时累加。示例代码如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// 1 分钟一次Checkpoint</span></span><br><span class="line">env.enableCheckpointing(TimeUnit.MINUTES.toMillis(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">CheckpointConfig checkpointConf = env.getCheckpointConfig();</span><br><span class="line"><span class="comment">// Checkpoint 语义 EXACTLY ONCE</span></span><br><span class="line">checkpointConf.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line">checkpointConf.enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);</span><br><span class="line"></span><br><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"localhost:9092"</span>);</span><br><span class="line">props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"app-pv-stat"</span>);</span><br><span class="line"></span><br><span class="line">DataStreamSource&lt;String&gt; appInfoSource = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">        <span class="comment">// kafka topic， String 序列化</span></span><br><span class="line">        <span class="string">"app-topic"</span>,  <span class="keyword">new</span> SimpleStringSchema(), props));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 按照 appId 进行 keyBy</span></span><br><span class="line">appInfoSource.keyBy((KeySelector&lt;String, String&gt;) appId -&gt; appId)</span><br><span class="line">        .map(<span class="keyword">new</span> RichMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">            <span class="keyword">private</span> ValueState&lt;Long&gt; pvState;</span><br><span class="line">            <span class="keyword">private</span> <span class="keyword">long</span> pv = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">super</span>.open(parameters);</span><br><span class="line">                <span class="comment">// 初始化状态</span></span><br><span class="line">                pvState = getRuntimeContext().getState(</span><br><span class="line">                        <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">"pvStat"</span>,</span><br><span class="line">                        TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Long&gt;() &#123;&#125;)));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Long&gt; <span class="title">map</span><span class="params">(String appId)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">// 从状态中获取该 app 的 PV 值，+1后，update 到状态中</span></span><br><span class="line">                <span class="keyword">if</span>(<span class="keyword">null</span> == pvState.value())&#123;</span><br><span class="line">                    pv = <span class="number">1</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    pv = pvState.value();</span><br><span class="line">                    pv += <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                pvState.update(pv);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(appId, pv);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        .print();</span><br><span class="line"></span><br><span class="line">env.execute(<span class="string">"Flink PV stat"</span>);</span><br></pre></td></tr></table></figure><p>代码中设置 1 分钟一次 Checkpoint，Checkpoint 语义 EXACTLY ONCE，从 Kafka 中读取数据，这里为了简化代码，所以 Kafka 中读取的直接就是 String 类型的 appId，按照 appId KeyBy 后，执行 RichMapFunction，RichMapFunction 的 open 方法中会初始化 ValueState<Long> 类型的 pvState，pvState 就是上文一直强调的状态信息，每次 Checkpoint 的时候，会把 pvState 的状态信息快照一份到 HDFS 来提供恢复。这里按照 appId 进行 keyBy，所以每一个 appId 都会对应一个 pvState，pvState 里存储着该 appId 对应的 pv 值。每来一条数据都会执行一次 map 方法，当这条数据对应的 appId 是新 app 时，pvState 里就没有存储这个 appId 当前的 pv 值，将 pv 值赋值为 1，当 pvState 里存储的 value 不为 null 时，拿出 pv 值 +1后 update 到 pvState 里。map 方法再将 appId 和 pv 值发送到下游算子，下游直接调用了 print 进行输出，这里完全可以替换成相应的 RedisSink 或 HBaseSink。本案例中计算 pv 的工作交给了 Flink 内部的 ValueState，不依赖外部存储介质进行累加，外部介质承担的角色仅仅是提供数据给业务方查询，所以无论下游使用什么形式的 Sink，只要 Sink 端能够按照主键去重，该统计方案就可以保证 Exactly Once。本案例使用的 ValueState，关于 State 的详细使用请参阅第3.1节。</p><h4 id="TwoPhaseCommitSinkFunction-如何保证端对端的-Exactly-Once"><a href="#TwoPhaseCommitSinkFunction-如何保证端对端的-Exactly-Once" class="headerlink" title="TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once"></a>TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once</h4><p>Flink 的源码中有这么一段注释：This is a recommended base class for all of the {@link SinkFunction} that intend to implement exactly-once semantic。意思是对于打算实现 Exactly Once 语义的所有 SinkFunction 都推荐继承该抽象类。在介绍 TwoPhaseCommitSinkFunction 之前，先了解一下 2PC 分布式一致性协议。</p><p>在分布式系统中，每一个机器节点虽然都能明确地知道自己在进行事务操作过程中的结果是成功或失败，但无法直接获取到其他分布式节点的操作结果。因此，当一个事务操作需要跨越多个分布式节点的时候，为了让每个节点都能够获取到其他节点的事务执行状况，需要引入一个”协调者（Coordinator）”节点来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点被称为”参与者（Participant）”。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务真正的提交。<br>普通的事务可以保证单个事务内所有操作要么全部成功，要么全部失败，而分布式系统中具体如何保证多台节点上执行的事务要么所有节点事务都成功，要么所有节点事务都失败呢？先了解一下 2PC 一致性协议。</p><p>2PC 是 Two-Phase Commit 的缩写，即两阶段提交。2PC 将分布式事务分为了两个阶段，分别是提交事务请求（投票）和执行事务提交。协调者会根据参与者在第一阶段的投票结果，来决定第二阶段是否真正的执行事务，具体流程如下。</p><h5 id="提交事务请求（投票）阶段"><a href="#提交事务请求（投票）阶段" class="headerlink" title="提交事务请求（投票）阶段"></a>提交事务请求（投票）阶段</h5><p>提交事务请求阶段如下所示：</p><ul><li>协调者向所有参与者发送 prepare 请求与事务内容，询问是否可以准备事务提交，并等待参与者的响应</li><li>各参与者执行事务操作，并记录 Undo日志（用于回滚）和 Redo日志（用于重放），但不真正提交</li><li>参与者向协调者返回事务操作的执行结果，执行成功返回 Yes，否则返回 No</li></ul><h5 id="执行事务提交阶段"><a href="#执行事务提交阶段" class="headerlink" title="执行事务提交阶段"></a>执行事务提交阶段</h5><p>分为成功与失败两种情况：</p><ul><li>若第一阶段所有参与者都返回 Yes，说明事务可以提交<ul><li>协调者向所有参与者发送 Commit 请求</li><li>参与者收到 Commit 请求后，会正式执行事务提交操作，并在提交完成后释放事务资源</li><li>完成事务提交后，向协调者发送 Ack 消息</li><li>协调者收到所有参与者的 Ack 消息，完成事务</li></ul></li></ul><p>事务提交成功的流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151552.jpg" style="zoom:12%;" /></p><ul><li>若第一阶段有参与者返回 No 或者超时未返回，说明事务中断，需要回滚<ul><li>协调者向所有参与者发送 Rollback 请求</li><li>参与者收到 Rollback 请求后，根据 Undo日志回滚到事务执行前的状态，释放占用的事务资源</li><li>参与者在完成事务回滚后，向协调者返回 Ack</li><li>协调者收到所有参与者的 Ack 消息，事务回滚完成</li></ul></li></ul><p>事务提交中断，需要回滚的流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151557.jpg" style="zoom:12%;" /></p><p>简单来讲，2PC 将一个事务的处理过程分为了投票和执行两个阶段，其核心是每个事务都采用先尝试后提交的处理方式。2PC 的优缺点如下所示：</p><p>优点：原理简单，实现方便</p><p>缺点：</p><ul><li>协调者单点问题：协调者在整个 2PC 协议中非常重要，一旦协调者故障，则 2PC 将无法运转</li><li>过于保守：在 2PC 的阶段一，如果参与者出现故障而导致协调者无法获取到参与者的响应信息，这时协调者只能依靠自身的超时机制来判断是否需要中断事务，这种策略比较保守。换言之，2PC 没有涉及较为完善的容错机制，任意一个节点失败都会导致整个事务的失败</li><li>同步阻塞：执行过程是完全同步的，各个参与者在等待其他参与者投票响应的的过程中，将无法进行其他任何操作</li><li>数据不一致：在二阶段提交协议的阶段二，当协调者向所有的参与者发送 Commit 请求后，出现了局部网络异常或局部参与者机器故障等因素导致一部分的参与者执行了 Commit 操作，而发生故障的参与者没有执行 Commit，于是整个分布式系统便出现了数据不一致现象</li></ul><p>Flink 的 TwoPhaseCommitSinkFunction 是基于 2PC 实现的。Flink 的 JobManager 对应到 2PC 中的协调者，Operator 实例对应到 2PC 中的参与者。TwoPhaseCommitSinkFunction 实现了 CheckpointedFunction 和 CheckpointListener 接口。CheckpointedFunction 接口中有两个方法 snapshotState 和 initializeState，snapshotState 方法会在 Checkpoint 时且做快照之前被调用，initializeState 方法会在自定义 Function 初始化恢复状态时被调用。CheckpointListener 接口中有一个 notifyCheckpointComplete 方法，Operator 实例的 Checkpoint 成功后，会反馈给 JobManager，当 JobManager 接收到所有 Operator 实例 Checkpoint 成功的通知后，就认为本次 Checkpoint 成功了，会给所有 Operator 实例发送一个 Checkpoint 完成的通知，Operator 实例接收到通知后，就会调用 notifyCheckpointComplete 方法。</p><p>TwoPhaseCommitSinkFunction定义了如下 5 个抽象方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 处理每一条数据</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(TXN transaction, IN value, Context context)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 开始一个事务，返回事务信息的句柄</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> TXN <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 预提交（即提交请求）阶段的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">preCommit</span><span class="params">(TXN transaction)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 正式提交阶段的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">(TXN transaction)</span></span>;</span><br><span class="line"><span class="comment">// 取消事务,Rollback 相关的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">abort</span><span class="params">(TXN transaction)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="9-5-3-分析-FlinkKafkaConsumer-的设计思想"><a href="#9-5-3-分析-FlinkKafkaConsumer-的设计思想" class="headerlink" title="9.5.3 分析 FlinkKafkaConsumer 的设计思想"></a>9.5.3 分析 FlinkKafkaConsumer 的设计思想</h3><h4 id="kafka-offset-存储及如何实现-Consumer-实例消费-partition-的负载均衡"><a href="#kafka-offset-存储及如何实现-Consumer-实例消费-partition-的负载均衡" class="headerlink" title="kafka offset 存储及如何实现 Consumer 实例消费 partition 的负载均衡"></a>kafka offset 存储及如何实现 Consumer 实例消费 partition 的负载均衡</h4><h4 id="Source-端并行度改变了，如何来恢复-offset"><a href="#Source-端并行度改变了，如何来恢复-offset" class="headerlink" title="Source 端并行度改变了，如何来恢复 offset"></a>Source 端并行度改变了，如何来恢复 offset</h4><h4 id="如何实现自动发现当前消费-topic-下新增的-partition"><a href="#如何实现自动发现当前消费-topic-下新增的-partition" class="headerlink" title="如何实现自动发现当前消费 topic 下新增的 partition"></a>如何实现自动发现当前消费 topic 下新增的 partition</h4><h3 id="9-5-4-小结与反思"><a href="#9-5-4-小结与反思" class="headerlink" title="9.5.4 小结与反思"></a>9.5.4 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-5-Flink-中如何保证-Exactly-Once？&quot;&gt;&lt;a href=&quot;#9-5-Flink-中如何保证-Exactly-Once？&quot; class=&quot;headerlink&quot; title=&quot;9.5 Flink 中如何保证 Exactly Once？&quot;&gt;&lt;/a&gt;9.5 Flink 中如何保证 Exactly Once？&lt;/h2&gt;&lt;p&gt;在分布式场景下，我们的应用程序随时可能出现任何形式的故障，例如：机器硬件故障、程序 OOM 等。当应用程序出现故障时，Flink 为了保证数据消费的 Exactly Once，需要有相应的故障容错能力。Flink 是通过周期性 Checkpoint 的方式来实现故障容错，这里使用的是基于 Chandy-Lamport 改进的算法。本节会介绍 Flink 内部如何保证 Exactly Once 以及端对端如何保证 Exactly Once。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— 如何合理的设置 Flink 作业并行度？</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/10/flink-in-action-9.4/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/10/flink-in-action-9.4/</id>
    <published>2021-08-09T16:00:00.000Z</published>
    <updated>2022-01-23T12:03:10.122Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-4-如何合理的设置-Flink-作业并行度？"><a href="#9-4-如何合理的设置-Flink-作业并行度？" class="headerlink" title="9.4 如何合理的设置 Flink 作业并行度？"></a>9.4 如何合理的设置 Flink 作业并行度？</h2><p>在 9.2 节中讲解了 Flink Job 中的执行计划，并详细分析了 Flink 中的 operator chain 在一起的各种条件，在 9.3 节中也通过真实生产环境的案例来分享并行度与 Slot 的概念与关系。相信大家也都有一定的理解，但是有时候生产环境如果 Job 突然消费不及时了，或者 Job 就根本不在消费数据了，那么该怎么办？首先得看下相关的监控查看 Job 是否在正常运行，是否出现反压的情况，是否这会生产数据量过大然而并行度却是根据之前数据量设置的，种种原因都需要一个个排查一下，然后找到根因才能够对应的去解决。这节来讲解下遇到这种问题后如何合理配置并行度呢？</p><a id="more"></a><h3 id="9-4-1-Source-端并行度的配置"><a href="#9-4-1-Source-端并行度的配置" class="headerlink" title="9.4.1 Source 端并行度的配置"></a>9.4.1 Source 端并行度的配置</h3><p>假设数据源端是 Kafka，在出现作业消费不及时的时候，首先看下 Kafka 的监控是不是现在生产者生产的数据上涨速度较快，从而导致作业目前的消费速度就是跟不上 Kafka 生产者的生产速度，如果是这样的话，那么就得查看作业的并行度和 Kafka 的分区数是否一致，如果小于 Kafka 的分区数，那么可以增大并行度至 Kafka 的分区数，然后再观察作业消费速度是否可以跟上数据生产速度；如果已经等于 Kafka 的分区数了，那得考虑下是否 Kafka 要扩大分区，但是这样可能会带来 Kafka 其他的问题，这个操作需要谨慎。</p><p>Kafka 中数据出现堆积的话，还可以分析下数据的类型，如果数据不重要，但是又要保证数据的及时性，可以修改作业让作业始终从最新的数据开始消费，丢弃之前堆积的数据，这样就可以保证数据的及时性。举个例子，假如一个实时告警作业它突然消费不及时，Kafka 中堆积了几亿条数据（数据延迟几个小时），那么如果作业调高并行度重启后，它还是从上一次提交的 offset 处开始消费的话，这样告警作业即使现在消费速度跟的上了，但是它要处理掉之前堆积的几亿条数据也是要一段时间的，那么就意味着这个作业仍将有段时间处于 ‘不可用’。因为即使判断出来要告警，可能这个告警信息的原数据已经是几个小时前的了，没准这个告警此时已经恢复了，但是还发出来告警这就意味着延迟性比较大，还会对告警消息接收者造成一定的干扰，所以这种场景下建议重启作业就直接开始从最新的数据开始消费。当然不同的场景可能不一样，如果金融行业的交易数据，那么是肯定不能允许这样丢数据的，即使堆积了，也要慢慢的去消费堆积的数据，直到后面追平至最新的数据。</p><p>在 Source 端设置并行度的话，如果数据源是 Kafka 的话，建议并行度不要超过 Kafka 的分区数，因为一个并行度会去处理一至多个分区的数据，如果设置过多的话，会出现部分并行度空闲。如果是其他的数据源，可以根据实际情况合理增大并行度来提高作业的处理数据能力。</p><h3 id="9-4-2-中间-Operator-并行度的配置"><a href="#9-4-2-中间-Operator-并行度的配置" class="headerlink" title="9.4.2 中间 Operator 并行度的配置"></a>9.4.2 中间 Operator 并行度的配置</h3><p>数据从 Source 端流入后，通常会进行一定的数据转换、聚合才能够满足需求，在数据转换中可能会和第三方系统进行交互，在交互的过程中可能会因为网络原因或者第三方服务原因导致有一定的延迟，从而导致这个数据交互的算子处理数据的吞吐量会降低，可能会造成反压，从而会影响上游的算子的消费。那么在这种情况下这些与第三方系统有交互的算子得稍微提高并行度，防止出现这种反压问题（当然反压问题不一定就这样可以解决，具体如何处理参见 9.1 节）。</p><p>除了这种与第三方服务做交互的外，另外可能的性能瓶颈也会出现在这类算子中，比如你 Kafka 过来的数据是 JSON 串的 String，然后需要转换成对象，在大数据量的情况下这个转换也是比较耗费性能的。</p><p>所以数据转换中间过程的算子也是非常重要的，如果哪一步算子的并行度设置的不合理，可能就会造成各种各样的问题出现。</p><h3 id="9-4-3-Sink-端并行度的配置"><a href="#9-4-3-Sink-端并行度的配置" class="headerlink" title="9.4.3 Sink 端并行度的配置"></a>9.4.3 Sink 端并行度的配置</h3><p>Sink 端是数据流向下游的地方，可以根据 Sink 端的数据量进行评估，可能有的作业是 Source 端的数据量最大，然后数据量不断的变少，最后到 Sink 端的数据就一点点了，比较常见的就是监控告警的场景。Source 端的数据是海量的，但是通过逐层的过滤和转换，到最后判断要告警的数据其实已经减少很多很多了，那么在最后的这个地方就可以将并行度设置的小一些。</p><p>当然也可能会有这样的情况，在 Source 端的数据量是最小的，拿到 Source 端流过来的数据后做了细粒度的拆分，那么数据量就不断的增加了，到 Sink 端的数据量就非常非常的大了。那么在 Sink 到下游的存储中间件的时候就需要提高并行度。</p><p>另外 Sink 端也是要与下游的服务进行交互，并行度还得根据下游的服务抗压能力来设置，如果在 Flink Sink 这端的数据量过大的话，然后在 Sink 处并行度也设置的很大，但是下游的服务完全撑不住这么大的并发写入，也是可能会造成下游服务直接被写挂的，下游服务可能还要对外提供一些其他的服务，如果稳定性不能保证的话，会造成很大的影响，所以最终还是要在 Sink 处的并行度做一定的权衡。</p><h3 id="9-4-4-Operator-Chain"><a href="#9-4-4-Operator-Chain" class="headerlink" title="9.4.4 Operator Chain"></a>9.4.4 Operator Chain</h3><p>对于一般的作业（无特殊耗性能处），可以尽量让算子的并行度从 Source 端到 Sink 端都保持一致，这样可以尽可能的让 Job 中的算子进行 chain 在一起，形成链，数据在链中可以直接传输，而不需要再次进行序列化与反序列化，这样带来的性能消耗就会得到降低。在 9.2 节中具体讲解了算子 chain 在一起的条件，忘记的话可以去回顾一下。</p><h3 id="9-4-5-小结与反思"><a href="#9-4-5-小结与反思" class="headerlink" title="9.4.5 小结与反思"></a>9.4.5 小结与反思</h3><p>本节讲了作业执行过程中 Source 端、中间算子和 Sink 端的并行度设置的一些技巧。并行度修改后（增大或者减小）重启 Job，如果是减小并行度，之前原有的并行度的状态该怎么办；如果是新增并行度，如何确保和原来的并行度状态保持一致？</p><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-4-如何合理的设置-Flink-作业并行度？&quot;&gt;&lt;a href=&quot;#9-4-如何合理的设置-Flink-作业并行度？&quot; class=&quot;headerlink&quot; title=&quot;9.4 如何合理的设置 Flink 作业并行度？&quot;&gt;&lt;/a&gt;9.4 如何合理的设置 Flink 作业并行度？&lt;/h2&gt;&lt;p&gt;在 9.2 节中讲解了 Flink Job 中的执行计划，并详细分析了 Flink 中的 operator chain 在一起的各种条件，在 9.3 节中也通过真实生产环境的案例来分享并行度与 Slot 的概念与关系。相信大家也都有一定的理解，但是有时候生产环境如果 Job 突然消费不及时了，或者 Job 就根本不在消费数据了，那么该怎么办？首先得看下相关的监控查看 Job 是否在正常运行，是否出现反压的情况，是否这会生产数据量过大然而并行度却是根据之前数据量设置的，种种原因都需要一个个排查一下，然后找到根因才能够对应的去解决。这节来讲解下遇到这种问题后如何合理配置并行度呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《Flink 实战与性能优化》—— Flink Parallelism 和 Slot 深度理解</title>
    <link href="http://www.54tianzhisheng.cn/2021/08/09/flink-in-action-9.3/"/>
    <id>http://www.54tianzhisheng.cn/2021/08/09/flink-in-action-9.3/</id>
    <published>2021-08-08T16:00:00.000Z</published>
    <updated>2022-01-23T11:58:52.936Z</updated>
    
    <content type="html"><![CDATA[<h2 id="9-3-Flink-Parallelism-和-Slot-深度理解"><a href="#9-3-Flink-Parallelism-和-Slot-深度理解" class="headerlink" title="9.3 Flink Parallelism 和 Slot 深度理解"></a>9.3 Flink Parallelism 和 Slot 深度理解</h2><p>相信使用过 Flink 的你或多或少遇到过下面这个问题（笔者自己的项目曾经也出现过这样的问题），错误信息如下：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Caused by: akka.pattern.AskTimeoutException: </span><br><span class="line">Ask timed out on [Actor[akka://flink/user/taskmanager_0#15608456]] after [10000 ms]. </span><br><span class="line">Sender[null] sent message of type &quot;org.apache.flink.runtime.rpc.messages.LocalRpcInvocation&quot;.</span><br></pre></td></tr></table></figure><p>错误信息的完整截图如下图所示。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/FkaM6A.jpg" alt=""></p><p>跟着这问题在 Flink 的 Issue 列表里看到了一个类似的问题：<a href="https://issues.apache.org/jira/browse/FLINK-9056">FLINK-9056 issues</a>，看到该 Issue 下面的评论说出现该问题的原因是因为 TaskManager 的 Slot 数量不足导致的 Job 提交失败，在 Flink 1.63 中已经修复了，变成抛出异常了，修复的代码如下图所示。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/p4Tr9Z.jpg" alt=""></p><p>竟然知道了是因为 Slot 不足的原因了，那么我们就要先了解下 Slot 是什么呢？不过在了解 Slot 之前这里先介绍下 Parallelism。</p><h3 id="9-3-1-Parallelism-简介"><a href="#9-3-1-Parallelism-简介" class="headerlink" title="9.3.1 Parallelism 简介"></a>9.3.1 Parallelism 简介</h3><p>Parallelism 翻译成中文是并行的意思，在 Flink 作业里面代表算子的并行度，适当的提高并行度可以大大提高 Job 的执行效率，比如你的 Job 消费 Kafka 数据过慢，适当调大可能就消费正常了。那么在 Flink 中怎么设置并行度呢？</p><h3 id="9-3-2-如何设置-Parallelism？"><a href="#9-3-2-如何设置-Parallelism？" class="headerlink" title="9.3.2 如何设置 Parallelism？"></a>9.3.2 如何设置 Parallelism？</h3><p>在 Flink 配置文件中默认并行度是 1，你可以通过下面的命令查看到配置文件中的默认并行度：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat flink-conf.yaml | grep parallelism</span><br></pre></td></tr></table></figure><p>结果如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-055925.png" alt=""></p><p>所以如果在你的 Flink Job 里面不设置任何 Parallelism 的话，那么它也会有一个默认的 Parallelism（默认为 1），那也意味着可以修改这个配置文件的默认并行度来提高 Job 的执行效率。如果是使用命令行启动你的 Flink Job，那么你也可以这样设置并行度(使用 -p n 参数)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run -p 10 /Users/zhisheng/word-count.jar</span><br></pre></td></tr></table></figure><p>你也可以在作业中通过 <code>env.setParallelism(n)</code> 代码来设置整个作业程序的并行度。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setParallelism(10);</span><br></pre></td></tr></table></figure><p>注意：这样设置的并行度是整个程序的并行度，那么后面如果每个算子不单独设置并行度覆盖的话，那么后面每个算子的并行度就都是以这里设置的并行度为准了。如何给每个算子单独设置并行度呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data.keyBy(<span class="keyword">new</span> xxxKey())</span><br><span class="line">    .flatMap(<span class="keyword">new</span> XxxFlatMapFunction()).setParallelism(<span class="number">5</span>)</span><br><span class="line">    .map(<span class="keyword">new</span> XxxMapFunction).setParallelism(<span class="number">5</span>)</span><br><span class="line">    .addSink(<span class="keyword">new</span> XxxSink()).setParallelism(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>如上就是给每个算子单独设置并行度，这样的话，就算程序设置了 <code>env.setParallelism(10)</code> 也是会被覆盖的。这也说明优先级是：算子设置并行度 &gt; env 设置并行度 &gt; 配置文件默认并行度。</p><p>并行度讲到这里应该都懂了，下面就继续讲什么是 Slot？</p><h3 id="9-3-3-Slot-简介"><a href="#9-3-3-Slot-简介" class="headerlink" title="9.3.3 Slot 简介"></a>9.3.3 Slot 简介</h3><p>其实 Slot 的概念在 1.2 节中已经提及到，这里再细讲一点。Flink 的作业提交的架构流程如下图所示：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/r19yJh.jpg" alt=""></p><p>图中 TaskManager 是从 JobManager 处接收需要部署的 Task，任务能配置的最大并行度由 TaskManager 上可用的 Slot 决定。每个任务代表分配给任务槽的一组资源，Slot 在 Flink 里面可以认为是资源组，Flink 将每个任务分成子任务并且将这些子任务分配到 Slot 中，这样就可以并行的执行程序。</p><p>例如，如果 TaskManager 有四个 Slot，那么它将为每个 Slot 分配 25％ 的内存。 可以在一个 Slot 中运行一个或多个线程。 同一 Slot 中的线程共享相同的 JVM。 同一 JVM 中的任务共享 TCP 连接和心跳消息。TaskManager 的一个 Slot 代表一个可用线程，该线程具有固定的内存，注意 Slot 只对内存隔离，没有对 CPU 隔离。默认情况下，Flink 允许子任务共享 Slot，即使它们是不同 Task 的 subtask，只要它们来自相同的 Job，这种共享模式可以大大的提高资源利用率。</p><p>如下图所示，有两个 TaskManager，每个 TaskManager 有三个 Slot，这样我们的算子最大并行度那么就可以达到 6 个，在同一个 Slot 里面可以执行 1 至多个子任务。那么再看下图，source/map/keyby/window/apply 算子最大可以设置 6 个并行度，sink 只设置了 1 个并行度。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/ECv5y2.jpg" alt=""></p><p>每个 Flink TaskManager 在集群中提供 Slot，Slot 的数量通常与每个 TaskManager 的可用 CPU 内核数成比例（一般情况下 Slot 个数是每个 TaskManager 的 CPU 核数）。Flink 配置文件中设置的一个 TaskManager 默认的 Slot 是 1，配置如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-062913.png" alt=""></p><p><code>taskmanager.numberOfTaskSlots: 1</code> 该参数可以根据实际情况做一定的修改。</p><h3 id="9-3-4-Slot-和-Parallelism-的关系"><a href="#9-3-4-Slot-和-Parallelism-的关系" class="headerlink" title="9.3.4 Slot 和 Parallelism 的关系"></a>9.3.4 Slot 和 Parallelism 的关系</h3><h3 id="9-3-5-可能会遇到-Slot-和-Parallelism-的问题"><a href="#9-3-5-可能会遇到-Slot-和-Parallelism-的问题" class="headerlink" title="9.3.5 可能会遇到 Slot 和 Parallelism 的问题"></a>9.3.5 可能会遇到 Slot 和 Parallelism 的问题</h3><h3 id="9-3-6-小结与反思"><a href="#9-3-6-小结与反思" class="headerlink" title="9.3.6 小结与反思"></a>9.3.6 小结与反思</h3><p>加入知识星球可以看到上面文章：<a href="https://t.zsxq.com/uFEEYzJ">https://t.zsxq.com/uFEEYzJ</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;9-3-Flink-Parallelism-和-Slot-深度理解&quot;&gt;&lt;a href=&quot;#9-3-Flink-Parallelism-和-Slot-深度理解&quot; class=&quot;headerlink&quot; title=&quot;9.3 Flink Parallelism 和 Slot 深度理解&quot;&gt;&lt;/a&gt;9.3 Flink Parallelism 和 Slot 深度理解&lt;/h2&gt;&lt;p&gt;相信使用过 Flink 的你或多或少遇到过下面这个问题（笔者自己的项目曾经也出现过这样的问题），错误信息如下：&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
</feed>
